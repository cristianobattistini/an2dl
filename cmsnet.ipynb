{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13644638,"sourceType":"datasetVersion","datasetId":8673684}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Artificial Neural Networks and Deep Learning**\n\n---","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è **Libraries Import**","metadata":{}},{"cell_type":"code","source":"# Set seed for reproducibility\nSEED = 42\n\n# Import necessary libraries\nimport os\n\n# Set environment variables before importing modules\nos.environ['PYTHONHASHSEED'] = str(SEED)\nos.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n\n# Suppress warnings\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# Import necessary modules\nimport logging\nimport random\nimport numpy as np\n\n# Set seeds for random number generators in NumPy and Python\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\n# Import PyTorch\nimport torch\ntorch.manual_seed(SEED)\nfrom torch import nn\nfrom torchsummary import summary\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.utils.data import TensorDataset, DataLoader\nlogs_dir = \"tensorboard\"\n!pkill -f tensorboard\n%load_ext tensorboard\n!mkdir -p models\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.benchmark = True\nelse:\n    device = torch.device(\"cpu\")\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"Device: {device}\")\n\n# Import other libraries\nimport copy\nimport shutil\nfrom datetime import datetime\nfrom itertools import product\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nfrom pathlib import Path\nimport pickle\n\n# Configure plot display settings\nsns.set(font_scale=1.4)\nsns.set_style('white')\nplt.rc('font', size=14)\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:32:50.003785Z","iopub.execute_input":"2025-11-11T23:32:50.003989Z","iopub.status.idle":"2025-11-11T23:32:50.348157Z","shell.execute_reply.started":"2025-11-11T23:32:50.003971Z","shell.execute_reply":"2025-11-11T23:32:50.347147Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚è≥ **Data Loading**","metadata":{}},{"cell_type":"code","source":"DATASET_ROOT = Path(\"./dataset\")\n\n# --- 2Ô∏è‚É£ Kaggle ---\nDATASET_ROOT = Path(\"/kaggle/input/pirate-pain\")\n\n# --- 3Ô∏è‚É£ Server o cluster privato (es. Westworld/Elysium) ---\n# DATASET_ROOT = Path(\"/multiverse/datasets/private_dataset/pirate_pain\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:32:50.349862Z","iopub.execute_input":"2025-11-11T23:32:50.350159Z","iopub.status.idle":"2025-11-11T23:32:50.354186Z","shell.execute_reply.started":"2025-11-11T23:32:50.350136Z","shell.execute_reply":"2025-11-11T23:32:50.353384Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Caricamento dati\nX_train = pd.read_csv(DATASET_ROOT / \"pirate_pain_train.csv\")\nX_TRAIN = pd.read_csv(DATASET_ROOT / \"pirate_pain_train.csv\")\n\ny_train = pd.read_csv(DATASET_ROOT / \"pirate_pain_train_labels.csv\")\nY_TRAIN = pd.read_csv(DATASET_ROOT / \"pirate_pain_train_labels.csv\")\n\nX_test  = pd.read_csv(DATASET_ROOT / \"pirate_pain_test.csv\")\n\nprint(f\"  X_train: {X_train.shape}\")\nprint(f\"  y_train: {y_train.shape}\")\nprint(f\"  X_test:  {X_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:32:50.354899Z","iopub.execute_input":"2025-11-11T23:32:50.355170Z","iopub.status.idle":"2025-11-11T23:32:54.997714Z","shell.execute_reply.started":"2025-11-11T23:32:50.355144Z","shell.execute_reply":"2025-11-11T23:32:54.996917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1) Which columns are what?\njoint_cols        = [c for c in X_train.columns if c.startswith(\"joint_\")]\npain_survey_cols  = [c for c in X_train.columns if c.startswith(\"pain_survey_\")]\ncat_two_cols      = [\"n_legs\", \"n_hands\", \"n_eyes\"]  # 2 options each (binary)\n\nprint(\"Counts ‚Äî joints:\", len(joint_cols),\n      \"| pain_survey:\", len(pain_survey_cols),\n      \"| binary cats:\", len(cat_two_cols))\n\n# 2) Unique values for the binary categoricals (before any mapping)\nfor c in cat_two_cols:\n    vals = X_train[c].dropna().unique().tolist()\n    print(f\"{c}: uniques -> {vals}\")\n\n# 3) Unique values for each pain_survey_* column\nsurvey_uniques = {}\nfor c in pain_survey_cols:\n    vals = np.sort(X_train[c].dropna().unique())\n    survey_uniques[c] = vals\n    print(f\"{c}: uniques -> {vals} (dtype={X_train[c].dtype})\")\n\n# 4) Cardinalities summary (useful if we embed)\ncat_cardinalities = {\n    **{c: int(X_train[c].nunique()) for c in cat_two_cols},\n    **{c: int(X_train[c].nunique()) for c in pain_survey_cols}\n}\nprint(\"Cardinalities:\", cat_cardinalities)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:32:54.999539Z","iopub.execute_input":"2025-11-11T23:32:54.999782Z","iopub.status.idle":"2025-11-11T23:32:55.062432Z","shell.execute_reply.started":"2025-11-11T23:32:54.999765Z","shell.execute_reply":"2025-11-11T23:32:55.061837Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üîé **Exploration and Data Analysis**","metadata":{}},{"cell_type":"code","source":"# Controllo struttura e tipi\ndisplay(X_train.head())\nX_train.info()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:32:55.063068Z","iopub.execute_input":"2025-11-11T23:32:55.063301Z","iopub.status.idle":"2025-11-11T23:32:55.131621Z","shell.execute_reply.started":"2025-11-11T23:32:55.063276Z","shell.execute_reply":"2025-11-11T23:32:55.130975Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MERGE BETWEEN TRAIN DATA AND LABELS\n# the labels are in a separated file linked through 'sample_index\n# here we merge X_train and y_train in a unique Dataframe to explore\n\ntrain_merge = X_train.merge(y_train, on=\"sample_index\", how=\"left\")\n\n# check whether all the labels have been associated or not\nmissing_labels = train_merge[\"label\"].isna().sum()\nif missing_labels > 0:\n    print(f\"{missing_labels} rows without a label\")\n\n# check\nprint(train_merge[[\"sample_index\",\"time\",\"label\"]].head())\nprint(\"Class Distribution\")\nprint(train_merge[\"label\"].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:32:55.132247Z","iopub.execute_input":"2025-11-11T23:32:55.132479Z","iopub.status.idle":"2025-11-11T23:32:55.171148Z","shell.execute_reply.started":"2025-11-11T23:32:55.132459Z","shell.execute_reply":"2025-11-11T23:32:55.170381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(y_train[\"label\"].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:32:55.171902Z","iopub.execute_input":"2025-11-11T23:32:55.172108Z","iopub.status.idle":"2025-11-11T23:32:55.177081Z","shell.execute_reply.started":"2025-11-11T23:32:55.172090Z","shell.execute_reply":"2025-11-11T23:32:55.176243Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üîÑ **Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"def dataset_conversion_type_embed_ready(df):\n    \"\"\"\n    Minimal, embedding-friendly preprocessing:\n    - joints: float32 (continuous features)\n    - pain_survey_*: int64 indices (0..2) for embeddings\n    - n_legs/hands/eyes: mapped to {0,1} as int64 for embeddings\n    Returns: df, meta\n    \"\"\"\n    df = df.copy()\n\n    # 1) continuous features\n    joint_cols = [c for c in df.columns if c.startswith(\"joint_\")]\n    df[joint_cols] = df[joint_cols].astype(\"float32\")\n\n    # 2) surveys as categorical indices (already 0/1/2)\n    pain_survey_cols = [c for c in df.columns if c.startswith(\"pain_survey_\")]\n    df[pain_survey_cols] = df[pain_survey_cols].astype(\"int64\")\n\n    # 3) 2-way categoricals ‚Üí indices\n    legs_map  = {\"two\": 0, \"one+peg_leg\": 1}\n    hands_map = {\"two\": 0, \"one+hook_hand\": 1}\n    eyes_map  = {\"two\": 0, \"one+eye_patch\": 1}\n\n    if \"n_legs\" in df.columns:\n        df[\"n_legs\"]  = df[\"n_legs\"].map(legs_map).astype(\"int64\")\n    if \"n_hands\" in df.columns:\n        df[\"n_hands\"] = df[\"n_hands\"].map(hands_map).astype(\"int64\")\n    if \"n_eyes\" in df.columns:\n        df[\"n_eyes\"]  = df[\"n_eyes\"].map(eyes_map).astype(\"int64\")\n\n    # 4) define columns\n    cat_two_cols = [c for c in [\"n_legs\",\"n_hands\",\"n_eyes\"] if c in df.columns]\n    cat_cols = pain_survey_cols + cat_two_cols\n    cont_cols = joint_cols  # keep only joints as continuous\n\n    # 5) cardinals for embeddings (compute on TRAIN ONLY in CV, reuse for VAL/TEST)\n    cardinals = {c: int(df[c].nunique()) for c in cat_cols}\n    # suggested tiny dims: 1 for binaries, 2 for 3-class surveys\n    emb_dims = {c: (1 if cardinals[c] == 2 else 2) for c in cat_cols}\n\n    meta = {\n        \"cont_cols\": cont_cols,\n        \"cat_cols\":  cat_cols,\n        \"cardinals\": cardinals,\n        \"emb_dims\":  emb_dims,\n        \"maps\": {\"n_legs\": legs_map, \"n_hands\": hands_map, \"n_eyes\": eyes_map},\n    }\n    return df, meta\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:32:55.177842Z","iopub.execute_input":"2025-11-11T23:32:55.178078Z","iopub.status.idle":"2025-11-11T23:32:55.189323Z","shell.execute_reply.started":"2025-11-11T23:32:55.178062Z","shell.execute_reply":"2025-11-11T23:32:55.188671Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualise the count of timestamps for each kind of pain\nplt.figure(figsize=(17, 5))\nsns.countplot(\n    x='label',\n    data=train_merge,\n    order=train_merge['label'].value_counts().index,\n    palette='tab10'\n)\n\n# Set the title of the plot\nplt.title('Label Timestamps')\n\n# Display the plot\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:32:55.189990Z","iopub.execute_input":"2025-11-11T23:32:55.190181Z","iopub.status.idle":"2025-11-11T23:32:55.468854Z","shell.execute_reply.started":"2025-11-11T23:32:55.190167Z","shell.execute_reply":"2025-11-11T23:32:55.467907Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count the number of timesteps per sample\nseq_lengths = train_merge.groupby(\"sample_index\").size()\n\n# Quick look\nprint(seq_lengths.describe())\n\nplt.figure(figsize=(8,4))\nsns.histplot(seq_lengths, bins=30, kde=True, color=\"skyblue\")\nplt.title(\"Distribution of Sequence Lengths\")\nplt.xlabel(\"Timesteps per Sequence\")\nplt.ylabel(\"Number of Sequences\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:32:55.471145Z","iopub.execute_input":"2025-11-11T23:32:55.471432Z","iopub.status.idle":"2025-11-11T23:32:55.704454Z","shell.execute_reply.started":"2025-11-11T23:32:55.471412Z","shell.execute_reply":"2025-11-11T23:32:55.703879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a function to inspect sensor data for a specific pain\ndef inspect_pain(pain, df, n_rows=120000):\n    # Filter the DataFrame for the specified pain and limit to 500 rows\n    joint_cols = [col for col in df.columns if col.startswith(\"joint_\")]\n    data = df[df['label'] == pain][joint_cols][:n_rows]\n\n    # Dynamically adjust figure height based on number of joints\n    fig_height = len(joint_cols) * 1  # keep proportions similar to your original\n    axis = data.plot(subplots=True, figsize=(17, fig_height), title=pain)\n\n    # Adjust legend position for each subplot\n    for ax in axis:\n        ax.legend(loc='lower right')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:32:55.705105Z","iopub.execute_input":"2025-11-11T23:32:55.705296Z","iopub.status.idle":"2025-11-11T23:32:55.709904Z","shell.execute_reply.started":"2025-11-11T23:32:55.705281Z","shell.execute_reply":"2025-11-11T23:32:55.709269Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inspect the sensor data for the activity \"Standing\"\ninspect_pain(\"no_pain\", train_merge)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:32:55.710623Z","iopub.execute_input":"2025-11-11T23:32:55.710802Z","iopub.status.idle":"2025-11-11T23:33:01.755309Z","shell.execute_reply.started":"2025-11-11T23:32:55.710788Z","shell.execute_reply":"2025-11-11T23:33:01.754499Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inspect the sensor data for the activity \"Standing\"\ninspect_pain(\"low_pain\", train_merge, 15000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:01.756150Z","iopub.execute_input":"2025-11-11T23:33:01.756386Z","iopub.status.idle":"2025-11-11T23:33:06.871882Z","shell.execute_reply.started":"2025-11-11T23:33:01.756346Z","shell.execute_reply":"2025-11-11T23:33:06.871098Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inspect the sensor data for the activity \"Standing\"\ninspect_pain(\"high_pain\", train_merge, 12000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:06.872911Z","iopub.execute_input":"2025-11-11T23:33:06.873141Z","iopub.status.idle":"2025-11-11T23:33:11.638202Z","shell.execute_reply.started":"2025-11-11T23:33:06.873124Z","shell.execute_reply":"2025-11-11T23:33:11.637346Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_joints(df, \n                      drop_redundant=False, \n                      drop_near_zero=False, \n                      drop_low_var=False,\n                      verbose=True):\n    \"\"\"\n    Simplify joint_* preprocessing based on EDA results.\n    Removes constant, redundant, or near-zero-variance joints.\n\n    Returns a (df_out, feature_cols) tuple.\n    \"\"\"\n    joint_cols = sorted([c for c in df.columns if c.startswith(\"joint_\")],\n                        key=lambda x: int(x.split(\"_\")[1]))\n    drop = set()\n\n    # 1 Drop constant joint_30\n    if \"joint_30\" in joint_cols:\n        drop.add(\"joint_30\")\n\n    #  Drop redundant joints (from correlation heatmap)\n    if drop_redundant:\n        for c in [\"joint_01\", \"joint_02\", \"joint_05\"]:\n            if c in joint_cols:\n                drop.add(c)\n\n    # Drop near-zero variance joints (joint_13‚Äì25)\n    if drop_near_zero:\n        for i in range(13, 26):\n            c = f\"joint_{i:02d}\"\n            if c in joint_cols:\n                drop.add(c)\n\n    # (Optional) Drop low-variance but not-zero joints (joint_26‚Äì29)\n    if drop_low_var:\n        for i in range(26, 30):\n            c = f\"joint_{i:02d}\"\n            if c in joint_cols:\n                drop.add(c)\n\n    # apply\n    kept = [c for c in joint_cols if c not in drop]\n    df_out = df.drop(columns=list(drop), errors=\"ignore\")\n\n    if verbose:\n        print(f\"[preprocess_joints] start={len(joint_cols)} | kept={len(kept)} | dropped={len(drop)}\")\n        if drop:\n            print(\"  ‚Ä¢ dropped:\", sorted(list(drop)))\n\n    return df_out, kept\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:11.639314Z","iopub.execute_input":"2025-11-11T23:33:11.639688Z","iopub.status.idle":"2025-11-11T23:33:11.647299Z","shell.execute_reply.started":"2025-11-11T23:33:11.639653Z","shell.execute_reply":"2025-11-11T23:33:11.646646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, _ = preprocess_joints(X_train)\nX_test, _ = preprocess_joints(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:11.648195Z","iopub.execute_input":"2025-11-11T23:33:11.648533Z","iopub.status.idle":"2025-11-11T23:33:11.700112Z","shell.execute_reply.started":"2025-11-11T23:33:11.648516Z","shell.execute_reply":"2025-11-11T23:33:11.699242Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üîÑ **Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"# 1) Fit preprocessing on TRAIN ONLY\nX_train, meta = dataset_conversion_type_embed_ready(X_train)\n\n# 2) Apply the SAME mappings/cardinals to TEST\n#    (pain_survey_* are already 0/1/2; for n_legs/hands/eyes we reuse meta[\"maps\"])\nX_test = X_test.copy()\nfor c, m in meta[\"maps\"].items():\n    if c in X_test.columns:\n        X_test[c] = X_test[c].map(m).astype(\"int64\")\n\n# Cast types consistently with train\nX_test[meta[\"cont_cols\"]] = X_test[meta[\"cont_cols\"]].astype(\"float32\")\nfor c in meta[\"cat_cols\"]:\n    X_test[c] = X_test[c].astype(\"int64\")\n\n# 3) Sanity checks\nprint(\"Train cont/cat:\", len(meta[\"cont_cols\"]), len(meta[\"cat_cols\"]))\nprint(\"Train cont cols:\", meta[\"cont_cols\"][:5], \"‚Ä¶\")\nprint(\"Train cat  cols:\", meta[\"cat_cols\"])\nprint(\"Test has all cont cols?\", set(meta[\"cont_cols\"]).issubset(X_test.columns))\nprint(\"Test has all cat  cols?\", set(meta[\"cat_cols\"]).issubset(X_test.columns))\n\n# Optional: verify cardinalities didn‚Äôt explode on test (should be ‚â§ train)\nfor c in meta[\"cat_cols\"]:\n    tr_card = meta[\"cardinals\"][c]\n    te_card = int(X_test[c].nunique())\n    if te_card > tr_card:\n        print(f\"WARNING: column {c} has unseen categories in TEST (train={tr_card}, test={te_card})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:11.701099Z","iopub.execute_input":"2025-11-11T23:33:11.701341Z","iopub.status.idle":"2025-11-11T23:33:11.862958Z","shell.execute_reply.started":"2025-11-11T23:33:11.701323Z","shell.execute_reply":"2025-11-11T23:33:11.862258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1 ‚Äî Copy merged train and raw test\ntrain_dataset = X_train.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:11.863630Z","iopub.execute_input":"2025-11-11T23:33:11.863882Z","iopub.status.idle":"2025-11-11T23:33:11.893213Z","shell.execute_reply.started":"2025-11-11T23:33:11.863853Z","shell.execute_reply":"2025-11-11T23:33:11.892641Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# to reload quickly\nX_train = train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:11.893980Z","iopub.execute_input":"2025-11-11T23:33:11.894173Z","iopub.status.idle":"2025-11-11T23:33:11.898019Z","shell.execute_reply.started":"2025-11-11T23:33:11.894159Z","shell.execute_reply":"2025-11-11T23:33:11.897190Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train columns:\", X_train.columns.tolist())\nprint(\"Test columns:\", X_test.columns.tolist())\n\ntrain_only = [c for c in X_train.columns if c not in X_test.columns]\ntest_only  = [c for c in X_test.columns if c not in X_train.columns]\n\nif train_only or test_only:\n    print(\"Column mismatch detected!\")\n    if train_only:\n        print(\"  Present only in TRAIN:\", train_only)\n    if test_only:\n        print(\"  Present only in TEST:\", test_only)\nelse:\n    print(\"‚úÖ Train and Test have identical columns.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:11.898886Z","iopub.execute_input":"2025-11-11T23:33:11.899134Z","iopub.status.idle":"2025-11-11T23:33:11.910612Z","shell.execute_reply.started":"2025-11-11T23:33:11.899111Z","shell.execute_reply":"2025-11-11T23:33:11.909948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1. temporary merge X_train + y_train to create splits ---\ntrain_merged = X_train.merge(y_train, on=\"sample_index\")\nprint(train_merged.shape)\n\n# Step 2. retrieve unique indexes and labels to stratify ---\nunique_samples = train_merged['sample_index'].unique()\ny_seq = train_merged.groupby('sample_index')['label'].first().reindex(unique_samples).values\n\n# Step 3. Divide in train e val (stratified) ---\n\ntrain_idxs, val_idxs = train_test_split(unique_samples, test_size=0.20, random_state=SEED, stratify=y_seq)\nprint(f\"Train Size: {len(train_idxs)}, Val Size: {len(val_idxs)}, total: {len(train_idxs)+len(val_idxs)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:11.911251Z","iopub.execute_input":"2025-11-11T23:33:11.911457Z","iopub.status.idle":"2025-11-11T23:33:11.946385Z","shell.execute_reply.started":"2025-11-11T23:33:11.911443Z","shell.execute_reply":"2025-11-11T23:33:11.945657Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4. Apply split on X e y (separately) ---\ndf_train = train_merged[train_merged['sample_index'].isin(train_idxs)]\ndf_val   = train_merged[train_merged['sample_index'].isin(val_idxs)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:11.947117Z","iopub.execute_input":"2025-11-11T23:33:11.947415Z","iopub.status.idle":"2025-11-11T23:33:11.961914Z","shell.execute_reply.started":"2025-11-11T23:33:11.947396Z","shell.execute_reply":"2025-11-11T23:33:11.961375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# X: only features\nX_train = df_train.drop(columns=['label'])\nX_val   = df_val.drop(columns=['label'])\n\n# y: one label for each sequence\ny_train = df_train.groupby(\"sample_index\")[\"label\"].first().values\ny_val   = df_val.groupby(\"sample_index\")[\"label\"].first().values\n\nprint(f\"X_train shape: {X_train.shape}, X_val shape: {X_val.shape}\")\nprint(f\"y_train: {len(y_train)}, y_val: {len(y_val)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:11.962517Z","iopub.execute_input":"2025-11-11T23:33:11.962698Z","iopub.status.idle":"2025-11-11T23:33:11.984606Z","shell.execute_reply.started":"2025-11-11T23:33:11.962684Z","shell.execute_reply":"2025-11-11T23:33:11.983836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define mapping once\nlabel_mapping = {'no_pain': 0, 'low_pain': 1, 'high_pain': 2}\ninv_label_mapping = {v: k for k, v in label_mapping.items()}\n\n# Convert y_train/y_val from string ‚Üí int\ny_train = np.array([label_mapping[l] for l in y_train])\ny_val   = np.array([label_mapping[l] for l in y_val])\n\n# Compute label distributions\ntrain_counts = {inv_label_mapping[k]: np.sum(y_train == k) for k in np.unique(y_train)}\nval_counts   = {inv_label_mapping[k]: np.sum(y_val == k) for k in np.unique(y_val)}\n\nprint(\"Training labels:\", train_counts)\nprint(\"Validation labels:\", val_counts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:11.985522Z","iopub.execute_input":"2025-11-11T23:33:11.985747Z","iopub.status.idle":"2025-11-11T23:33:11.992072Z","shell.execute_reply.started":"2025-11-11T23:33:11.985720Z","shell.execute_reply":"2025-11-11T23:33:11.991412Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Normalisation","metadata":{}},{"cell_type":"code","source":"scale_columns = [col for col in X_train.columns if col.startswith(\"joint_\")]\n\n# calculate the minimum and maximum values from the training data only\nmins = X_train[scale_columns].min()\nmaxs = X_train[scale_columns].max()\n\n# apply normalisation to the specified columns in all datasets (training and validation)\nfor column in scale_columns:\n\n    # normalise the training set\n    X_train[column] = (X_train[column] - mins[column]) / (maxs[column] - mins[column])\n\n    # normalise the validation set\n    X_val[column] = (X_val[column] - mins[column]) / (maxs[column] - mins[column])\n\n    # normalise the test set\n    X_test[column] = (X_test[column] - mins[column]) / (maxs[column] - mins[column])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:11.992724Z","iopub.execute_input":"2025-11-11T23:33:11.992880Z","iopub.status.idle":"2025-11-11T23:33:12.062223Z","shell.execute_reply.started":"2025-11-11T23:33:11.992868Z","shell.execute_reply":"2025-11-11T23:33:12.061594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train:\", X_train[scale_columns].min().min(), \"‚Üí\", X_train[scale_columns].max().max())\nprint(\"Val:  \", X_val[scale_columns].min().min(),   \"‚Üí\", X_val[scale_columns].max().max())\nprint(\"Test: \", X_test[scale_columns].min().min(),   \"‚Üí\", X_test[scale_columns].max().max())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:12.062987Z","iopub.execute_input":"2025-11-11T23:33:12.063209Z","iopub.status.idle":"2025-11-11T23:33:12.143711Z","shell.execute_reply.started":"2025-11-11T23:33:12.063187Z","shell.execute_reply":"2025-11-11T23:33:12.143110Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the first five rows of the training DataFrame\nprint(X_train.shape, y_train.shape)\nprint(X_val.shape, y_val.shape)\n\nX_train, y_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:12.144449Z","iopub.execute_input":"2025-11-11T23:33:12.144731Z","iopub.status.idle":"2025-11-11T23:33:12.163880Z","shell.execute_reply.started":"2025-11-11T23:33:12.144708Z","shell.execute_reply":"2025-11-11T23:33:12.163294Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_sequences(\n    df: pd.DataFrame,\n    y: pd.DataFrame | np.ndarray | None = None,\n    window: int | None = None,\n    stride: int | None = None,\n    pad: bool = False,\n):\n    \"\"\" \n    Build sequences from the dataset, either:\n      - full-length per sample_index (when window/stride are None), or\n      - sliding windows with given window and stride.\n\n    Data assumptions for THIS notebook:\n      ‚Ä¢ df already normalized/mapped (categoricals numeric; e.g., n_legs/hands/eyes ‚àà {0,1})\n      ‚Ä¢ df has columns: ['sample_index','time', joint_*, pain_survey_*, n_legs, n_hands, n_eyes]\n      ‚Ä¢ each sample_index has T=160 rows (fixed-length), but we still allow windowing/stride\n\n    Returns:\n        dataset: np.ndarray of shape (N,T,F) or (N,window,F)\n        labels:  np.ndarray of shape (N,) if y is provided, else None\n    \"\"\"\n    # ------------------------------------------------------------------\n    # Feature groups (already numeric at this stage)\n    joint_cols  = [c for c in df.columns if c.startswith('joint_')]\n    pain_cols   = [c for c in df.columns if c.startswith('pain_survey_')]\n    static_cols = [c for c in ['n_legs', 'n_hands', 'n_eyes'] if c in df.columns]\n\n    # Keep only the necessary columns in a copy; preserve order\n    cols_needed = ['sample_index', 'time'] + joint_cols + pain_cols + static_cols\n    df = df[cols_needed].copy()\n\n    # Sort to preserve chronological order within each sequence\n    df = df.sort_values([\"sample_index\", \"time\"])\n\n    # If labels are provided, build a lookup dictionary: sample_index ‚Üí label\n    label_dict = None\n    if y is not None:\n        if isinstance(y, np.ndarray):\n            # Build mapping using the unique order of sample_index in df\n            unique_ids = df[\"sample_index\"].unique()\n            label_dict = {sid: int(lbl) for sid, lbl in zip(unique_ids, y)}\n        elif isinstance(y, pd.DataFrame):\n            # Expect columns ['sample_index','label'] with already-int-mapped labels\n            label_dict = dict(zip(y[\"sample_index\"], y[\"label\"]))\n\n    # Prepare outputs\n    dataset = []\n    labels  = []\n\n    # If no window/stride provided ‚Üí fall back to full-length per sequence\n    full_length_mode = (window is None or stride is None)\n\n    # Iterate over each sequence\n    for sid, group in df.groupby(\"sample_index\", sort=False):\n        # --- Extract groups (already numeric) ---\n        X_joints = group[joint_cols].to_numpy(dtype=np.float32)        # (T, J)\n\n        # Current path: use pain_survey_* as numeric features (already mapped)\n        X_pain = group[pain_cols].to_numpy(dtype=np.float32)            # (T, 4)\n\n        # Static features are numeric 0/1 but vary by row; we keep them as provided\n        X_static = group[static_cols].to_numpy(dtype=np.float32) if static_cols else None  # (T, 3) or None\n\n        # Concatenate all feature groups along last dimension\n        if X_static is not None:\n            X_full = np.concatenate([X_joints, X_pain, X_static], axis=1)  # (T, F_total)\n        else:\n            X_full = np.concatenate([X_joints, X_pain], axis=1)            # (T, F_total)\n\n        T = X_full.shape[0]\n\n        if full_length_mode:\n            # ----- FULL-LENGTH MODE -----\n            dataset.append(X_full)\n            if label_dict is not None and sid in label_dict:\n                labels.append(int(label_dict[sid]))\n        else:\n            # ----- WINDOWED MODE (window, stride) -----\n            W = int(window)\n            S = int(stride)\n            assert W > 0 and S > 0, \"window and stride must be positive integers\"\n\n            if pad and T % W != 0:\n                # pad at the end with zeros to allow the last partial window\n                pad_len = (W - (T % W)) % W\n                if pad_len > 0:\n                    X_pad = np.zeros((pad_len, X_full.shape[1]), dtype=np.float32)\n                    X_seq = np.concatenate([X_full, X_pad], axis=0)\n                else:\n                    X_seq = X_full\n                Tmax = X_seq.shape[0]\n                idx = 0\n                while idx + W <= Tmax:\n                    dataset.append(X_seq[idx:idx+W])\n                    if label_dict is not None and sid in label_dict:\n                        labels.append(int(label_dict[sid]))\n                    idx += S\n            else:\n                # no padding ‚Üí only windows fully inside the sequence\n                idx = 0\n                while idx + W <= T:\n                    dataset.append(X_full[idx:idx+W])\n                    if label_dict is not None and sid in label_dict:\n                        labels.append(int(label_dict[sid]))\n                    idx += S\n\n    # Convert to numpy arrays\n    dataset = np.asarray(dataset, dtype=np.float32) if len(dataset) > 0 else np.empty((0, 0, 0), dtype=np.float32)\n    labels  = np.asarray(labels,  dtype=np.int64)   if len(labels)  > 0 else None\n\n    if dataset.size > 0:\n        print(f\"Built {len(dataset)} sequence{'s' if len(dataset)!=1 else ''}; each shape = {dataset[0].shape}\")\n    else:\n        print(\"Built 0 sequences (check window/stride vs sequence length).\")\n\n    return dataset, labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:12.167847Z","iopub.execute_input":"2025-11-11T23:33:12.168027Z","iopub.status.idle":"2025-11-11T23:33:12.181413Z","shell.execute_reply.started":"2025-11-11T23:33:12.168014Z","shell.execute_reply":"2025-11-11T23:33:12.180779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- ACF-DRIVEN WINDOWING (drop-in) ---------------------------------\n# Goal:\n#   Use autocorrelation (ACF) to pick a WINDOW_SIZE (W) and STRIDE (S)\n#   that reflect how far the signal ‚Äúremembers‚Äù its past.\n#\n# Design choices:\n#   ‚Ä¢ We use ONLY joint_* signals (continuous), excluding pain_survey_* and\n#     static cats (n_legs/hands/eyes), because ACF is meaningful for\n#     continuous, time-varying signals. Surveys/cats would distort it.\n#   ‚Ä¢ We compute ACF per joint, per sequence, then average to get a robust\n#     \"mean ACF\" over the dataset (train only ‚Üí no leakage).\n#   ‚Ä¢ From the mean ACF curve we pick W via a simple heuristic:\n#       1) first local peak (a natural cycle length)\n#       2) else, first lag where ACF falls below a cutoff (memory fades)\n#     then clamp to a safe lower bound (min_window) and snap to multiple of 4.\n#\n# How to read the outputs:\n#   ‚Ä¢ W_SUGG = suggested window (steps of lookback the model should \"see\")\n#   ‚Ä¢ S_SUGG = suggested stride (step between window starts; default W//4)\n#   ‚Ä¢ n_windows = number of windows per sequence with length T=160\n#   ‚Ä¢ covered_steps = n_windows * W  (overlaps ‚Üí can exceed T)\n#\n# Keep in mind:\n#   ‚Ä¢ This is NOT a replacement for cross-validation. Use CV to compare\n#     W in a small neighborhood (e.g., W, W¬±4 or W¬±8) and keep what wins.\n# ---------------------------------------------------------------------\n\ndef _acf_1d(x: np.ndarray, max_lag: int) -> np.ndarray:\n    \"\"\"\n    Compute the autocorrelation function (ACF) for a 1D vector up to `max_lag`.\n\n    Steps:\n      1) Normalize x to zero-mean and unit-variance so the ACF is scale-free.\n      2) Use np.correlate in 'full' mode to get correlation at all lags.\n      3) Slice the non-negative lags [0..max_lag].\n      4) Normalize by acf[0] (the variance) so ACF[0] == 1 and 0<=ACF<=1 (approx).\n\n    Args:\n      x (np.ndarray): 1D time series (length T)\n      max_lag (int): maximum lag we want to evaluate (<= T-1)\n\n    Returns:\n      acf (np.ndarray): shape (max_lag+1,), acf[0]=1, acf[k]=similarity at lag k\n    \"\"\"\n    x = x.astype(np.float64)\n    x = (x - x.mean()) / (x.std() + 1e-8)      # protect from near-constant series\n    acf_full = np.correlate(x, x, mode='full') # length 2T-1\n    # Keep the right half: lags 0..max_lag (index starts at the center)\n    acf = acf_full[len(x)-1 : len(x)-1 + max_lag + 1]\n    # Normalize so that ACF[0] == 1 (divide by variance term)\n    return acf / (acf[0] + 1e-8)\n\ndef mean_acf_over_joints(df, max_lag=80, sample_cap=256):\n    \"\"\"\n    Compute the MEAN ACF across joints and (optionally) across a subset\n    of sequences for speed. This gives a single, smooth ACF curve.\n\n    Expected df columns:\n      ‚Ä¢ 'sample_index', 'time', and many 'joint_*' columns\n\n    Process:\n      For each sequence (sample_index):\n        - sort by time\n        - build a (T, J) matrix of joint features\n        - for each joint j, compute ACF_j[0..L] where L = min(max_lag, T-1)\n        - average ACF over joints ‚Üí one curve per sequence\n      Average all sequence curves ‚Üí mean ACF\n\n    Why average?\n      Reduces noise and avoids picking a window based on a single joint\n      or a single quirky sequence.\n\n    Args:\n      df (DataFrame): TRAIN subset only (to avoid leakage)\n      max_lag (int): maximum lag we consider (e.g., 80)\n      sample_cap (int): if many sequences, randomly subsample this many\n                        to keep runtime small\n\n    Returns:\n      lags (np.ndarray): [0, 1, ..., L]\n      mean_acf (np.ndarray): averaged ACF curve, length L+1\n    \"\"\"\n    joint_cols = [c for c in df.columns if c.startswith(\"joint_\")]\n    assert len(joint_cols) > 0, \"No joint_* columns found.\"\n\n    # Subsample sequences if needed (for speed on large datasets)\n    sids = df[\"sample_index\"].unique()\n    if len(sids) > sample_cap:\n        rng = np.random.default_rng(42)\n        sids = rng.choice(sids, size=sample_cap, replace=False)\n\n    acfs = []\n    for sid in sids:\n        # (T, J) matrix for this sequence\n        seq = (df.loc[df[\"sample_index\"] == sid]\n                 .sort_values(\"time\")[joint_cols].to_numpy(dtype=np.float32))\n        T, J = seq.shape\n        L = min(max_lag, T - 1)  # ACF defined up to T-1\n        # ACF for each joint, then average across joints ‚Üí one curve per sequence\n        per_joint = []\n        for j in range(J):\n            per_joint.append(_acf_1d(seq[:, j], L))  # shape (L+1,)\n        acfs.append(np.mean(np.stack(per_joint, axis=0), axis=0))  # (L+1,)\n\n    # Average across sequences ‚Üí single smooth ACF curve\n    mean_acf = np.mean(np.stack(acfs, axis=0), axis=0)  # (L+1,)\n    lags = np.arange(len(mean_acf))\n    return lags, mean_acf\n\ndef suggest_window_from_acf(mean_acf: np.ndarray, min_window=12, cutoff=0.10):\n    \"\"\"\n    Heuristic to convert the mean ACF curve into a WINDOW_SIZE (W).\n\n    Intuition:\n      ‚Ä¢ If there's a visible \"cycle\", the ACF will have a local peak at its period.\n        ‚Üí pick the first local maximum after lag=1 (we ignore lag=0..1).\n      ‚Ä¢ If no clear peak, use the lag where correlation \"dies out\" (drops < cutoff).\n        ‚Üí pick first lag where ACF < cutoff (e.g., 0.10).\n      ‚Ä¢ Clamp to a minimum window (min_window) so we don't get too tiny a W.\n      ‚Ä¢ Snap to a multiple of 4 to make stride W//4 an integer (nice, common choice).\n\n    Args:\n      mean_acf (np.ndarray): curve from mean_acf_over_joints\n      min_window (int): lower bound to keep W usable for training (default 12)\n      cutoff (float): ACF threshold for \"memory fades\" (default 0.10)\n\n    Returns:\n      W (int): suggested window size\n    \"\"\"\n    # 1) Look for the first local MAX after lag=1 (i.e., k >= 2)\n    peak_lag = None\n    for k in range(2, len(mean_acf) - 1):\n        # local max if it is >= next and > previous\n        if mean_acf[k] > mean_acf[k - 1] and mean_acf[k] >= mean_acf[k + 1]:\n            peak_lag = k\n            break\n\n    # 2) First lag where ACF falls below cutoff (correlation has faded)\n    below = np.where(mean_acf < cutoff)[0]\n    drop_lag = int(below[0]) if len(below) else None\n\n    # Combine signals (prefer a peak if present, else use drop)\n    if peak_lag is not None and drop_lag is not None:\n        # keep it within [min_window, drop_lag]\n        W = min(max(peak_lag, min_window), drop_lag)\n    elif peak_lag is not None:\n        W = max(peak_lag, min_window)\n    elif drop_lag is not None:\n        W = max(drop_lag, min_window)\n    else:\n        # No clear info ‚Üí conservative fallback\n        W = max(24, min_window)\n\n    # Safety clamp within [min_window, 160] (your T=160)\n    W = int(np.clip(W, min_window, 160))\n\n    # Snap to multiple of 4 so stride = W//4 is an integer\n    if W % 4 != 0:\n        W += (4 - (W % 4))\n    return W\n\ndef suggest_stride(window: int) -> int:\n    \"\"\"\n    Default stride choice: quarter window.\n    Why? Good balance between:\n      - enough overlap to preserve information\n      - not exploding the number of windows too much\n    \"\"\"\n    return max(1, window // 4)\n\n# ---- RUN IT ON YOUR TRAIN DF (after normalization/mapping) ----------\n# NOTE: Use df_train (TRAIN SPLIT ONLY) to avoid leaking validation info.\nlags, mean_acf = mean_acf_over_joints(df_train, max_lag=80, sample_cap=256)\n\n# Heuristic suggestions from ACF\nW_SUGG = suggest_window_from_acf(mean_acf, min_window=12, cutoff=0.10)\nS_SUGG = suggest_stride(W_SUGG)\n\nprint(f\"[ACF] Suggested WINDOW_SIZE={W_SUGG}, STRIDE={S_SUGG}\")\n\n# Optional: coverage diagnostic for your fixed T=160\nT = 160\nn_windows = (T - W_SUGG) // S_SUGG + 1 if T >= W_SUGG else 0\ncovered = n_windows * W_SUGG  # can exceed T because windows overlap\nprint(f\"[ACF] With T={T}: n_windows={n_windows}, covered_steps={covered}/{T}\")\n# --------------------------------------------------------------------","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:12.182106Z","iopub.execute_input":"2025-11-11T23:33:12.182373Z","iopub.status.idle":"2025-11-11T23:33:12.821200Z","shell.execute_reply.started":"2025-11-11T23:33:12.182334Z","shell.execute_reply":"2025-11-11T23:33:12.820563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# y_train_df must contain sample_index + label columns\ny_train_df = pd.DataFrame({\n    \"sample_index\": X_train[\"sample_index\"].unique(),\n    \"label\": y_train\n})\n\nX_train_seq_complete_window, y_train_seq_complete_window = build_sequences(X_train, y_train_df, window=160)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:12.821933Z","iopub.execute_input":"2025-11-11T23:33:12.822200Z","iopub.status.idle":"2025-11-11T23:33:13.316971Z","shell.execute_reply.started":"2025-11-11T23:33:12.822174Z","shell.execute_reply":"2025-11-11T23:33:13.316322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_val_df = pd.DataFrame({\n    \"sample_index\": X_val[\"sample_index\"].unique(),\n    \"label\": y_val\n})\n\nX_val_seq_complete_window, y_val_seq_complete_window = build_sequences(X_val, y_val_df, 160)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:13.317658Z","iopub.execute_input":"2025-11-11T23:33:13.317936Z","iopub.status.idle":"2025-11-11T23:33:13.448717Z","shell.execute_reply.started":"2025-11-11T23:33:13.317919Z","shell.execute_reply":"2025-11-11T23:33:13.448156Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_seq_complete_window, _ = build_sequences(X_test, window=160)  # no labels ‚Üí returns (dataset, None)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:13.449331Z","iopub.execute_input":"2025-11-11T23:33:13.449540Z","iopub.status.idle":"2025-11-11T23:33:14.757671Z","shell.execute_reply.started":"2025-11-11T23:33:13.449525Z","shell.execute_reply":"2025-11-11T23:33:14.756842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_tr_win, y_tr_win = build_sequences(X_train, y_train, window=W_SUGG, stride=S_SUGG, pad=False)\nX_va_win, y_va_win = build_sequences(X_val,y_val, window=W_SUGG, stride=S_SUGG, pad=False)\nX_te_win, _        = build_sequences(X_test,None, window=W_SUGG, stride=S_SUGG, pad=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:14.758503Z","iopub.execute_input":"2025-11-11T23:33:14.758782Z","iopub.status.idle":"2025-11-11T23:33:16.786062Z","shell.execute_reply.started":"2025-11-11T23:33:14.758758Z","shell.execute_reply":"2025-11-11T23:33:16.785408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_shape = X_tr_win.shape[1:] # extract the shape of a single sequence\nnum_classes = len(np.unique(y_tr_win)) # how many unique pain level exists\ninput_shape, num_classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:16.786692Z","iopub.execute_input":"2025-11-11T23:33:16.786869Z","iopub.status.idle":"2025-11-11T23:33:16.792435Z","shell.execute_reply.started":"2025-11-11T23:33:16.786856Z","shell.execute_reply":"2025-11-11T23:33:16.791846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert numpy arrays to PyTorch datasets (pairs features with labels)\n# each dataset now pairs each (T,F) TENSOR WITH ITS LABEL\ntrain_ds = TensorDataset(torch.from_numpy(X_tr_win), torch.from_numpy(y_tr_win))\nval_ds   = TensorDataset(torch.from_numpy(X_va_win), torch.from_numpy(y_va_win))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:16.793050Z","iopub.execute_input":"2025-11-11T23:33:16.793207Z","iopub.status.idle":"2025-11-11T23:33:16.807914Z","shell.execute_reply.started":"2025-11-11T23:33:16.793195Z","shell.execute_reply":"2025-11-11T23:33:16.807158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the batch size, which is the number of samples in each batch\nBATCH_SIZE = 128","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:16.808632Z","iopub.execute_input":"2025-11-11T23:33:16.808864Z","iopub.status.idle":"2025-11-11T23:33:16.818420Z","shell.execute_reply.started":"2025-11-11T23:33:16.808840Z","shell.execute_reply":"2025-11-11T23:33:16.817860Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_loader(ds, batch_size, shuffle, drop_last):\n    # Determine optimal number of worker processes for data loading\n    cpu_cores = os.cpu_count() or 2\n    num_workers = max(2, min(4, cpu_cores))\n\n    # Create DataLoader with performance optimizations\n    return DataLoader(\n        ds,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        drop_last=drop_last,\n        num_workers=num_workers,\n        pin_memory=True,  # Faster GPU transfer\n        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n        prefetch_factor=4,  # Load 4 batches aheads\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:16.819069Z","iopub.execute_input":"2025-11-11T23:33:16.819294Z","iopub.status.idle":"2025-11-11T23:33:16.829933Z","shell.execute_reply.started":"2025-11-11T23:33:16.819274Z","shell.execute_reply":"2025-11-11T23:33:16.829399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create data loaders with different settings for each phase\ntrain_loader = make_loader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\nval_loader   = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:16.830732Z","iopub.execute_input":"2025-11-11T23:33:16.831197Z","iopub.status.idle":"2025-11-11T23:33:16.841274Z","shell.execute_reply.started":"2025-11-11T23:33:16.831175Z","shell.execute_reply":"2025-11-11T23:33:16.840592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get one batch from the training data loader\nfor xb, yb in train_loader:\n    print(\"Features batch shape:\", xb.shape)\n    print(\"Labels batch shape:\", yb.shape)\n    break # Stop after getting one batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:16.842067Z","iopub.execute_input":"2025-11-11T23:33:16.842317Z","iopub.status.idle":"2025-11-11T23:33:17.067261Z","shell.execute_reply.started":"2025-11-11T23:33:16.842294Z","shell.execute_reply":"2025-11-11T23:33:17.066390Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üõ†Ô∏è **Model Building**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ClassAwareLabelSmoothing(nn.Module):\n    \"\"\"\n    Implements BOTH professor's advice:\n    - Advice 08/11: Class weights (errors on rare classes weighted higher)\n    - Advice 09/11: Label smoothing (prevents overconfidence)\n    \"\"\"\n    def __init__(self, num_classes=3, smoothing_per_class=None, class_weights=None):\n        super().__init__()\n        self.num_classes = num_classes\n        \n        # Label smoothing per class (Advice 09/11)\n        if smoothing_per_class is None:\n            # More smoothing for majority, less for minority\n            smoothing_per_class = [0.15, 0.05, 0.02]\n        self.smoothing = smoothing_per_class\n        \n        # Class weights (Advice 08/11) - NEW!\n        if class_weights is None:\n            # Calculate inverse frequency weights\n            # Your distribution: 408:75:45 = 77%:14%:9%\n            # Weights: [1.0, 408/75, 408/45] ‚âà [1.0, 5.4, 9.1]\n            class_weights = torch.tensor([1.0, 5.44, 9.07])\n        else:\n            class_weights = torch.tensor(class_weights)\n        \n        # Register as buffer (moves with model to GPU)\n        self.register_buffer('class_weights', class_weights)\n    \n    def forward(self, pred, target):\n        \"\"\"\n        Args:\n            pred: logits [batch_size, num_classes]\n            target: true labels [batch_size] (integers 0,1,2)\n        \"\"\"\n        log_probs = F.log_softmax(pred, dim=-1)\n        batch_size = target.size(0)\n        \n        # Create smooth targets per sample based on its true class\n        smooth_targets = torch.zeros_like(pred)\n        sample_weights = torch.zeros(batch_size, device=pred.device)\n        \n        for i in range(batch_size):\n            true_class = target[i].item()\n            smoothing = self.smoothing[true_class]\n            confidence = 1.0 - smoothing\n            \n            # Distribute smoothing uniformly across other classes\n            smooth_targets[i].fill_(smoothing / (self.num_classes - 1))\n            smooth_targets[i, true_class] = confidence\n            \n            # Apply class weight (NEW! - Advice 08/11)\n            sample_weights[i] = self.class_weights[true_class]\n        \n        # Compute loss with class weights applied per sample\n        per_sample_loss = -(smooth_targets * log_probs).sum(dim=-1)\n        weighted_loss = (per_sample_loss * sample_weights).mean()\n        \n        return weighted_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:17.068310Z","iopub.execute_input":"2025-11-11T23:33:17.068574Z","iopub.status.idle":"2025-11-11T23:33:17.077107Z","shell.execute_reply.started":"2025-11-11T23:33:17.068551Z","shell.execute_reply":"2025-11-11T23:33:17.076317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def recurrent_summary(model, input_size):\n    \"\"\"\n    Custom summary function that emulates torchinfo's output while correctly\n    counting parameters for RNN/GRU/LSTM layers.\n\n    This function is designed for models whose direct children are\n    nn.Linear, nn.RNN, nn.GRU, or nn.LSTM layers.\n\n    Args:\n        model (nn.Module): The model to analyze.\n        input_size (tuple): Shape of the input tensor (e.g., (seq_len, features)).\n    \"\"\"\n\n    # Dictionary to store output shapes captured by forward hooks\n    output_shapes = {}\n    # List to track hook handles for later removal\n    hooks = []\n\n    def get_hook(name):\n        \"\"\"Factory function to create a forward hook for a specific module.\"\"\"\n        def hook(module, input, output):\n            # Handle RNN layer outputs (returns a tuple)\n            if isinstance(output, tuple):\n                # output[0]: all hidden states with shape (batch, seq_len, hidden*directions)\n                shape1 = list(output[0].shape)\n                shape1[0] = -1  # Replace batch dimension with -1\n\n                # output[1]: final hidden state h_n (or tuple (h_n, c_n) for LSTM)\n                if isinstance(output[1], tuple):  # LSTM case: (h_n, c_n)\n                    shape2 = list(output[1][0].shape)  # Extract h_n only\n                else:  # RNN/GRU case: h_n only\n                    shape2 = list(output[1].shape)\n\n                # Replace batch dimension (middle position) with -1\n                shape2[1] = -1\n\n                output_shapes[name] = f\"[{shape1}, {shape2}]\"\n\n            # Handle standard layer outputs (e.g., Linear)\n            else:\n                shape = list(output.shape)\n                shape[0] = -1  # Replace batch dimension with -1\n                output_shapes[name] = f\"{shape}\"\n        return hook\n\n    # 1. Determine the device where model parameters reside\n    try:\n        device = next(model.parameters()).device\n    except StopIteration:\n        device = torch.device(\"cpu\")  # Fallback for models without parameters\n\n    # 2. Create a dummy input tensor with batch_size=1\n    dummy_input = torch.randn(1, *input_size).to(device)\n\n    # 3. Register forward hooks on target layers\n    # Iterate through direct children of the model (e.g., self.rnn, self.classifier)\n    for name, module in model.named_children():\n        if isinstance(module, (nn.Linear, nn.RNN, nn.GRU, nn.LSTM)):\n            # Register the hook and store its handle for cleanup\n            hook_handle = module.register_forward_hook(get_hook(name))\n            hooks.append(hook_handle)\n\n    # 4. Execute a dummy forward pass in evaluation mode\n    model.eval()\n    with torch.no_grad():\n        try:\n            model(dummy_input)\n        except Exception as e:\n            print(f\"Error during dummy forward pass: {e}\")\n            # Clean up hooks even if an error occurs\n            for h in hooks:\n                h.remove()\n            return\n\n    # 5. Remove all registered hooks\n    for h in hooks:\n        h.remove()\n\n    # --- 6. Print the summary table ---\n\n    print(\"-\" * 79)\n    # Column headers\n    print(f\"{'Layer (type)':<25} {'Output Shape':<28} {'Param #':<18}\")\n    print(\"=\" * 79)\n\n    total_params = 0\n    total_trainable_params = 0\n\n    # Iterate through modules again to collect and display parameter information\n    for name, module in model.named_children():\n        if name in output_shapes:\n            # Count total and trainable parameters for this module\n            module_params = sum(p.numel() for p in module.parameters())\n            trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n\n            total_params += module_params\n            total_trainable_params += trainable_params\n\n            # Format strings for display\n            layer_name = f\"{name} ({type(module).__name__})\"\n            output_shape_str = str(output_shapes[name])\n            params_str = f\"{trainable_params:,}\"\n\n            print(f\"{layer_name:<25} {output_shape_str:<28} {params_str:<15}\")\n\n    print(\"=\" * 79)\n    print(f\"Total params: {total_params:,}\")\n    print(f\"Trainable params: {total_trainable_params:,}\")\n    print(f\"Non-trainable params: {total_params - total_trainable_params:,}\")\n    print(\"-\" * 79)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:17.077951Z","iopub.execute_input":"2025-11-11T23:33:17.078205Z","iopub.status.idle":"2025-11-11T23:33:17.094325Z","shell.execute_reply.started":"2025-11-11T23:33:17.078182Z","shell.execute_reply":"2025-11-11T23:33:17.093716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RecurrentClassifier(nn.Module):\n    \"\"\"\n    Generic RNN classifier (RNN, LSTM, GRU).\n    Uses the last hidden state for classification.\n    \"\"\"\n    def __init__(\n            self,\n            input_size,\n            hidden_size,\n            num_layers,\n            num_classes,\n            rnn_type='GRU',        # 'RNN', 'LSTM', or 'GRU'\n            bidirectional=False,\n            dropout_rate=0.2\n            ):\n        super().__init__()\n\n        self.rnn_type = rnn_type\n        self.num_layers = num_layers\n        self.hidden_size = hidden_size\n        self.bidirectional = bidirectional\n\n        # Map string name to PyTorch RNN class\n        rnn_map = {\n            'RNN': nn.RNN,\n            'LSTM': nn.LSTM,\n            'GRU': nn.GRU\n        }\n\n        if rnn_type not in rnn_map:\n            raise ValueError(\"rnn_type must be 'RNN', 'LSTM', or 'GRU'\")\n\n        rnn_module = rnn_map[rnn_type]\n\n        # Dropout is only applied between layers (if num_layers > 1)\n        dropout_val = dropout_rate if num_layers > 1 else 0\n\n        # Create the recurrent layer\n        self.rnn = rnn_module(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,       # Input shape: (batch, seq_len, features)\n            bidirectional=bidirectional,\n            dropout=dropout_val\n        )\n\n        # Calculate input size for the final classifier\n        if self.bidirectional:\n            classifier_input_size = hidden_size * 2 # Concat fwd + bwd\n        else:\n            classifier_input_size = hidden_size\n\n        # Final classification layer\n        self.classifier = nn.Linear(classifier_input_size, num_classes)\n\n    def forward(self, x):\n        \"\"\"\n        x shape: (batch_size, seq_length, input_size)\n        \"\"\"\n\n        # rnn_out shape: (batch_size, seq_len, hidden_size * num_directions)\n        rnn_out, hidden = self.rnn(x)\n\n        # LSTM returns (h_n, c_n), we only need h_n\n        if self.rnn_type == 'LSTM':\n            hidden = hidden[0]\n\n        # hidden shape: (num_layers * num_directions, batch_size, hidden_size)\n\n        if self.bidirectional:\n            # Reshape to (num_layers, 2, batch_size, hidden_size)\n            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n\n            # Concat last fwd (hidden[-1, 0, ...]) and bwd (hidden[-1, 1, ...])\n            # Final shape: (batch_size, hidden_size * 2)\n            hidden_to_classify = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n        else:\n            # Take the last layer's hidden state\n            # Final shape: (batch_size, hidden_size)\n            hidden_to_classify = hidden[-1]\n\n        # Get logits\n        logits = self.classifier(hidden_to_classify)\n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:17.095041Z","iopub.execute_input":"2025-11-11T23:33:17.095209Z","iopub.status.idle":"2025-11-11T23:33:17.108895Z","shell.execute_reply.started":"2025-11-11T23:33:17.095194Z","shell.execute_reply":"2025-11-11T23:33:17.108130Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üß† **Model Training**","metadata":{}},{"cell_type":"code","source":"# Initialize best model tracking variables\nbest_model = None\nbest_performance = float('-inf')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:17.109632Z","iopub.execute_input":"2025-11-11T23:33:17.109854Z","iopub.status.idle":"2025-11-11T23:33:17.122256Z","shell.execute_reply.started":"2025-11-11T23:33:17.109835Z","shell.execute_reply":"2025-11-11T23:33:17.121551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_epoch(model, train_loader, criterion, optimizer, scaler, \n                    device, l1_lambda=0, l2_lambda=0,max_grad_norm=1.0):\n    \"\"\"\n    Perform one complete training epoch through the entire training dataset.\n\n    Args:\n        model (nn.Module): The neural network model to train\n        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n        l1_lambda (float): Lambda for L1 regularization\n        l2_lambda (float): Lambda for L2 regularization\n\n    Returns:\n        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n    \"\"\"\n    model.train()  # Set model to training mode\n\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n\n    # Iterate through training batches\n    for batch_idx, (inputs, targets) in enumerate(train_loader):\n        # Move data to device (GPU/CPU)\n        inputs, targets = inputs.to(device), targets.to(device)\n\n        # Clear gradients from previous step\n        optimizer.zero_grad(set_to_none=True)\n\n        # Forward pass with mixed precision (if CUDA available)\n        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n            logits = model(inputs)\n            loss = criterion(logits, targets)\n\n            # Add L1 and L2 regularization\n            l1_norm = sum(p.abs().sum() for p in model.parameters())\n            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n            loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n\n\n        # Backward pass with gradient scaling\n        if scaler is not None and device.type == 'cuda':\n            scaler.scale(loss).backward()            # grads are scaled\n            scaler.unscale_(optimizer)               # unscale to true grad values\n            torch.nn.utils.clip_grad_norm_(          # CLIP true gradients (magnitude cap)\n                model.parameters(), max_norm=max_grad_norm\n            )\n            scaler.step(optimizer)                   # safe optimizer.step() (skips on inf/NaN)\n            scaler.update()                          # update scaling factor\n        else:\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n            optimizer.step()\n\n        # Accumulate metrics\n        running_loss += loss.item() * inputs.size(0)\n        predictions = logits.argmax(dim=1)\n        all_predictions.append(predictions.cpu().numpy())\n        all_targets.append(targets.cpu().numpy())\n\n    # Calculate epoch metrics\n    epoch_loss = running_loss / len(train_loader.dataset)\n    epoch_f1 = f1_score(\n        np.concatenate(all_targets),\n        np.concatenate(all_predictions),\n        average='macro'\n    )\n\n    return epoch_loss, epoch_f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:17.123048Z","iopub.execute_input":"2025-11-11T23:33:17.123258Z","iopub.status.idle":"2025-11-11T23:33:17.133508Z","shell.execute_reply.started":"2025-11-11T23:33:17.123235Z","shell.execute_reply":"2025-11-11T23:33:17.132755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def validate_one_epoch(model, val_loader, criterion, device):\n    \"\"\"\n    Perform one complete validation epoch through the entire validation dataset.\n\n    Args:\n        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n        criterion (nn.Module): Loss function used to calculate validation loss\n        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n\n    Returns:\n        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n\n    Note:\n        This function automatically sets the model to evaluation mode and disables\n        gradient computation for efficiency during validation.\n    \"\"\"\n    model.eval()  # Set model to evaluation mode\n\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n\n    # Disable gradient computation for validation\n    with torch.no_grad():\n        for inputs, targets in val_loader:\n            # Move data to device\n            inputs, targets = inputs.to(device), targets.to(device)\n\n            # Forward pass with mixed precision (if CUDA available)\n            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n                logits = model(inputs)\n                loss = criterion(logits, targets)\n\n            # Accumulate metrics\n            running_loss += loss.item() * inputs.size(0)\n            predictions = logits.argmax(dim=1)\n            all_predictions.append(predictions.cpu().numpy())\n            all_targets.append(targets.cpu().numpy())\n\n    # Calculate epoch metrics\n    epoch_loss = running_loss / len(val_loader.dataset)\n    epoch_accuracy = f1_score(\n        np.concatenate(all_targets),\n        np.concatenate(all_predictions),\n        average='macro'\n    )\n\n    return epoch_loss, epoch_accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:17.134160Z","iopub.execute_input":"2025-11-11T23:33:17.134347Z","iopub.status.idle":"2025-11-11T23:33:17.143781Z","shell.execute_reply.started":"2025-11-11T23:33:17.134334Z","shell.execute_reply":"2025-11-11T23:33:17.142971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def log_metrics_to_tensorboard(writer, epoch, train_loss, train_f1, val_loss, val_f1, model):\n    \"\"\"\n    Log training metrics and model parameters to TensorBoard for visualization.\n\n    Args:\n        writer (SummaryWriter): TensorBoard SummaryWriter object for logging\n        epoch (int): Current epoch number (used as x-axis in TensorBoard plots)\n        train_loss (float): Training loss for this epoch\n        train_f1 (float): Training f1 score for this epoch\n        val_loss (float): Validation loss for this epoch\n        val_f1 (float): Validation f1 score for this epoch\n        model (nn.Module): The neural network model (for logging weights/gradients)\n\n    Note:\n        This function logs scalar metrics (loss/f1 score) and histograms of model\n        parameters and gradients, which helps monitor training progress and detect\n        issues like vanishing/exploding gradients.\n    \"\"\"\n    # Log scalar metrics\n    writer.add_scalar('Loss/Training', train_loss, epoch)\n    writer.add_scalar('Loss/Validation', val_loss, epoch)\n    writer.add_scalar('F1/Training', train_f1, epoch)\n    writer.add_scalar('F1/Validation', val_f1, epoch)\n\n    # Log model parameters and gradients\n    for name, param in model.named_parameters():\n        if param.requires_grad:\n            # Check if the tensor is not empty before adding a histogram\n            if param.numel() > 0:\n                writer.add_histogram(f'{name}/weights', param.data, epoch)\n            if param.grad is not None:\n                # Check if the gradient tensor is not empty before adding a histogram\n                if param.grad.numel() > 0:\n                    if param.grad is not None and torch.isfinite(param.grad).all():\n                        writer.add_histogram(f'{name}/gradients', param.grad.data, epoch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:17.144619Z","iopub.execute_input":"2025-11-11T23:33:17.144878Z","iopub.status.idle":"2025-11-11T23:33:17.156218Z","shell.execute_reply.started":"2025-11-11T23:33:17.144857Z","shell.execute_reply":"2025-11-11T23:33:17.155630Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fit(model, train_loader, val_loader, epochs, train_criterion, val_criterion, optimizer, scaler, device,\n        l1_lambda=0, l2_lambda=0, patience=0, scheduler=None, # Added scheduler parameter\n        evaluation_metric=\"val_f1\", mode='max', \n        restore_best_weights=True, writer=None, verbose=1, experiment_name=\"\"):\n    \"\"\"\n    Train the neural network model on the training data and validate on the validation data.\n\n    Args:\n        model (nn.Module): The neural network model to train\n        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n        epochs (int): Number of training epochs\n        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n        l1_lambda (float): L1 regularization coefficient (default: 0)\n        l2_lambda (float): L2 regularization coefficient (default: 0)\n        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n        verbose (int, optional): Frequency of printing training progress (default: 10)\n        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n\n    Returns:\n        tuple: (model, training_history) - Trained model and metrics history\n    \"\"\"\n\n    # Initialize metrics tracking\n    training_history = {\n        'train_loss': [], 'val_loss': [],\n        'train_f1': [], 'val_f1': []\n    }\n\n    # Configure early stopping if patience is set\n    if patience > 0:\n        patience_counter = 0\n        best_metric = float('-inf') if mode == 'max' else float('inf')\n        best_epoch = 0\n\n    print(f\"Training {epochs} epochs...\")\n\n    # Main training loop: iterate through epochs\n    for epoch in range(1, epochs + 1):\n\n        # Forward pass through training data, compute gradients, update weights\n        train_loss, train_f1 = train_one_epoch(\n            model, train_loader, train_criterion, optimizer, scaler, device\n        )\n\n        # Evaluate model on validation data without updating weights\n        if val_loader is not None:\n            val_loss, val_f1 = validate_one_epoch(model, val_loader, val_criterion, device)\n        else:\n            val_loss, val_f1 = None, None\n\n\n        # Step the scheduler if provided (typically after validation)\n        if scheduler is not None:\n            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n                scheduler.step(val_f1)\n            else:\n                scheduler.step()\n\n        # Store metrics for plotting and analysis\n        training_history['train_loss'].append(train_loss)\n        training_history['val_loss'].append(val_loss)\n        training_history['train_f1'].append(train_f1)\n        training_history['val_f1'].append(val_f1)\n\n        # Write metrics to TensorBoard for visualization\n        if writer is not None:\n            log_metrics_to_tensorboard(\n                writer, epoch, train_loss, train_f1, val_loss, val_f1, model\n            )\n\n        # Print progress every N epochs or on first epoch\n        if verbose > 0:\n            if epoch % verbose == 0 or epoch == 1:\n                if val_loss is not None:\n                    print(f\"Epoch {epoch:3d}/{epochs} | \"\n                          f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n                          f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f}\")\n                else:\n                    print(f\"Epoch {epoch:3d}/{epochs} | \"\n                          f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f}\")\n\n\n        # Early stopping logic: monitor metric and save best model\n        if patience > 0 and val_loader is not None:\n            current_metric = training_history[evaluation_metric][-1]\n            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n\n            if is_improvement:\n                best_metric = current_metric\n                best_epoch = epoch\n                torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n                patience_counter = 0\n            else:\n                patience_counter += 1\n                if patience_counter >= patience:\n                    print(f\"Early stopping triggered after {epoch} epochs.\")\n                    break\n\n\n    # Restore best model weights if early stopping was used\n    if restore_best_weights and patience > 0:\n        model.load_state_dict(torch.load(\"models/\"+experiment_name+'_model.pt'))\n        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n\n    # Save final model if no early stopping\n    if patience == 0:\n        torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n\n    # Close TensorBoard writer\n    if writer is not None:\n        writer.close()\n\n    return model, training_history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:17.157042Z","iopub.execute_input":"2025-11-11T23:33:17.157252Z","iopub.status.idle":"2025-11-11T23:33:17.175218Z","shell.execute_reply.started":"2025-11-11T23:33:17.157238Z","shell.execute_reply":"2025-11-11T23:33:17.174664Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üßÆ **Network and Training Hyperparameters**","metadata":{}},{"cell_type":"code","source":"# Training configuration\nLEARNING_RATE = 1e-3\nEPOCHS = 100\nPATIENCE = 20\n\n# Architecture\nHIDDEN_LAYERS = 2        # Hidden layers\nHIDDEN_SIZE = 128        # Neurons per layer\n\n# Regularisation\nDROPOUT_RATE = 0.4         # Dropout probability\nL1_LAMBDA = 0            # L1 penalty\nL2_LAMBDA = 3e-4            # L2 penalty\n\n# Set up loss function and optimizer\n\ny_train_np = np.array(y_train)  # (Replace with your actual array)\n\nnum_classes = np.max(y_train_np) + 1  # For 0-indexed labels: [0, 1, 2] ‚Üí num_classes=3\nclass_counts = np.bincount(y_train_np, minlength=num_classes)\ntotal = len(y_train_np)\n\nprint(\"Training class distribution:\")\nfor i, name in enumerate(['no_pain', 'low_pain', 'high_pain']):\n    print(f\"  {name} ({i}): {class_counts[i]} ({class_counts[i]/total*100:.1f}%)\")\n\n# Compute class weights using the 'maximum count' rule (makes the most common class weight=1.0)\nmax_count = class_counts.max()\nclass_weights = max_count / class_counts\nprint(f\"\\nClass weights: {class_weights}\")\n# For use in PyTorch or your label smoothing class:\nclass_weights = class_weights.tolist()\n\ntrain_criterion = ClassAwareLabelSmoothing(\n    num_classes=3,\n    smoothing_per_class=[0.15, 0.05, 0.02],  # Or tune as needed\n    class_weights=class_weights     # Use automatic weights\n)\n\nval_criterion = nn.CrossEntropyLoss()\n\n# model\nMODEL='GRU'\nBIDIRECTIONAL=False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:17.175973Z","iopub.execute_input":"2025-11-11T23:33:17.176229Z","iopub.status.idle":"2025-11-11T23:33:17.191313Z","shell.execute_reply.started":"2025-11-11T23:33:17.176210Z","shell.execute_reply":"2025-11-11T23:33:17.190680Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create model and display architecture with parameter count\nrnn_model = RecurrentClassifier(\n    input_size=input_shape[-1], # Pass the number of features\n    hidden_size=HIDDEN_SIZE,\n    num_layers=HIDDEN_LAYERS,\n    num_classes=num_classes,\n    dropout_rate=DROPOUT_RATE,\n    bidirectional=BIDIRECTIONAL,\n    rnn_type=MODEL\n    ).to(device)\nrecurrent_summary(rnn_model, input_size=input_shape)\n\n# Set up TensorBoard logging and save model architecture\nprefix = \"bi_\" if BIDIRECTIONAL else \"\"\nexperiment_name = prefix + MODEL.lower()\nwriter = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\nx = torch.randn(1, input_shape[0], input_shape[1]).to(device)\nwriter.add_graph(rnn_model, x)\n\n# Define optimizer with L2 regularization\noptimizer = torch.optim.AdamW(rnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n\n# Enable mixed precision training for GPU acceleration\nscaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:17.191991Z","iopub.execute_input":"2025-11-11T23:33:17.192244Z","iopub.status.idle":"2025-11-11T23:33:20.358953Z","shell.execute_reply.started":"2025-11-11T23:33:17.192217Z","shell.execute_reply":"2025-11-11T23:33:20.358400Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# Train model and track training history\nrnn_model, training_history = fit(\n    model=rnn_model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    epochs=EPOCHS,\n    train_criterion=train_criterion,\n    val_criterion=val_criterion,\n    optimizer=optimizer,\n    scaler=scaler,\n    device=device,\n    writer=writer,\n    verbose=1,\n    experiment_name=MODEL.lower(),\n    patience=PATIENCE\n    )\n\n# Update best model if current performance is superior\nif training_history['val_f1'][-1] > best_performance:\n    best_model = rnn_model\n    best_performance = training_history['val_f1'][-1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:33:20.359577Z","iopub.execute_input":"2025-11-11T23:33:20.360069Z","iopub.status.idle":"2025-11-11T23:38:45.853765Z","shell.execute_reply.started":"2025-11-11T23:33:20.360045Z","shell.execute_reply":"2025-11-11T23:38:45.852958Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Experiments","metadata":{}},{"cell_type":"code","source":"# @title Plot Hitory\n# Create a figure with two side-by-side subplots (two columns)\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n\n# Plot of training and validation loss on the first axis\nax1.plot(training_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\nax1.plot(training_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\nax1.set_title('Loss')\nax1.legend()\nax1.grid(alpha=0.3)\n\n# Plot of training and validation accuracy on the second axis\nax2.plot(training_history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\nax2.plot(training_history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\nax2.set_title('F1 Score')\nax2.legend()\nax2.grid(alpha=0.3)\n\n# Adjust the layout and display the plot\nplt.tight_layout()\nplt.subplots_adjust(right=0.85)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:38:45.854959Z","iopub.execute_input":"2025-11-11T23:38:45.855289Z","iopub.status.idle":"2025-11-11T23:38:46.461458Z","shell.execute_reply.started":"2025-11-11T23:38:45.855254Z","shell.execute_reply":"2025-11-11T23:38:46.460729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# @title Plot Confusion Matrix\n# Collect predictions and ground truth labels\nval_preds, val_targets = [], []\nwindow_to_sample = []  # Track which windows belong to which sample\n\nwith torch.no_grad():  # Disable gradient computation for inference\n    for xb, yb in val_loader:\n        xb = xb.to(device)\n        \n        # Forward pass: get model predictions\n        logits = rnn_model(xb)\n        preds = logits.argmax(dim=1).cpu().numpy()\n        \n        # Store batch results (these are still per-window)\n        val_preds.append(preds)\n        val_targets.append(yb.numpy())\n\n# Combine all batches into single arrays (still per-window)\nval_preds_windows = np.concatenate(val_preds)\nval_targets_windows = np.concatenate(val_targets)\n\n# ============= AGGREGATE WINDOWS TO SEQUENCES =============\n# Reconstruct mapping: each sequence produces (160 - W) // S + 1 windows\nn_windows_per_seq = (160 - W_SUGG) // S_SUGG + 1\n\n# Map window predictions back to sample_index\nunique_samples = X_val[\"sample_index\"].unique()\nsequence_preds = {}\nsequence_targets = {}\n\nfor idx, sid in enumerate(unique_samples):\n    # Extract windows for this sequence\n    start_idx = idx * n_windows_per_seq\n    end_idx = start_idx + n_windows_per_seq\n    \n    window_preds = val_preds_windows[start_idx:end_idx]\n    window_targets = val_targets_windows[start_idx:end_idx]\n    \n    # Aggregate strategy: MAJORITY VOTE\n    from collections import Counter\n    vote_counts = Counter(window_preds)\n    final_pred = vote_counts.most_common(1)[0][0]\n    \n    # Target should be same across all windows (sanity check)\n    assert len(np.unique(window_targets)) == 1, f\"Sample {sid} has inconsistent labels!\"\n    final_target = window_targets[0]\n    \n    sequence_preds[sid] = final_pred\n    sequence_targets[sid] = final_target\n\n# Convert to arrays for metrics\nval_preds = np.array([sequence_preds[sid] for sid in unique_samples])\nval_targets = np.array([sequence_targets[sid] for sid in unique_samples])\n# ============= END AGGREGATION =============\n\n# Calculate overall validation metrics (now sequence-level)\nval_acc = accuracy_score(val_targets, val_preds)\nval_prec = precision_score(val_targets, val_preds, average='macro')\nval_rec = recall_score(val_targets, val_preds, average='macro')\nval_f1 = f1_score(val_targets, val_preds, average='macro')\nprint(f\"Accuracy over the validation set: {val_acc:.4f}\")\nprint(f\"Precision over the validation set: {val_prec:.4f}\")\nprint(f\"Recall over the validation set: {val_rec:.4f}\")\nprint(f\"F1 score over the validation set: {val_f1:.4f}\")\n\n# Generate confusion matrix for detailed error analysis\ncm = confusion_matrix(val_targets, val_preds)\n\n# Create numeric labels for heatmap annotation\nlabels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n\n# Visualise confusion matrix\nplt.figure(figsize=(8, 7))\nsns.heatmap(cm, annot=labels, fmt='',\n            cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix ‚Äî Validation Set (Sequence-Level)')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:38:46.462164Z","iopub.execute_input":"2025-11-11T23:38:46.462412Z","iopub.status.idle":"2025-11-11T23:38:47.052489Z","shell.execute_reply.started":"2025-11-11T23:38:46.462386Z","shell.execute_reply":"2025-11-11T23:38:47.051675Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# choose output directory manually\n\n# --- Kaggle ---\n# OUT_DIR = \"/kaggle/working\"\n\n# --- Cluster (Westworld / Elysium) ---\n# OUT_DIR = \"/home/cristiano.battistini/storage/an2dl_outputs\"\n\n# --- Docker / local environment ---\nOUT_DIR = os.path.join(os.getcwd(), \"outputs\")\n\n# --- Create directory if it doesn't exist ---\nos.makedirs(OUT_DIR, exist_ok=True)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:38:47.053765Z","iopub.execute_input":"2025-11-11T23:38:47.054110Z","iopub.status.idle":"2025-11-11T23:38:47.058394Z","shell.execute_reply.started":"2025-11-11T23:38:47.054089Z","shell.execute_reply":"2025-11-11T23:38:47.057749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_experiment_output(\n    model_name: str,\n    hyperparams: dict,\n    X_test_seq: np.ndarray,\n    label_mapping: dict,\n    sample_indices: list,\n    output_dir: str,\n    model=None,\n    batch_size: int = 256,\n    window_size: int = None,\n    stride: int = None\n):\n    \"\"\"\n    Run inference on the test set, save predictions and hyperparameters.\n\n    Args:\n        model_name (str): Name of the experiment (e.g. 'lstm', 'bilstm', 'ffn').\n        hyperparams (dict): Dict containing all hyperparameters and training config.\n        X_test_seq (np.ndarray): Test sequences of shape (N_windows, W, F) ‚Äî windowed data.\n        label_mapping (dict): Mapping from label string to class index.\n        sample_indices (list): List of sample_index identifiers (as strings).\n        output_dir (str): Folder where submission and metadata are saved.\n        model (torch.nn.Module): Trained model for inference.\n        batch_size (int): Inference batch size.\n        window_size (int): Window size used to create X_test_seq.\n        stride (int): Stride used to create X_test_seq.\n    \"\"\"\n\n    os.makedirs(output_dir, exist_ok=True)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Reverse mapping\n    idx2label = {v: k for k, v in label_mapping.items()}\n\n    # --- Inference on windows ---\n    model.eval().to(device)\n    with torch.inference_mode():\n        logits = []\n        for i in range(0, len(X_test_seq), batch_size):\n            xb = torch.from_numpy(X_test_seq[i:i+batch_size]).to(device)\n            logits.append(model(xb).cpu().numpy())\n        logits = np.concatenate(logits, axis=0)  # (N_windows, num_classes)\n\n    # Get per-window predictions\n    pred_idx_windows = logits.argmax(axis=1)  # (N_windows,)\n\n    # --- Aggregate windows to sequences ---\n    # Calculate how many windows per sequence (assuming T=160)\n    if window_size is None or stride is None:\n        # Try to infer from hyperparams if not provided\n        window_size = hyperparams.get('window', 12)\n        stride = hyperparams.get('stride', 3)\n    \n    n_windows_per_seq = (160 - window_size) // stride + 1\n\n    # ============= FIX: SORT SAMPLE INDICES =============\n    # CRITICAL: X_test_seq windows are created in the order that sample_indices\n    # appear in X_test. We must match this order for aggregation.\n    # If build_sequences processes sample_indices in sorted order, sort here too.\n    sample_indices = sorted(sample_indices)  # Ensure alignment\n    # ============= END FIX =============\n    \n    # Group predictions by sample_index using majority vote\n    from collections import Counter\n    sequence_predictions = []\n    \n    for idx in range(len(sample_indices)):\n        # Extract windows for this sequence\n        start_idx = idx * n_windows_per_seq\n        end_idx = start_idx + n_windows_per_seq\n        \n        window_preds = pred_idx_windows[start_idx:end_idx]\n        \n        # Majority vote across windows\n        vote_counts = Counter(window_preds)\n        final_pred_idx = vote_counts.most_common(1)[0][0]\n        \n        sequence_predictions.append(final_pred_idx)\n    \n    # Convert indices to labels\n    pred_labels = [idx2label[int(i)] for i in sequence_predictions]\n\n    # --- Build submission DataFrame ---\n    submission = pd.DataFrame({\n        \"sample_index\": [str(sid).zfill(3) for sid in sample_indices],\n        \"label\": pred_labels\n    })\n\n    # --- Build file names ---\n    run_name = f\"{model_name}_exp\"\n    csv_path = os.path.join(output_dir, f\"{run_name}_submission.csv\")\n    json_path = os.path.join(output_dir, f\"{run_name}_config.json\")\n\n    # --- Save submission ---\n    submission.to_csv(csv_path, index=False)\n\n    # --- Save hyperparameters as JSON ---\n    with open(json_path, \"w\") as f:\n        json.dump(hyperparams, f, indent=4)\n\n    print(f\"Saved submission at: {csv_path}\")\n    print(f\"Saved hyperparameters at: {json_path}\")\n    return submission\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:38:47.059209Z","iopub.execute_input":"2025-11-11T23:38:47.059542Z","iopub.status.idle":"2025-11-11T23:38:47.074056Z","shell.execute_reply.started":"2025-11-11T23:38:47.059518Z","shell.execute_reply":"2025-11-11T23:38:47.073508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define your hyperparameters as a dict\nhyperparams = {\n    \"m\": MODEL,\n    \"lr\": LEARNING_RATE,\n    \"epochs\": EPOCHS,\n    \"pat\": PATIENCE,\n    \"hl\": HIDDEN_LAYERS,\n    \"hs\": HIDDEN_SIZE,\n    \"dr\": DROPOUT_RATE,\n    \"l1\": L1_LAMBDA,\n    \"l2\": L2_LAMBDA,\n}\n\nmodel = best_model if \"best_model\" in globals() else rnn_model\n\n# Run and save output\nsubmission = save_experiment_output(\n    model_name=MODEL.lower(),\n    hyperparams=hyperparams,\n    X_test_seq=X_te_win,\n    label_mapping={'no_pain': 0, 'low_pain': 1, 'high_pain': 2},\n    sample_indices=X_test[\"sample_index\"].unique(),\n    output_dir=OUT_DIR,\n    model=model,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:38:47.074837Z","iopub.execute_input":"2025-11-11T23:38:47.075085Z","iopub.status.idle":"2025-11-11T23:38:47.689790Z","shell.execute_reply.started":"2025-11-11T23:38:47.075065Z","shell.execute_reply":"2025-11-11T23:38:47.689015Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **K-Shuffle-Split Cross Validation**","metadata":{}},{"cell_type":"code","source":"def k_shuffle_split_cross_validation_round_rnn(df, y, epochs, device, k, batch_size, window, stride,\n                                               hidden_layers, hidden_size, learning_rate, dropout_rate, rnn_type, bidirectional,\n                            l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n                            restore_best_weights=True, writer=None, verbose=10, seed=SEED, experiment_name=\"\"):\n    \"\"\"\n    Perform K-fold shuffle split cross-validation with user-based splitting for time series data.\n\n    Args:\n        df: DataFrame with columns ['user_id', 'activity', 'x_axis', 'y_axis', 'z_axis', 'id']\n        epochs: Number of training epochs\n        device: torch.device for computation\n        k: Number of cross-validation splits\n        n_val_idxs: Number of indexes for validation set\n        batch_size: Batch size for training\n        hidden_layers: Number of recurrent layers\n        hidden_size: Hidden state dimensionality\n        learning_rate: Learning rate for optimizer\n        dropout_rate: Dropout rate\n        rnn_type: Type of RNN ('RNN', 'LSTM', 'GRU')\n        bidirectional: Whether to use bidirectional RNN\n        l1_lambda: L1 regularization coefficient (if used)\n        l2_lambda: L2 regularization coefficient (weight_decay)\n        patience: Early stopping patience\n        evaluation_metric: Metric to monitor for early stopping\n        mode: 'max' or 'min' for evaluation metric\n        restore_best_weights: Whether to restore best weights after training\n        writer: TensorBoard writer\n        verbose: Verbosity level\n        seed: Random seed\n        experiment_name: Name for experiment logging\n\n    Returns:\n        fold_losses: Dict with validation losses for each split\n        fold_metrics: Dict with validation F1 scores for each split\n        best_scores: Dict with best F1 score for each split plus mean and std\n    \"\"\"\n\n    # Initialise containers for results across all splits\n    fold_losses = {}\n    fold_metrics = {}\n    best_scores = {}\n    best_epochs_per_fold = {}\n\n    DF, _ = preprocess_joints(X_TRAIN.copy())\n    X_train, _  = dataset_conversion_type_embed_ready(DF)\n    y = Y_TRAIN.copy()\n\n    # Step 1. temporary merge X_train + y_train to create splits ---\n    train_merged = X_train.merge(y, on=\"sample_index\", how=\"left\")\n\n    # Step 2. Retrieve unique indexes ---\n    unique_samples = train_merged['sample_index'].unique()\n\n    num_classes = len(train_merged['label'].unique())\n\n    # Prepare stratified K-fold based on label per sample_index\n    # ---------------------------------------------------------------\n    # Extract one label per sample_index\n    label_per_sample = train_merged.groupby(\"sample_index\")[\"label\"].first().map({\n        \"no_pain\": 0, \"low_pain\": 1, \"high_pain\": 2\n    }).values\n\n    # Create stratified splitter\n    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n    all_splits = list(skf.split(unique_samples, label_per_sample))\n    # ---------------------------------------------------------------\n\n    # Store initial weights to reset model for each split\n    initial_state = None\n\n    # Iterate through K random splits\n    for split_idx, (train_idx, val_idx) in enumerate(all_splits):\n\n        if verbose > 0:\n            print(f\"Split {split_idx+1}/{k}\")\n\n        # stratified split indices\n        train_idxs = unique_samples[train_idx]\n        val_idxs   = unique_samples[val_idx]\n\n        # Split the dataset into training, validation, and test sets based on user IDs\n        df_train = train_merged[train_merged['sample_index'].isin(train_idxs)].copy()\n        df_val = train_merged[train_merged['sample_index'].isin(val_idxs)].copy()\n\n        # X: only features\n        X_train = df_train.drop(columns=['label'])\n        X_val   = df_val.drop(columns=['label'])\n\n        # y: un'etichetta per ogni sequenza\n        y_train = df_train.groupby(\"sample_index\")[\"label\"].first().values\n        y_val   = df_val.groupby(\"sample_index\")[\"label\"].first().values\n\n        # Define mapping once\n        label_mapping = {'no_pain': 0, 'low_pain': 1, 'high_pain': 2}\n        inv_label_mapping = {v: k for k, v in label_mapping.items()}\n\n        # Convert y_train/y_val from string ‚Üí int\n        y_train = np.array([label_mapping[l] for l in y_train])\n        y_val   = np.array([label_mapping[l] for l in y_val])\n\n        # ============= COMPUTE CLASS WEIGHTS FROM TRAINING FOLD =============\n        # Calculate class distribution for this fold's training set\n        num_classes_fold = np.max(y_train) + 1\n        class_counts_fold = np.bincount(y_train, minlength=num_classes_fold)\n        \n        if verbose > 0:\n            total_train = len(y_train)\n            print(f\"  Training fold class distribution:\")\n            for i, name in enumerate(['no_pain', 'low_pain', 'high_pain']):\n                print(f\"    {name} ({i}): {class_counts_fold[i]} ({class_counts_fold[i]/total_train*100:.1f}%)\")\n        \n        # Compute class weights using the 'maximum count' rule\n        max_count_fold = class_counts_fold.max()\n        class_weights_fold = max_count_fold / class_counts_fold\n        \n        if verbose > 0:\n            print(f\"  Class weights for this fold: {class_weights_fold}\")\n        \n        # Define training criterion with class-aware label smoothing for this fold\n        train_criterion = ClassAwareLabelSmoothing(\n            num_classes=num_classes_fold,\n            smoothing_per_class=[0.15, 0.05, 0.02],\n            class_weights=class_weights_fold.tolist()\n        )\n        # ============= END CLASS WEIGHTS COMPUTATION =============\n\n        # Normalise features using training set statistics\n        scale_columns = [col for col in X_train.columns if col.startswith(\"joint_\")]\n\n        train_max = X_train[scale_columns].max()\n        train_min = X_train[scale_columns].min()\n\n        X_train[scale_columns] = (X_train[scale_columns] - train_min) / (train_max - train_min + 1e-8)\n        X_val[scale_columns] = (X_val[scale_columns] - train_min) / (train_max - train_min + 1e-8)\n\n        if verbose > 0:\n            print(f\"  Training set shape: {X_train.shape}\")\n            print(f\"  Validation set shape: {X_val.shape}\")\n\n        y_train_df = pd.DataFrame({\n            \"sample_index\": X_train[\"sample_index\"].unique(),\n            \"label\": y_train\n        })\n\n        X_train_seq, y_train_seq = build_sequences(X_train, y_train_df, window, stride)\n\n        y_val_df = pd.DataFrame({\n            \"sample_index\": X_val[\"sample_index\"].unique(),\n            \"label\": y_val\n        })\n\n        X_val_seq, y_val_seq = build_sequences(X_val, y_val_df, window, stride)\n\n        if verbose > 0:\n            print(f\"  Training sequences shape: {X_train_seq.shape}\")\n            print(f\"  Validation sequences shape: {X_val_seq.shape}\")\n\n        input_shape = X_train_seq.shape[1:] # extract the shape of a single sequence\n        num_classes = len(np.unique(y_train)) # how many unique pain level exists\n\n        if verbose > 0:\n            print(f\"  Input shape: {input_shape}\")\n            print(f\"  Num classes: {num_classes}\")\n\n        # Create PyTorch datasets\n        train_ds = TensorDataset(torch.from_numpy(X_train_seq), torch.from_numpy(y_train_seq))\n        val_ds   = TensorDataset(torch.from_numpy(X_val_seq), torch.from_numpy(y_val_seq))\n\n        # Create data loaders\n        train_loader = make_loader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n        val_loader   = make_loader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n\n        # Initialise model architecture\n        model = RecurrentClassifier(\n            input_size=input_shape[-1],\n            hidden_size=hidden_size,\n            num_layers=hidden_layers,\n            num_classes=num_classes,\n            dropout_rate=dropout_rate,\n            bidirectional=bidirectional,\n            rnn_type=rnn_type\n        ).to(device)\n\n        # 3. save initial state at 1st split, reset in the following splits\n        if initial_state is None:\n            # the first split (split_idx == 0)\n            # save initial random weights\n            initial_state = copy.deepcopy(model.state_dict())\n        else:\n            # Questo √® uno split successivo (1, 2, ...)\n            # Resetta il modello ai pesi iniziali salvati\n            model.load_state_dict(initial_state)\n        \n        # Define optimizer with L2 regularization\n        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=l2_lambda)\n\n        # Enable mixed precision training for GPU acceleration\n        split_scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n\n        # Create directory for model checkpoints\n        os.makedirs(f\"models/{experiment_name}\", exist_ok=True)\n\n        # Validation criterion (standard CrossEntropy without smoothing)\n        val_criterion = nn.CrossEntropyLoss()\n\n        # Train model on current split\n        model, training_history = fit(\n            model=model,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            epochs=epochs,\n            train_criterion=train_criterion,  # Use fold-specific class-aware smoothing\n            val_criterion=val_criterion,\n            optimizer=optimizer,\n            scaler=split_scaler,\n            device=device,\n            writer=writer,\n            patience=patience,\n            verbose=verbose,\n            evaluation_metric=evaluation_metric,\n            mode=mode,\n            restore_best_weights=restore_best_weights,\n            experiment_name=experiment_name+\"/split_\"+str(split_idx)\n        )\n\n        # Store results for this split\n        fold_losses[f\"split_{split_idx}\"] = training_history['val_loss']\n        fold_metrics[f\"split_{split_idx}\"] = training_history['val_f1']\n        best_scores[f\"split_{split_idx}\"] = max(training_history['val_f1'])\n\n        best_epoch_idx = training_history['val_f1'].index(max(training_history['val_f1']))\n        best_epochs_per_fold[f\"split_{split_idx}\"] = best_epoch_idx\n\n\n    # Compute mean and standard deviation of best scores across splits\n    best_scores[\"mean\"] = np.mean([best_scores[k] for k in best_scores.keys() if k.startswith(\"split_\")])\n    best_scores[\"std\"] = np.std([best_scores[k] for k in best_scores.keys() if k.startswith(\"split_\")])\n    best_scores[\"mean_best_epoch\"] = np.mean([\n        best_epochs_per_fold[k] for k in best_epochs_per_fold.keys() if k.startswith(\"split_\")\n    ])\n\n    if verbose > 0:\n        print(f\"Best score: {best_scores['mean']:.4f}¬±{best_scores['std']:.4f}\")\n\n    return fold_losses, fold_metrics, best_scores\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:04:54.943222Z","iopub.execute_input":"2025-11-12T00:04:54.943917Z","iopub.status.idle":"2025-11-12T00:04:54.963226Z","shell.execute_reply.started":"2025-11-12T00:04:54.943894Z","shell.execute_reply":"2025-11-12T00:04:54.962567Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Hyperparameters Tuning**","metadata":{}},{"cell_type":"code","source":"import pickle\n\ndef grid_search_cv_rnn(df, y, param_grid, fixed_params, cv_params, verbose=True, n_iter=60, \n                       checkpoint_every=10, early_prune_threshold=0.7):\n    \"\"\"\n    Execute grid search with K-shuffle-split cross-validation for RNN models on time series data.\n\n    Args:\n        df: DataFrame with columns \n        param_grid: Dict of parameters to test, e.g. {'batch_size': [16, 32], 'rnn_type': ['LSTM', 'GRU']}\n        fixed_params: Dict of fixed hyperparameters (hidden_size, learning_rate, window_size, stride, etc.)\n        cv_params: Dict of CV settings (epochs, k, patience, criterion, scaler, device, etc.)\n        verbose: Print progress for each configuration\n        checkpoint_every: Save results every N iterations (default 10)\n        early_prune_threshold: Stop config if score < best_score * threshold after 2 folds (default 0.7)\n\n    Returns:\n        results: Dict with scores for each configuration\n        best_config: Dict with best hyperparameter combination\n        best_score: Best mean F1 score achieved\n        best_config_epochs: Mean best epoch from best configuration\n    \"\"\"\n    # Generate all parameter combinations\n    param_names = list(param_grid.keys())\n    param_values = list(param_grid.values())\n    all_combinations = list(product(*param_values))\n\n    total_possible = len(all_combinations)\n\n    \n    results = {}\n    best_score = -np.inf\n    best_config = None\n    best_config_epochs = None\n\n    # Se n_iter √® minore del totale, scegli N combinazioni a caso\n    if n_iter < total_possible:\n        print(f\"--- Eseguendo RANDOM SEARCH ---\")\n        print(f\"Selezionate {n_iter} combinazioni casuali su {total_possible} possibili.\")\n        # Use seed for reproducibility\n        random.seed(cv_params.get('seed', 42))\n        combinations = random.sample(all_combinations, n_iter)\n    else:\n        print(f\"--- Eseguendo GRID SEARCH ---\")\n        print(f\"Testando tutte le {total_possible} combinazioni.\")\n        combinations = all_combinations\n\n    for idx, combo in enumerate(combinations, 1):\n        # Create current configuration dict\n        current_config = dict(zip(param_names, combo))\n        config_str = \"_\".join([f\"{k}_{v}\" for k, v in current_config.items()])\n\n        if verbose:\n            if n_iter < total_possible:\n                print(f\"\\nConfiguration {idx}/{n_iter}:\")\n            else:\n                 print(f\"\\nConfiguration {idx}/{total_possible}:\")\n            for param, value in current_config.items():\n                print(f\"  {param}: {value}\")\n\n        # Merge current config with fixed parameters\n        run_params = {**fixed_params, **current_config}\n\n        # Execute cross-validation \n        _, _, fold_scores = k_shuffle_split_cross_validation_round_rnn(\n            df=df,\n            y=y,\n            experiment_name=config_str,\n            **run_params,\n            **cv_params\n        )\n\n        # Early pruning: skip config if performance is too poor after initial folds\n        if best_score > -np.inf:  # Only prune after we have a baseline\n            partial_scores = fold_scores.get('scores', [])\n            if len(partial_scores) >= 2:\n                partial_mean = np.mean(partial_scores[:2])\n                if partial_mean < best_score * early_prune_threshold:\n                    if verbose:\n                        print(f\"  [PRUNED] Score {partial_mean:.4f} < {best_score * early_prune_threshold:.4f} (threshold), skipping.\")\n                    results[config_str] = fold_scores  # Still save for analysis\n                    continue\n\n        # Store results\n        results[config_str] = fold_scores\n\n        # Track best configuration\n        if fold_scores[\"mean\"] > best_score:\n            best_score = fold_scores[\"mean\"]\n            best_config = current_config.copy()\n            best_config_epochs = fold_scores[\"mean_best_epoch\"]\n            if verbose:\n                print(\"  NEW BEST SCORE!\")\n\n        if verbose:\n            print(f\"  F1 Score: {fold_scores['mean']:.4f}¬±{fold_scores['std']:.4f}\")\n\n        # Save checkpoint periodically\n        if idx % checkpoint_every == 0:\n            checkpoint_path = f'grid_search_checkpoint_{idx}.pkl'\n            with open(checkpoint_path, 'wb') as f:\n                pickle.dump({\n                    'results': results,\n                    'best_config': best_config,\n                    'best_score': best_score,\n                    'best_config_epochs': best_config_epochs,\n                    'completed_idx': idx,\n                    'total': n_iter if n_iter < total_possible else total_possible\n                }, f)\n            if verbose:\n                print(f\"  [CHECKPOINT] Salvato in {checkpoint_path}\")\n\n    # Final save\n    final_path = 'grid_search_final.pkl'\n    with open(final_path, 'wb') as f:\n        pickle.dump({\n            'results': results,\n            'best_config': best_config,\n            'best_score': best_score,\n            'best_config_epochs': best_config_epochs\n        }, f)\n    print(f\"\\n[COMPLETATO] Risultati salvati in {final_path}\")\n\n    return results, best_config, best_score, best_config_epochs\n\n\ndef plot_top_configurations_rnn(results, k_splits, top_n=5, figsize=(14, 7)):\n    \"\"\"\n    Visualise top N RNN configurations with boxplots of F1 scores across CV splits.\n\n    Args:\n        results: Dict of results from grid_search_cv_rnn\n        k_splits: Number of CV splits used\n        top_n: Number of top configurations to display\n        figsize: Figure size tuple\n    \"\"\"\n    # Sort by mean score\n    config_scores = {name: data['mean'] for name, data in results.items()}\n    sorted_configs = sorted(config_scores.items(), key=lambda x: x[1], reverse=True)\n\n    # Select top N\n    top_configs = sorted_configs[:min(top_n, len(sorted_configs))]\n\n    # Prepare boxplot data\n    boxplot_data = []\n    labels = []\n\n    # Define a dictionary for replacements, ordered to handle prefixes correctly\n    replacements = {\n        'window_':'W=',\n        'stride_':'S=',\n        'batch_size_': 'BS=',\n        'learning_rate_': '\\nLR=',\n        'hidden_layers_': '\\nHL=',\n        'hidden_size_': '\\nHS=',\n        'dropout_rate_': '\\nDR=',\n        'rnn_type_': '\\nRNN=',\n        'bidirectional_': '\\nBIDIR=',\n        'l1_lambda_': '\\nL1=',\n        'l2_lambda_': '\\nL2='\n    }\n\n    # Replacements for separators\n    separator_replacements = {\n        '_window_':'\\nW=',\n        '_stride_':'\\nS=',\n        '_learning_rate_': '\\nLR=',\n        '_hidden_layers_': '\\nHL=',\n        '_hidden_size_': '\\nHS=',\n        '_dropout_rate_': '\\nDR=',\n        '_rnn_type_': '\\nRNN=',\n        '_bidirectional_': '\\nBIDIR=',\n        '_l1_lambda_': '\\nL1=',\n        '_l2_lambda_': '\\nL2=',\n        '_': ''\n    }\n\n    for config_name, mean_score in top_configs:\n        # Extract best score from each split (auto-detect number of splits)\n        split_scores = []\n        for i in range(k_splits):\n            if f'split_{i}' in results[config_name]:\n                split_scores.append(results[config_name][f'split_{i}'])\n        boxplot_data.append(split_scores)\n\n        # Verify we have the expected number of splits\n        if len(split_scores) != k_splits:\n            print(f\"Warning: Config {config_name} has {len(split_scores)} splits, expected {k_splits}\")\n\n        # Create readable label using the replacements dictionary\n        readable_label = config_name\n        for old, new in replacements.items():\n            readable_label = readable_label.replace(old, new)\n\n        # Apply separator replacements\n        for old, new in separator_replacements.items():\n             readable_label = readable_label.replace(old, new)\n\n        labels.append(f\"{readable_label}\\n(Œº={mean_score:.3f})\")\n\n    # Create plot\n    fig, ax = plt.subplots(figsize=figsize)\n    bp = ax.boxplot(boxplot_data, labels=labels, patch_artist=True,\n                    showmeans=True, meanline=True)\n\n    # Styling\n    for patch in bp['boxes']:\n        patch.set_facecolor('lightblue')\n        patch.set_alpha(0.7)\n\n    # Highlight best configuration\n    ax.get_xticklabels()[0].set_fontweight('bold')\n\n    ax.set_ylabel('F1 Score')\n    ax.set_xlabel('Configuration')\n    ax.set_title(f'Top {len(top_configs)} RNN Configurations - F1 Score Distribution Across {k_splits} Splits')\n    ax.grid(alpha=0.3, axis='y')\n\n    plt.xticks(rotation=0, ha='center')\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:38:47.803763Z","iopub.execute_input":"2025-11-11T23:38:47.804002Z","iopub.status.idle":"2025-11-11T23:38:47.821982Z","shell.execute_reply.started":"2025-11-11T23:38:47.803977Z","shell.execute_reply":"2025-11-11T23:38:47.821458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DF, _ = preprocess_joints(X_TRAIN.copy())\nX_train, _ = dataset_conversion_type_embed_ready(DF)\ny = Y_TRAIN.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:45:55.823549Z","iopub.execute_input":"2025-11-11T23:45:55.824396Z","iopub.status.idle":"2025-11-11T23:45:55.896007Z","shell.execute_reply.started":"2025-11-11T23:45:55.824340Z","shell.execute_reply":"2025-11-11T23:45:55.895399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(type(X_train))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:45:57.170919Z","iopub.execute_input":"2025-11-11T23:45:57.171403Z","iopub.status.idle":"2025-11-11T23:45:57.175172Z","shell.execute_reply.started":"2025-11-11T23:45:57.171380Z","shell.execute_reply":"2025-11-11T23:45:57.174537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"K = 5\nVAL_FRAC = 0.20  # 20% sequences for validation in each split\nN = X_train['sample_index'].nunique()  # Returns integer\nN_VAL_IDXS = max(1, int(round(N * VAL_FRAC)))\nprint(\"Number of validation sequences per split:\", N_VAL_IDXS)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:46:00.690475Z","iopub.execute_input":"2025-11-11T23:46:00.691146Z","iopub.status.idle":"2025-11-11T23:46:00.696338Z","shell.execute_reply.started":"2025-11-11T23:46:00.691124Z","shell.execute_reply":"2025-11-11T23:46:00.695768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\n# Define parameters to search\nparam_grid = {\n    # Batch size ‚Äî gradient noise vs stability\n    'batch_size': [64, 128, 256],\n\n    # Model capacity ‚Äî too small underfits, too large overfits quickly\n    'hidden_size': [64, 128, 192],\n    'hidden_layers': [1, 2, 3],\n\n    # Regularization ‚Äî dropout reduces overfitting; 0.3‚Äì0.5 typical for RNNs\n    'dropout_rate': [0.2, 0.4, 0.5],\n\n    # Learning rate ‚Äî main driver of convergence\n    'learning_rate': [1e-3, 5e-4, 3e-4],\n\n    # Weight decay (L2) ‚Äî mild values prevent overfitting\n    'l2_lambda': [0, 1e-4, 3e-4, 1e-3],\n\n    # Architecture type and direction\n    'rnn_type': ['GRU', 'LSTM'],\n    'bidirectional': [False, True],\n\n    # Training dynamics\n    'epochs': [100],      # Reduced from 300\n    'patience': [20],     # Reduced from 50\n\n    'window': [12, 16, 20, 24],  # From ACF analysis\n    'stride': [3, 4, 5, 6],   # From ACF analysis\n}\n\n\n# Fixed hyperparameters (not being tuned)\nfixed_params = {\n    'l1_lambda': L1_LAMBDA,\n}\n\n# Cross-validation settings\ncv_params = {\n    'device': device,\n    'k': K,\n    'verbose': 0,\n    'seed': SEED\n}\n\n# Run aggressive random search\n# Total possible: 3√ó3√ó3√ó3√ó3√ó4√ó2√ó2 = 3,888 combinations\n# Testing: 60 random samples (~1.5% of total)\nresults, best_config, best_score, best_epochs = grid_search_cv_rnn(\n    df=df_train,\n    y=y_train,\n    param_grid=param_grid,\n    fixed_params=fixed_params,\n    cv_params=cv_params,\n    verbose=True,\n    n_iter=60,  # Sample 60 random configurations\n    checkpoint_every=10,  # Save every 10 iterations\n    early_prune_threshold=0.70  # Skip if score < 70% of best\n)\n\nprint(f\"\\n{'='*60}\")\nprint(f\"BEST CONFIGURATION:\")\nfor k, v in best_config.items():\n    print(f\"  {k}: {v}\")\nprint(f\"Best F1 Score: {best_score:.4f}\")\nprint(f\"Best Epochs: {best_epochs:.1f}\")\nprint(f\"{'='*60}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:20:13.654995Z","iopub.execute_input":"2025-11-12T00:20:13.655722Z","iopub.status.idle":"2025-11-12T00:40:09.453508Z","shell.execute_reply.started":"2025-11-12T00:20:13.655686Z","shell.execute_reply":"2025-11-12T00:40:09.452678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualise results\nplot_top_configurations_rnn(results, k_splits=K, top_n=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:40:23.692804Z","iopub.execute_input":"2025-11-12T00:40:23.693143Z","iopub.status.idle":"2025-11-12T00:40:23.900129Z","shell.execute_reply.started":"2025-11-12T00:40:23.693097Z","shell.execute_reply":"2025-11-12T00:40:23.899517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DF, _ = preprocess_joints(X_TRAIN.copy())\nX_train_full, _ = dataset_conversion_type_embed_ready(DF)\ny_full = Y_TRAIN.copy()\n\n\nlabels_full = y_full[\"label\"].map(label_mapping)\ny_full_np = labels_full.to_numpy()\n\nnum_classes = np.max(y_full_np) + 1  # For 0-indexed labels: [0, 1, 2] ‚Üí num_classes=3\nclass_counts = np.bincount(y_full_np, minlength=num_classes)\ntotal = len(y_full_np)\n\nprint(\"\\nTraining class distribution:\")\nfor i, name in enumerate(['no_pain', 'low_pain', 'high_pain']):\n    print(f\"  {name} ({i}): {class_counts[i]} ({class_counts[i]/total*100:.1f}%)\")\n\n# Compute class weights using the 'maximum count' rule (makes the most common class weight=1.0)\nmax_count = class_counts.max()\nclass_weights = max_count / class_counts\nprint(f\"Class weights: {class_weights}\")\n\n# For use in PyTorch or your label smoothing class:\nclass_weights = class_weights.tolist()\n\n# Define training criterion with class-aware label smoothing\ntrain_criterion = ClassAwareLabelSmoothing(\n    num_classes=3,\n    smoothing_per_class=[0.15, 0.05, 0.02],  # Or tune as needed\n    class_weights=class_weights              # Use automatic weights\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:40:31.854629Z","iopub.execute_input":"2025-11-12T00:40:31.854928Z","iopub.status.idle":"2025-11-12T00:40:31.948507Z","shell.execute_reply.started":"2025-11-12T00:40:31.854906Z","shell.execute_reply":"2025-11-12T00:40:31.947839Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# FINAL TRAINING ON THE FULL DATASET + SUBMISSION GENERATION\n# ============================================================\n\n# 1. Preprocess full training data\nDF, _ = preprocess_joints(X_TRAIN.copy())\nX_train_full, _ = dataset_conversion_type_embed_ready(DF)\ny_full = Y_TRAIN.copy()\n\n\nlabels_full = y_full[\"label\"].map(label_mapping)\ny_full_np = labels_full.to_numpy()\n\nnum_classes = np.max(y_full_np) + 1  # For 0-indexed labels: [0, 1, 2] ‚Üí num_classes=3\nclass_counts = np.bincount(y_full_np, minlength=num_classes)\ntotal = len(y_full_np)\n\nprint(\"\\nTraining class distribution:\")\nfor i, name in enumerate(['no_pain', 'low_pain', 'high_pain']):\n    print(f\"  {name} ({i}): {class_counts[i]} ({class_counts[i]/total*100:.1f}%)\")\n\n# Compute class weights using the 'maximum count' rule (makes the most common class weight=1.0)\nmax_count = class_counts.max()\nclass_weights = max_count / class_counts\nprint(f\"Class weights: {class_weights}\")\n\n# For use in PyTorch or your label smoothing class:\nclass_weights = class_weights.tolist()\n\n# Define training criterion with class-aware label smoothing\ntrain_criterion = ClassAwareLabelSmoothing(\n    num_classes=3,\n    smoothing_per_class=[0.15, 0.05, 0.02],  # Or tune as needed\n    class_weights=class_weights              # Use automatic weights\n)\n\n\n# 2. Combine the best hyperparameters (found in grid search)\nfinal_best_params = {**fixed_params, **best_config}\n\n# Use mean best epoch from CV + 20% buffer (more data ‚Üí slightly more epochs)\nfinal_epochs = int(best_epochs * 1.2)\nprint(f\"\\nüìä CV found best performance at epoch {best_epochs:.1f} (average)\")\nprint(f\"   Final training will use {final_epochs} epochs (20% buffer for full dataset)\")\n\nfinal_best_params['epochs'] = final_epochs\n\n\nprint(\"Training final model with best configuration:\")\nfor k, v in final_best_params.items():\n    print(f\"  {k}: {v}\")\n\n# 3. Merge features and labels\ntrain_merged = X_train_full.merge(y_full, on=\"sample_index\")\n\n# 4. Encode labels numerically BEFORE building sequences\nlabel_mapping = {\"no_pain\": 0, \"low_pain\": 1, \"high_pain\": 2}\ntrain_merged[\"label\"] = train_merged[\"label\"].map(label_mapping)\n\n\n\n# 5. Normalise feature values\n\nscale_columns = [col for col in train_merged.columns if col.startswith(\"joint_\")]\n# calculate the minimum and maximum values from the training data only\nmins = X_train[scale_columns].min()\nmaxs = X_train[scale_columns].max()\n\n# apply normalisation to the specified columns in all datasets (training and validation)\nfor column in scale_columns:\n\n    # normalise the training set\n    train_merged[column] = (train_merged[column] - mins[column]) / (maxs[column] - mins[column])\n\n# 6. Build full sequences\nX_train_seq, y_train_seq = build_sequences(train_merged, train_merged[[\"sample_index\", \"label\"]], window=final_best_params[\"window\"], stride=final_best_params[\"stride\"])\n\n\n# 7. DataLoader\ntrain_ds = TensorDataset(torch.from_numpy(X_train_seq), torch.from_numpy(y_train_seq))\ntrain_loader = make_loader(train_ds, batch_size=final_best_params[\"batch_size\"], shuffle=True, drop_last=False)\n\n# 8. Initialize model with tuned hyperparameters\nmodel = RecurrentClassifier(\n    input_size=X_train_seq.shape[2],\n    hidden_size=final_best_params[\"hidden_size\"],\n    num_layers=final_best_params[\"hidden_layers\"],\n    num_classes=len(label_mapping),\n    dropout_rate=final_best_params[\"dropout_rate\"],\n    bidirectional=final_best_params[\"bidirectional\"],\n    rnn_type=final_best_params[\"rnn_type\"]\n).to(device)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=final_best_params[\"learning_rate\"])\nscaler = torch.amp.GradScaler(enabled=(device.type == \"cuda\"))\n\n# 9. Train model on the entire dataset\nmodel, history = fit(\n    model=model,\n    train_loader=train_loader,\n    val_loader=None,\n    epochs=final_epochs,\n    train_criterion=train_criterion,\n    val_criterion=None,\n    optimizer=optimizer,\n    scaler=scaler,\n    device=device,\n    patience=final_best_params[\"patience\"],\n    verbose=True,\n    evaluation_metric=\"val_f1\",  # ignored since no validation\n    mode=\"max\",\n    restore_best_weights=False,\n    experiment_name=\"final_full_train\"\n)\n\n# 10. Prepare test set for inference\nX_test = pd.read_csv(DATASET_ROOT / \"pirate_pain_test.csv\")\nDF_test, _ = preprocess_joints(X_test.copy())\nX_test, _ = dataset_conversion_type_embed_ready(DF_test)\n\nfor column in scale_columns:\n    # normalise the test set\n    X_test[column] = (X_test[column] - mins[column]) / (maxs[column] - mins[column])\n\n# Build windowed sequences (this creates N_windows, not N_sequences)\nX_test_seq, _ = build_sequences(X_test, None, window=final_best_params[\"window\"], stride=final_best_params[\"stride\"])\n\n# 11. Save predictions and configuration\nOUT_DIR = \"results_best_model\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\nhyperparams = final_best_params.copy()\nhyperparams.update({\n    \"best_cv_f1\": best_score\n})\n\n# MODIFIED: Pass window_size and stride for aggregation\nsubmission = save_experiment_output(\n    model_name=final_best_params[\"rnn_type\"].lower(),\n    hyperparams=hyperparams,\n    X_test_seq=X_test_seq,  # Windowed data (N_windows, W, F)\n    label_mapping=label_mapping,\n    output_dir=OUT_DIR,\n    sample_indices=X_test[\"sample_index\"].unique(),\n    model=model,\n    window_size=final_best_params[\"window\"],  # NEW: pass for aggregation\n    stride=final_best_params[\"stride\"]  # NEW: pass for aggregation\n)\n\nprint(\"\\n‚úÖ Final model trained and submission saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:40:39.497272Z","iopub.execute_input":"2025-11-12T00:40:39.498003Z","iopub.status.idle":"2025-11-12T00:44:55.436296Z","shell.execute_reply.started":"2025-11-12T00:40:39.497978Z","shell.execute_reply":"2025-11-12T00:44:55.435565Z"}},"outputs":[],"execution_count":null}]}