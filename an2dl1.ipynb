{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79a2dd0",
   "metadata": {},
   "source": [
    "# **Artificial Neural Networks and Deep Learning**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b2cc3",
   "metadata": {},
   "source": [
    "## âš™ï¸ **Libraries Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6513d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "PyTorch version: 2.9.0+cu128\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# Import necessary modules\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "logs_dir = \"tensorboard\"\n",
    "!pkill -f tensorboard\n",
    "%load_ext tensorboard\n",
    "!mkdir -p models\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Import other libraries\n",
    "import copy\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fa9263",
   "metadata": {},
   "source": [
    "## â³ **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5bae3260",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = Path(\"./dataset\")\n",
    "\n",
    "# --- 2ï¸âƒ£ Kaggle ---\n",
    "# DATASET_ROOT = Path(\"/kaggle/input/pirate-pain\")\n",
    "\n",
    "# --- 3ï¸âƒ£ Server o cluster privato (es. Westworld/Elysium) ---\n",
    "# DATASET_ROOT = Path(\"/multiverse/datasets/private_dataset/pirate_pain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b24be028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X_train: (105760, 40)\n",
      "  y_train: (661, 2)\n",
      "  X_test:  (211840, 40)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caricamento dati\n",
    "X_train = pd.read_csv(DATASET_ROOT / \"pirate_pain_train.csv\")\n",
    "X_TRAIN = pd.read_csv(DATASET_ROOT / \"pirate_pain_train.csv\")\n",
    "\n",
    "y_train = pd.read_csv(DATASET_ROOT / \"pirate_pain_train_labels.csv\")\n",
    "Y_TRAIN = pd.read_csv(DATASET_ROOT / \"pirate_pain_train_labels.csv\")\n",
    "\n",
    "X_test  = pd.read_csv(DATASET_ROOT / \"pirate_pain_test.csv\")\n",
    "\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  X_test:  {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f23beee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts â€” joints: 31 | pain_survey: 4 | binary cats: 3\n",
      "n_legs: uniques -> ['two', 'one+peg_leg']\n",
      "n_hands: uniques -> ['two', 'one+hook_hand']\n",
      "n_eyes: uniques -> ['two', 'one+eye_patch']\n",
      "pain_survey_1: uniques -> [0 1 2] (dtype=int64)\n",
      "pain_survey_2: uniques -> [0 1 2] (dtype=int64)\n",
      "pain_survey_3: uniques -> [0 1 2] (dtype=int64)\n",
      "pain_survey_4: uniques -> [0 1 2] (dtype=int64)\n",
      "Cardinalities: {'n_legs': 2, 'n_hands': 2, 'n_eyes': 2, 'pain_survey_1': 3, 'pain_survey_2': 3, 'pain_survey_3': 3, 'pain_survey_4': 3}\n"
     ]
    }
   ],
   "source": [
    "# 1) Which columns are what?\n",
    "joint_cols        = [c for c in X_train.columns if c.startswith(\"joint_\")]\n",
    "pain_survey_cols  = [c for c in X_train.columns if c.startswith(\"pain_survey_\")]\n",
    "cat_two_cols      = [\"n_legs\", \"n_hands\", \"n_eyes\"]  # 2 options each (binary)\n",
    "\n",
    "print(\"Counts â€” joints:\", len(joint_cols),\n",
    "      \"| pain_survey:\", len(pain_survey_cols),\n",
    "      \"| binary cats:\", len(cat_two_cols))\n",
    "\n",
    "# 2) Unique values for the binary categoricals (before any mapping)\n",
    "for c in cat_two_cols:\n",
    "    vals = X_train[c].dropna().unique().tolist()\n",
    "    print(f\"{c}: uniques -> {vals}\")\n",
    "\n",
    "# 3) Unique values for each pain_survey_* column\n",
    "survey_uniques = {}\n",
    "for c in pain_survey_cols:\n",
    "    vals = np.sort(X_train[c].dropna().unique())\n",
    "    survey_uniques[c] = vals\n",
    "    print(f\"{c}: uniques -> {vals} (dtype={X_train[c].dtype})\")\n",
    "\n",
    "# 4) Cardinalities summary (useful if we embed)\n",
    "cat_cardinalities = {\n",
    "    **{c: int(X_train[c].nunique()) for c in cat_two_cols},\n",
    "    **{c: int(X_train[c].nunique()) for c in pain_survey_cols}\n",
    "}\n",
    "print(\"Cardinalities:\", cat_cardinalities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e88eff",
   "metadata": {},
   "source": [
    "## ðŸ”Ž **Exploration and Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e4cca83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>time</th>\n",
       "      <th>pain_survey_1</th>\n",
       "      <th>pain_survey_2</th>\n",
       "      <th>pain_survey_3</th>\n",
       "      <th>pain_survey_4</th>\n",
       "      <th>n_legs</th>\n",
       "      <th>n_hands</th>\n",
       "      <th>n_eyes</th>\n",
       "      <th>joint_00</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_21</th>\n",
       "      <th>joint_22</th>\n",
       "      <th>joint_23</th>\n",
       "      <th>joint_24</th>\n",
       "      <th>joint_25</th>\n",
       "      <th>joint_26</th>\n",
       "      <th>joint_27</th>\n",
       "      <th>joint_28</th>\n",
       "      <th>joint_29</th>\n",
       "      <th>joint_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>1.094705</td>\n",
       "      <td>...</td>\n",
       "      <td>3.499558e-06</td>\n",
       "      <td>1.945042e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.153299e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.017592</td>\n",
       "      <td>0.013508</td>\n",
       "      <td>0.026798</td>\n",
       "      <td>0.027815</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>1.135183</td>\n",
       "      <td>...</td>\n",
       "      <td>3.976952e-07</td>\n",
       "      <td>6.765107e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4.643774e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.013716</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>1.080745</td>\n",
       "      <td>...</td>\n",
       "      <td>1.533820e-07</td>\n",
       "      <td>1.698525e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.424536e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>0.024097</td>\n",
       "      <td>0.023105</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>0.938017</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006865e-05</td>\n",
       "      <td>5.511079e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.432416e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011832</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>0.028613</td>\n",
       "      <td>0.024648</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>1.090185</td>\n",
       "      <td>...</td>\n",
       "      <td>4.437266e-06</td>\n",
       "      <td>1.735459e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.825366e-08</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.033026</td>\n",
       "      <td>0.025328</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
       "0             0     0              2              0              2   \n",
       "1             0     1              2              2              2   \n",
       "2             0     2              2              0              2   \n",
       "3             0     3              2              2              2   \n",
       "4             0     4              2              2              2   \n",
       "\n",
       "   pain_survey_4 n_legs n_hands n_eyes  joint_00  ...      joint_21  \\\n",
       "0              1    two     two    two  1.094705  ...  3.499558e-06   \n",
       "1              2    two     two    two  1.135183  ...  3.976952e-07   \n",
       "2              2    two     two    two  1.080745  ...  1.533820e-07   \n",
       "3              2    two     two    two  0.938017  ...  1.006865e-05   \n",
       "4              2    two     two    two  1.090185  ...  4.437266e-06   \n",
       "\n",
       "       joint_22  joint_23      joint_24  joint_25  joint_26  joint_27  \\\n",
       "0  1.945042e-06  0.000004  1.153299e-05  0.000004  0.017592  0.013508   \n",
       "1  6.765107e-07  0.000006  4.643774e-08  0.000000  0.013352  0.000000   \n",
       "2  1.698525e-07  0.000001  2.424536e-06  0.000003  0.016225  0.008110   \n",
       "3  5.511079e-07  0.000002  5.432416e-08  0.000000  0.011832  0.007450   \n",
       "4  1.735459e-07  0.000002  5.825366e-08  0.000007  0.005360  0.002532   \n",
       "\n",
       "   joint_28  joint_29  joint_30  \n",
       "0  0.026798  0.027815       0.5  \n",
       "1  0.013377  0.013716       0.5  \n",
       "2  0.024097  0.023105       0.5  \n",
       "3  0.028613  0.024648       0.5  \n",
       "4  0.033026  0.025328       0.5  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105760 entries, 0 to 105759\n",
      "Data columns (total 40 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   sample_index   105760 non-null  int64  \n",
      " 1   time           105760 non-null  int64  \n",
      " 2   pain_survey_1  105760 non-null  int64  \n",
      " 3   pain_survey_2  105760 non-null  int64  \n",
      " 4   pain_survey_3  105760 non-null  int64  \n",
      " 5   pain_survey_4  105760 non-null  int64  \n",
      " 6   n_legs         105760 non-null  object \n",
      " 7   n_hands        105760 non-null  object \n",
      " 8   n_eyes         105760 non-null  object \n",
      " 9   joint_00       105760 non-null  float64\n",
      " 10  joint_01       105760 non-null  float64\n",
      " 11  joint_02       105760 non-null  float64\n",
      " 12  joint_03       105760 non-null  float64\n",
      " 13  joint_04       105760 non-null  float64\n",
      " 14  joint_05       105760 non-null  float64\n",
      " 15  joint_06       105760 non-null  float64\n",
      " 16  joint_07       105760 non-null  float64\n",
      " 17  joint_08       105760 non-null  float64\n",
      " 18  joint_09       105760 non-null  float64\n",
      " 19  joint_10       105760 non-null  float64\n",
      " 20  joint_11       105760 non-null  float64\n",
      " 21  joint_12       105760 non-null  float64\n",
      " 22  joint_13       105760 non-null  float64\n",
      " 23  joint_14       105760 non-null  float64\n",
      " 24  joint_15       105760 non-null  float64\n",
      " 25  joint_16       105760 non-null  float64\n",
      " 26  joint_17       105760 non-null  float64\n",
      " 27  joint_18       105760 non-null  float64\n",
      " 28  joint_19       105760 non-null  float64\n",
      " 29  joint_20       105760 non-null  float64\n",
      " 30  joint_21       105760 non-null  float64\n",
      " 31  joint_22       105760 non-null  float64\n",
      " 32  joint_23       105760 non-null  float64\n",
      " 33  joint_24       105760 non-null  float64\n",
      " 34  joint_25       105760 non-null  float64\n",
      " 35  joint_26       105760 non-null  float64\n",
      " 36  joint_27       105760 non-null  float64\n",
      " 37  joint_28       105760 non-null  float64\n",
      " 38  joint_29       105760 non-null  float64\n",
      " 39  joint_30       105760 non-null  float64\n",
      "dtypes: float64(31), int64(6), object(3)\n",
      "memory usage: 32.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Controllo struttura e tipi\n",
    "display(X_train.head())\n",
    "X_train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d0df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if joint angles repeat cyclically\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample = X_train[X_train['sample_index'] == 0]\n",
    "plt.plot(sample['time'], sample['joint_00'])\n",
    "plt.title(\"Joint 0 over time - Is it cyclic?\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e155c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "error.tobreak()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e9ef9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sample_index  time    label\n",
      "0             0     0  no_pain\n",
      "1             0     1  no_pain\n",
      "2             0     2  no_pain\n",
      "3             0     3  no_pain\n",
      "4             0     4  no_pain\n",
      "Class Distribution\n",
      "label\n",
      "no_pain      81760\n",
      "low_pain     15040\n",
      "high_pain     8960\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# MERGE BETWEEN TRAIN DATA AND LABELS\n",
    "# the labels are in a separated file linked through 'sample_index\n",
    "# here we merge X_train and y_train in a unique Dataframe to explore\n",
    "\n",
    "train_merge = X_train.merge(y_train, on=\"sample_index\", how=\"left\")\n",
    "\n",
    "# check whether all the labels have been associated or not\n",
    "missing_labels = train_merge[\"label\"].isna().sum()\n",
    "if missing_labels > 0:\n",
    "    print(f\"{missing_labels} rows without a label\")\n",
    "\n",
    "# check\n",
    "print(train_merge[[\"sample_index\",\"time\",\"label\"]].head())\n",
    "print(\"Class Distribution\")\n",
    "print(train_merge[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c814d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "no_pain      511\n",
      "low_pain      94\n",
      "high_pain     56\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006c340",
   "metadata": {},
   "source": [
    "## ðŸ”„ **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e8c7770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_conversion_type_embed_ready(df):\n",
    "    \"\"\"\n",
    "    Minimal, embedding-friendly preprocessing:\n",
    "    - joints: float32 (continuous features)\n",
    "    - pain_survey_*: int64 indices (0..2) for embeddings\n",
    "    - n_legs/hands/eyes: mapped to {0,1} as int64 for embeddings\n",
    "    Returns: df, meta\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) continuous features\n",
    "    joint_cols = [c for c in df.columns if c.startswith(\"joint_\")]\n",
    "    df[joint_cols] = df[joint_cols].astype(\"float32\")\n",
    "\n",
    "    # 2) surveys as categorical indices (already 0/1/2)\n",
    "    pain_survey_cols = [c for c in df.columns if c.startswith(\"pain_survey_\")]\n",
    "    df[pain_survey_cols] = df[pain_survey_cols].astype(\"int64\")\n",
    "\n",
    "    # 3) 2-way categoricals â†’ indices\n",
    "    legs_map  = {\"two\": 0, \"one+peg_leg\": 1}\n",
    "    hands_map = {\"two\": 0, \"one+hook_hand\": 1}\n",
    "    eyes_map  = {\"two\": 0, \"one+eye_patch\": 1}\n",
    "\n",
    "    if \"n_legs\" in df.columns:\n",
    "        df[\"n_legs\"]  = df[\"n_legs\"].map(legs_map).astype(\"int64\")\n",
    "    if \"n_hands\" in df.columns:\n",
    "        df[\"n_hands\"] = df[\"n_hands\"].map(hands_map).astype(\"int64\")\n",
    "    if \"n_eyes\" in df.columns:\n",
    "        df[\"n_eyes\"]  = df[\"n_eyes\"].map(eyes_map).astype(\"int64\")\n",
    "\n",
    "    # 4) define columns\n",
    "    cat_two_cols = [c for c in [\"n_legs\",\"n_hands\",\"n_eyes\"] if c in df.columns]\n",
    "    cat_cols = pain_survey_cols + cat_two_cols\n",
    "    cont_cols = joint_cols  # keep only joints as continuous\n",
    "\n",
    "    # 5) cardinals for embeddings (compute on TRAIN ONLY in CV, reuse for VAL/TEST)\n",
    "    cardinals = {c: int(df[c].nunique()) for c in cat_cols}\n",
    "    # suggested tiny dims: 1 for binaries, 2 for 3-class surveys\n",
    "    emb_dims = {c: (1 if cardinals[c] == 2 else 2) for c in cat_cols}\n",
    "\n",
    "    meta = {\n",
    "        \"cont_cols\": cont_cols,\n",
    "        \"cat_cols\":  cat_cols,\n",
    "        \"cardinals\": cardinals,\n",
    "        \"emb_dims\":  emb_dims,\n",
    "        \"maps\": {\"n_legs\": legs_map, \"n_hands\": hands_map, \"n_eyes\": eyes_map},\n",
    "    }\n",
    "    return df, meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9d3d738a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise the count of timestamps for each kind of pain\n",
    "plt.figure(figsize=(17, 5))\n",
    "sns.countplot(\n",
    "    x='label',\n",
    "    data=train_merge,\n",
    "    order=train_merge['label'].value_counts().index,\n",
    "    palette='tab10'\n",
    ")\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Label Timestamps')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a8bad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    661.0\n",
      "mean     160.0\n",
      "std        0.0\n",
      "min      160.0\n",
      "25%      160.0\n",
      "50%      160.0\n",
      "75%      160.0\n",
      "max      160.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the number of timesteps per sample\n",
    "seq_lengths = train_merge.groupby(\"sample_index\").size()\n",
    "\n",
    "# Quick look\n",
    "print(seq_lengths.describe())\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(seq_lengths, bins=30, kde=True, color=\"skyblue\")\n",
    "plt.title(\"Distribution of Sequence Lengths\")\n",
    "plt.xlabel(\"Timesteps per Sequence\")\n",
    "plt.ylabel(\"Number of Sequences\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16ce4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to inspect sensor data for a specific pain\n",
    "def inspect_pain(pain, df, n_rows=120000):\n",
    "    # Filter the DataFrame for the specified pain and limit to 500 rows\n",
    "    joint_cols = [col for col in df.columns if col.startswith(\"joint_\")]\n",
    "    data = df[df['label'] == pain][joint_cols][:n_rows]\n",
    "\n",
    "    # Dynamically adjust figure height based on number of joints\n",
    "    fig_height = len(joint_cols) * 1  # keep proportions similar to your original\n",
    "    axis = data.plot(subplots=True, figsize=(17, fig_height), title=pain)\n",
    "\n",
    "    # Adjust legend position for each subplot\n",
    "    for ax in axis:\n",
    "        ax.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the sensor data for the activity \"Standing\"\n",
    "inspect_pain(\"no_pain\", train_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the sensor data for the activity \"Standing\"\n",
    "inspect_pain(\"low_pain\", train_merge, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa2370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the sensor data for the activity \"Standing\"\n",
    "inspect_pain(\"high_pain\", train_merge, 12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f87ce476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_joints(df, \n",
    "                      drop_redundant=False, \n",
    "                      drop_near_zero=False, \n",
    "                      drop_low_var=False,\n",
    "                      verbose=True):\n",
    "    \"\"\"\n",
    "    Simplify joint_* preprocessing based on EDA results.\n",
    "    Removes constant, redundant, or near-zero-variance joints.\n",
    "\n",
    "    Returns a (df_out, feature_cols) tuple.\n",
    "    \"\"\"\n",
    "    joint_cols = sorted([c for c in df.columns if c.startswith(\"joint_\")],\n",
    "                        key=lambda x: int(x.split(\"_\")[1]))\n",
    "    drop = set()\n",
    "\n",
    "    # 1 Drop constant joint_30\n",
    "    if \"joint_30\" in joint_cols:\n",
    "        drop.add(\"joint_30\")\n",
    "\n",
    "    #  Drop redundant joints (from correlation heatmap)\n",
    "    if drop_redundant:\n",
    "        for c in [\"joint_01\", \"joint_02\", \"joint_05\"]:\n",
    "            if c in joint_cols:\n",
    "                drop.add(c)\n",
    "\n",
    "    # Drop near-zero variance joints (joint_13â€“25)\n",
    "    if drop_near_zero:\n",
    "        for i in range(13, 26):\n",
    "            c = f\"joint_{i:02d}\"\n",
    "            if c in joint_cols:\n",
    "                drop.add(c)\n",
    "\n",
    "    # (Optional) Drop low-variance but not-zero joints (joint_26â€“29)\n",
    "    if drop_low_var:\n",
    "        for i in range(26, 30):\n",
    "            c = f\"joint_{i:02d}\"\n",
    "            if c in joint_cols:\n",
    "                drop.add(c)\n",
    "\n",
    "    # apply\n",
    "    kept = [c for c in joint_cols if c not in drop]\n",
    "    df_out = df.drop(columns=list(drop), errors=\"ignore\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[preprocess_joints] start={len(joint_cols)} | kept={len(kept)} | dropped={len(drop)}\")\n",
    "        if drop:\n",
    "            print(\"  â€¢ dropped:\", sorted(list(drop)))\n",
    "\n",
    "    return df_out, kept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce115870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preprocess_joints] start=31 | kept=30 | dropped=1\n",
      "  â€¢ dropped: ['joint_30']\n",
      "[preprocess_joints] start=31 | kept=30 | dropped=1\n",
      "  â€¢ dropped: ['joint_30']\n"
     ]
    }
   ],
   "source": [
    "X_train, _ = preprocess_joints(X_train)\n",
    "X_test, _ = preprocess_joints(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65bedcf",
   "metadata": {},
   "source": [
    "## ðŸ”„ **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "914db185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train cont/cat: 30 7\n",
      "Train cont cols: ['joint_00', 'joint_01', 'joint_02', 'joint_03', 'joint_04'] â€¦\n",
      "Train cat  cols: ['pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4', 'n_legs', 'n_hands', 'n_eyes']\n",
      "Test has all cont cols? True\n",
      "Test has all cat  cols? True\n"
     ]
    }
   ],
   "source": [
    "# 1) Fit preprocessing on TRAIN ONLY\n",
    "X_train, meta = dataset_conversion_type_embed_ready(X_train)\n",
    "\n",
    "# 2) Apply the SAME mappings/cardinals to TEST\n",
    "#    (pain_survey_* are already 0/1/2; for n_legs/hands/eyes we reuse meta[\"maps\"])\n",
    "X_test = X_test.copy()\n",
    "for c, m in meta[\"maps\"].items():\n",
    "    if c in X_test.columns:\n",
    "        X_test[c] = X_test[c].map(m).astype(\"int64\")\n",
    "\n",
    "# Cast types consistently with train\n",
    "X_test[meta[\"cont_cols\"]] = X_test[meta[\"cont_cols\"]].astype(\"float32\")\n",
    "for c in meta[\"cat_cols\"]:\n",
    "    X_test[c] = X_test[c].astype(\"int64\")\n",
    "\n",
    "# 3) Sanity checks\n",
    "print(\"Train cont/cat:\", len(meta[\"cont_cols\"]), len(meta[\"cat_cols\"]))\n",
    "print(\"Train cont cols:\", meta[\"cont_cols\"][:5], \"â€¦\")\n",
    "print(\"Train cat  cols:\", meta[\"cat_cols\"])\n",
    "print(\"Test has all cont cols?\", set(meta[\"cont_cols\"]).issubset(X_test.columns))\n",
    "print(\"Test has all cat  cols?\", set(meta[\"cat_cols\"]).issubset(X_test.columns))\n",
    "\n",
    "# Optional: verify cardinalities didnâ€™t explode on test (should be â‰¤ train)\n",
    "for c in meta[\"cat_cols\"]:\n",
    "    tr_card = meta[\"cardinals\"][c]\n",
    "    te_card = int(X_test[c].nunique())\n",
    "    if te_card > tr_card:\n",
    "        print(f\"WARNING: column {c} has unseen categories in TEST (train={tr_card}, test={te_card})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "332f66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 â€” Copy merged train and raw test\n",
    "train_dataset = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e163a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reload quickly\n",
    "X_train = train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "793f8727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns: ['sample_index', 'time', 'pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4', 'n_legs', 'n_hands', 'n_eyes', 'joint_00', 'joint_01', 'joint_02', 'joint_03', 'joint_04', 'joint_05', 'joint_06', 'joint_07', 'joint_08', 'joint_09', 'joint_10', 'joint_11', 'joint_12', 'joint_13', 'joint_14', 'joint_15', 'joint_16', 'joint_17', 'joint_18', 'joint_19', 'joint_20', 'joint_21', 'joint_22', 'joint_23', 'joint_24', 'joint_25', 'joint_26', 'joint_27', 'joint_28', 'joint_29']\n",
      "Test columns: ['sample_index', 'time', 'pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4', 'n_legs', 'n_hands', 'n_eyes', 'joint_00', 'joint_01', 'joint_02', 'joint_03', 'joint_04', 'joint_05', 'joint_06', 'joint_07', 'joint_08', 'joint_09', 'joint_10', 'joint_11', 'joint_12', 'joint_13', 'joint_14', 'joint_15', 'joint_16', 'joint_17', 'joint_18', 'joint_19', 'joint_20', 'joint_21', 'joint_22', 'joint_23', 'joint_24', 'joint_25', 'joint_26', 'joint_27', 'joint_28', 'joint_29']\n",
      "âœ… Train and Test have identical columns.\n"
     ]
    }
   ],
   "source": [
    "print(\"Train columns:\", X_train.columns.tolist())\n",
    "print(\"Test columns:\", X_test.columns.tolist())\n",
    "\n",
    "train_only = [c for c in X_train.columns if c not in X_test.columns]\n",
    "test_only  = [c for c in X_test.columns if c not in X_train.columns]\n",
    "\n",
    "if train_only or test_only:\n",
    "    print(\"Column mismatch detected!\")\n",
    "    if train_only:\n",
    "        print(\"  Present only in TRAIN:\", train_only)\n",
    "    if test_only:\n",
    "        print(\"  Present only in TEST:\", test_only)\n",
    "else:\n",
    "    print(\"âœ… Train and Test have identical columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ed14591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105760, 40)\n",
      "Train Size: 528, Val Size: 133, total: 661\n"
     ]
    }
   ],
   "source": [
    "# Step 1. temporary merge X_train + y_train to create splits ---\n",
    "train_merged = X_train.merge(y_train, on=\"sample_index\")\n",
    "print(train_merged.shape)\n",
    "\n",
    "# Step 2. retrieve unique indexes and labels to stratify ---\n",
    "unique_samples = train_merged['sample_index'].unique()\n",
    "y_seq = train_merged.groupby('sample_index')['label'].first().reindex(unique_samples).values\n",
    "\n",
    "# Step 3. Divide in train e val (stratified) ---\n",
    "\n",
    "train_idxs, val_idxs = train_test_split(unique_samples, test_size=0.20, random_state=SEED, stratify=y_seq)\n",
    "print(f\"Train Size: {len(train_idxs)}, Val Size: {len(val_idxs)}, total: {len(train_idxs)+len(val_idxs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fff9cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. Apply split on X e y (separately) ---\n",
    "df_train = train_merged[train_merged['sample_index'].isin(train_idxs)]\n",
    "df_val   = train_merged[train_merged['sample_index'].isin(val_idxs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2dd6a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (84480, 39), X_val shape: (21280, 39)\n",
      "y_train: 528, y_val: 133\n"
     ]
    }
   ],
   "source": [
    "# X: only features\n",
    "X_train = df_train.drop(columns=['label'])\n",
    "X_val   = df_val.drop(columns=['label'])\n",
    "\n",
    "# y: one label for each sequence\n",
    "y_train = df_train.groupby(\"sample_index\")[\"label\"].first().values\n",
    "y_val   = df_val.groupby(\"sample_index\")[\"label\"].first().values\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, X_val shape: {X_val.shape}\")\n",
    "print(f\"y_train: {len(y_train)}, y_val: {len(y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48a99213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels: {'no_pain': np.int64(408), 'low_pain': np.int64(75), 'high_pain': np.int64(45)}\n",
      "Validation labels: {'no_pain': np.int64(103), 'low_pain': np.int64(19), 'high_pain': np.int64(11)}\n"
     ]
    }
   ],
   "source": [
    "# Define mapping once\n",
    "label_mapping = {'no_pain': 0, 'low_pain': 1, 'high_pain': 2}\n",
    "inv_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Convert y_train/y_val from string â†’ int\n",
    "y_train = np.array([label_mapping[l] for l in y_train])\n",
    "y_val   = np.array([label_mapping[l] for l in y_val])\n",
    "\n",
    "# Compute label distributions\n",
    "train_counts = {inv_label_mapping[k]: np.sum(y_train == k) for k in np.unique(y_train)}\n",
    "val_counts   = {inv_label_mapping[k]: np.sum(y_val == k) for k in np.unique(y_val)}\n",
    "\n",
    "print(\"Training labels:\", train_counts)\n",
    "print(\"Validation labels:\", val_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd1a34",
   "metadata": {},
   "source": [
    "### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f6697764",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_columns = [col for col in X_train.columns if col.startswith(\"joint_\")]\n",
    "\n",
    "# calculate the minimum and maximum values from the training data only\n",
    "mins = X_train[scale_columns].min()\n",
    "maxs = X_train[scale_columns].max()\n",
    "\n",
    "# apply normalisation to the specified columns in all datasets (training and validation)\n",
    "for column in scale_columns:\n",
    "\n",
    "    # normalise the training set\n",
    "    X_train[column] = (X_train[column] - mins[column]) / (maxs[column] - mins[column])\n",
    "\n",
    "    # normalise the validation set\n",
    "    X_val[column] = (X_val[column] - mins[column]) / (maxs[column] - mins[column])\n",
    "\n",
    "    # normalise the test set\n",
    "    X_test[column] = (X_test[column] - mins[column]) / (maxs[column] - mins[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c13cb0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0 â†’ 1.0\n",
      "Val:   -0.0077477884 â†’ 7.217308\n",
      "Test:  -0.07219823 â†’ 4.8295836\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", X_train[scale_columns].min().min(), \"â†’\", X_train[scale_columns].max().max())\n",
    "print(\"Val:  \", X_val[scale_columns].min().min(),   \"â†’\", X_val[scale_columns].max().max())\n",
    "print(\"Test: \", X_test[scale_columns].min().min(),   \"â†’\", X_test[scale_columns].max().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e4d0e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84480, 39) (528,)\n",
      "(21280, 39) (133,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
       " 0                  0     0              2              0              2   \n",
       " 1                  0     1              2              2              2   \n",
       " 2                  0     2              2              0              2   \n",
       " 3                  0     3              2              2              2   \n",
       " 4                  0     4              2              2              2   \n",
       " ...              ...   ...            ...            ...            ...   \n",
       " 105755           660   155              2              2              0   \n",
       " 105756           660   156              2              2              0   \n",
       " 105757           660   157              0              2              2   \n",
       " 105758           660   158              2              2              2   \n",
       " 105759           660   159              2              2              2   \n",
       " \n",
       "         pain_survey_4  n_legs  n_hands  n_eyes  joint_00  ...  joint_20  \\\n",
       " 0                   1       0        0       0  0.777046  ...  0.000001   \n",
       " 1                   2       0        0       0  0.805855  ...  0.000004   \n",
       " 2                   2       0        0       0  0.767110  ...  0.000001   \n",
       " 3                   2       0        0       0  0.665528  ...  0.000071   \n",
       " 4                   2       0        0       0  0.773829  ...  0.000039   \n",
       " ...               ...     ...      ...     ...       ...  ...       ...   \n",
       " 105755              0       0        0       0  0.746465  ...  0.000000   \n",
       " 105756              2       0        0       0  0.729322  ...  0.000000   \n",
       " 105757              2       0        0       0  0.790338  ...  0.000000   \n",
       " 105758              2       0        0       0  0.750993  ...  0.000000   \n",
       " 105759              0       0        0       0  0.715698  ...  0.000007   \n",
       " \n",
       "             joint_21      joint_22      joint_23  joint_24  joint_25  \\\n",
       " 0       2.426544e-06  1.503263e-06  1.052579e-04  0.000405  0.000004   \n",
       " 1       2.757563e-07  4.403064e-07  1.584209e-04  0.000001  0.000000   \n",
       " 2       1.063529e-07  1.575589e-08  3.805627e-05  0.000085  0.000003   \n",
       " 3       6.981461e-06  3.352260e-07  4.862392e-05  0.000002  0.000000   \n",
       " 4       3.076737e-06  1.885071e-08  4.086358e-05  0.000002  0.000007   \n",
       " ...              ...           ...           ...       ...       ...   \n",
       " 105755  0.000000e+00  1.739834e-07  7.708907e-08  0.000013  0.000001   \n",
       " 105756  1.010686e-06  1.741445e-07  0.000000e+00  0.000007  0.000004   \n",
       " 105757  0.000000e+00  1.742954e-07  6.375097e-05  0.000007  0.000007   \n",
       " 105758  1.210643e-07  1.744361e-07  1.594986e-05  0.000007  0.000001   \n",
       " 105759  4.086062e-07  1.745665e-07  0.000000e+00  0.000085  0.000001   \n",
       " \n",
       "         joint_26  joint_27  joint_28  joint_29  \n",
       " 0       0.014214  0.011376  0.018978  0.020291  \n",
       " 1       0.010748  0.000000  0.009473  0.010006  \n",
       " 2       0.013097  0.006830  0.017065  0.016856  \n",
       " 3       0.009505  0.006274  0.020264  0.017981  \n",
       " 4       0.004216  0.002132  0.023389  0.018477  \n",
       " ...          ...       ...       ...       ...  \n",
       " 105755  0.006255  0.022634  0.122919  0.161896  \n",
       " 105756  0.021736  0.010761  0.053784  0.085181  \n",
       " 105757  0.030063  0.023592  0.053808  0.057150  \n",
       " 105758  0.037765  0.015093  0.068772  0.077918  \n",
       " 105759  0.027207  0.035294  0.060020  0.119300  \n",
       " \n",
       " [84480 rows x 39 columns],\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 2, 0, 0, 1, 1, 2, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "        0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "        1, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 1, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 1,\n",
       "        0, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0,\n",
       "        0, 2, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        2, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "        2, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 2, 0, 0, 0, 2,\n",
       "        1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first five rows of the training DataFrame\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "368ff8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(\n",
    "    df: pd.DataFrame,\n",
    "    y: pd.DataFrame | np.ndarray | None = None,\n",
    "    window: int | None = None,\n",
    "    stride: int | None = None,\n",
    "    pad: bool = False,\n",
    "):\n",
    "    \"\"\" \n",
    "    Build sequences from the dataset, either:\n",
    "      - full-length per sample_index (when window/stride are None), or\n",
    "      - sliding windows with given window and stride.\n",
    "\n",
    "    Data assumptions for THIS notebook:\n",
    "      â€¢ df already normalized/mapped (categoricals numeric; e.g., n_legs/hands/eyes âˆˆ {0,1})\n",
    "      â€¢ df has columns: ['sample_index','time', joint_*, pain_survey_*, n_legs, n_hands, n_eyes]\n",
    "      â€¢ each sample_index has T=160 rows (fixed-length), but we still allow windowing/stride\n",
    "\n",
    "    Returns:\n",
    "        dataset: np.ndarray of shape (N,T,F) or (N,window,F)\n",
    "        labels:  np.ndarray of shape (N,) if y is provided, else None\n",
    "    \"\"\"\n",
    "    # ------------------------------------------------------------------\n",
    "    # Feature groups (already numeric at this stage)\n",
    "    joint_cols  = [c for c in df.columns if c.startswith('joint_')]\n",
    "    pain_cols   = [c for c in df.columns if c.startswith('pain_survey_')]\n",
    "    static_cols = [c for c in ['n_legs', 'n_hands', 'n_eyes'] if c in df.columns]\n",
    "\n",
    "    # Keep only the necessary columns in a copy; preserve order\n",
    "    cols_needed = ['sample_index', 'time'] + joint_cols + pain_cols + static_cols\n",
    "    df = df[cols_needed].copy()\n",
    "\n",
    "    # Sort to preserve chronological order within each sequence\n",
    "    df = df.sort_values([\"sample_index\", \"time\"])\n",
    "\n",
    "    # If labels are provided, build a lookup dictionary: sample_index â†’ label\n",
    "    label_dict = None\n",
    "    if y is not None:\n",
    "        if isinstance(y, np.ndarray):\n",
    "            # Build mapping using the unique order of sample_index in df\n",
    "            unique_ids = df[\"sample_index\"].unique()\n",
    "            label_dict = {sid: int(lbl) for sid, lbl in zip(unique_ids, y)}\n",
    "        elif isinstance(y, pd.DataFrame):\n",
    "            # Expect columns ['sample_index','label'] with already-int-mapped labels\n",
    "            label_dict = dict(zip(y[\"sample_index\"], y[\"label\"]))\n",
    "\n",
    "    # Prepare outputs\n",
    "    dataset = []\n",
    "    labels  = []\n",
    "\n",
    "    # If no window/stride provided â†’ fall back to full-length per sequence\n",
    "    full_length_mode = (window is None or stride is None)\n",
    "\n",
    "    # Iterate over each sequence\n",
    "    for sid, group in df.groupby(\"sample_index\", sort=False):\n",
    "        # --- Extract groups (already numeric) ---\n",
    "        X_joints = group[joint_cols].to_numpy(dtype=np.float32)        # (T, J)\n",
    "\n",
    "        # Current path: use pain_survey_* as numeric features (already mapped)\n",
    "        X_pain = group[pain_cols].to_numpy(dtype=np.float32)            # (T, 4)\n",
    "\n",
    "        # Static features are numeric 0/1 but vary by row; we keep them as provided\n",
    "        X_static = group[static_cols].to_numpy(dtype=np.float32) if static_cols else None  # (T, 3) or None\n",
    "\n",
    "        # Concatenate all feature groups along last dimension\n",
    "        if X_static is not None:\n",
    "            X_full = np.concatenate([X_joints, X_pain, X_static], axis=1)  # (T, F_total)\n",
    "        else:\n",
    "            X_full = np.concatenate([X_joints, X_pain], axis=1)            # (T, F_total)\n",
    "\n",
    "        T = X_full.shape[0]\n",
    "\n",
    "        if full_length_mode:\n",
    "            # ----- FULL-LENGTH MODE -----\n",
    "            dataset.append(X_full)\n",
    "            if label_dict is not None and sid in label_dict:\n",
    "                labels.append(int(label_dict[sid]))\n",
    "        else:\n",
    "            # ----- WINDOWED MODE (window, stride) -----\n",
    "            W = int(window)\n",
    "            S = int(stride)\n",
    "            assert W > 0 and S > 0, \"window and stride must be positive integers\"\n",
    "\n",
    "            if pad and T % W != 0:\n",
    "                # pad at the end with zeros to allow the last partial window\n",
    "                pad_len = (W - (T % W)) % W\n",
    "                if pad_len > 0:\n",
    "                    X_pad = np.zeros((pad_len, X_full.shape[1]), dtype=np.float32)\n",
    "                    X_seq = np.concatenate([X_full, X_pad], axis=0)\n",
    "                else:\n",
    "                    X_seq = X_full\n",
    "                Tmax = X_seq.shape[0]\n",
    "                idx = 0\n",
    "                while idx + W <= Tmax:\n",
    "                    dataset.append(X_seq[idx:idx+W])\n",
    "                    if label_dict is not None and sid in label_dict:\n",
    "                        labels.append(int(label_dict[sid]))\n",
    "                    idx += S\n",
    "            else:\n",
    "                # no padding â†’ only windows fully inside the sequence\n",
    "                idx = 0\n",
    "                while idx + W <= T:\n",
    "                    dataset.append(X_full[idx:idx+W])\n",
    "                    if label_dict is not None and sid in label_dict:\n",
    "                        labels.append(int(label_dict[sid]))\n",
    "                    idx += S\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    dataset = np.asarray(dataset, dtype=np.float32) if len(dataset) > 0 else np.empty((0, 0, 0), dtype=np.float32)\n",
    "    labels  = np.asarray(labels,  dtype=np.int64)   if len(labels)  > 0 else None\n",
    "\n",
    "    if dataset.size > 0:\n",
    "        print(f\"Built {len(dataset)} sequence{'s' if len(dataset)!=1 else ''}; each shape = {dataset[0].shape}\")\n",
    "    else:\n",
    "        print(\"Built 0 sequences (check window/stride vs sequence length).\")\n",
    "\n",
    "    return dataset, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1e5485d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ACF] Suggested WINDOW_SIZE=12, STRIDE=3\n",
      "[ACF] With T=160: n_windows=50, covered_steps=600/160\n"
     ]
    }
   ],
   "source": [
    "# --- ACF-DRIVEN WINDOWING (drop-in) ---------------------------------\n",
    "# Goal:\n",
    "#   Use autocorrelation (ACF) to pick a WINDOW_SIZE (W) and STRIDE (S)\n",
    "#   that reflect how far the signal â€œremembersâ€ its past.\n",
    "#\n",
    "# Design choices:\n",
    "#   â€¢ We use ONLY joint_* signals (continuous), excluding pain_survey_* and\n",
    "#     static cats (n_legs/hands/eyes), because ACF is meaningful for\n",
    "#     continuous, time-varying signals. Surveys/cats would distort it.\n",
    "#   â€¢ We compute ACF per joint, per sequence, then average to get a robust\n",
    "#     \"mean ACF\" over the dataset (train only â†’ no leakage).\n",
    "#   â€¢ From the mean ACF curve we pick W via a simple heuristic:\n",
    "#       1) first local peak (a natural cycle length)\n",
    "#       2) else, first lag where ACF falls below a cutoff (memory fades)\n",
    "#     then clamp to a safe lower bound (min_window) and snap to multiple of 4.\n",
    "#\n",
    "# How to read the outputs:\n",
    "#   â€¢ W_SUGG = suggested window (steps of lookback the model should \"see\")\n",
    "#   â€¢ S_SUGG = suggested stride (step between window starts; default W//4)\n",
    "#   â€¢ n_windows = number of windows per sequence with length T=160\n",
    "#   â€¢ covered_steps = n_windows * W  (overlaps â†’ can exceed T)\n",
    "#\n",
    "# Keep in mind:\n",
    "#   â€¢ This is NOT a replacement for cross-validation. Use CV to compare\n",
    "#     W in a small neighborhood (e.g., W, WÂ±4 or WÂ±8) and keep what wins.\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def _acf_1d(x: np.ndarray, max_lag: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the autocorrelation function (ACF) for a 1D vector up to `max_lag`.\n",
    "\n",
    "    Steps:\n",
    "      1) Normalize x to zero-mean and unit-variance so the ACF is scale-free.\n",
    "      2) Use np.correlate in 'full' mode to get correlation at all lags.\n",
    "      3) Slice the non-negative lags [0..max_lag].\n",
    "      4) Normalize by acf[0] (the variance) so ACF[0] == 1 and 0<=ACF<=1 (approx).\n",
    "\n",
    "    Args:\n",
    "      x (np.ndarray): 1D time series (length T)\n",
    "      max_lag (int): maximum lag we want to evaluate (<= T-1)\n",
    "\n",
    "    Returns:\n",
    "      acf (np.ndarray): shape (max_lag+1,), acf[0]=1, acf[k]=similarity at lag k\n",
    "    \"\"\"\n",
    "    x = x.astype(np.float64)\n",
    "    x = (x - x.mean()) / (x.std() + 1e-8)      # protect from near-constant series\n",
    "    acf_full = np.correlate(x, x, mode='full') # length 2T-1\n",
    "    # Keep the right half: lags 0..max_lag (index starts at the center)\n",
    "    acf = acf_full[len(x)-1 : len(x)-1 + max_lag + 1]\n",
    "    # Normalize so that ACF[0] == 1 (divide by variance term)\n",
    "    return acf / (acf[0] + 1e-8)\n",
    "\n",
    "def mean_acf_over_joints(df, max_lag=80, sample_cap=256):\n",
    "    \"\"\"\n",
    "    Compute the MEAN ACF across joints and (optionally) across a subset\n",
    "    of sequences for speed. This gives a single, smooth ACF curve.\n",
    "\n",
    "    Expected df columns:\n",
    "      â€¢ 'sample_index', 'time', and many 'joint_*' columns\n",
    "\n",
    "    Process:\n",
    "      For each sequence (sample_index):\n",
    "        - sort by time\n",
    "        - build a (T, J) matrix of joint features\n",
    "        - for each joint j, compute ACF_j[0..L] where L = min(max_lag, T-1)\n",
    "        - average ACF over joints â†’ one curve per sequence\n",
    "      Average all sequence curves â†’ mean ACF\n",
    "\n",
    "    Why average?\n",
    "      Reduces noise and avoids picking a window based on a single joint\n",
    "      or a single quirky sequence.\n",
    "\n",
    "    Args:\n",
    "      df (DataFrame): TRAIN subset only (to avoid leakage)\n",
    "      max_lag (int): maximum lag we consider (e.g., 80)\n",
    "      sample_cap (int): if many sequences, randomly subsample this many\n",
    "                        to keep runtime small\n",
    "\n",
    "    Returns:\n",
    "      lags (np.ndarray): [0, 1, ..., L]\n",
    "      mean_acf (np.ndarray): averaged ACF curve, length L+1\n",
    "    \"\"\"\n",
    "    joint_cols = [c for c in df.columns if c.startswith(\"joint_\")]\n",
    "    assert len(joint_cols) > 0, \"No joint_* columns found.\"\n",
    "\n",
    "    # Subsample sequences if needed (for speed on large datasets)\n",
    "    sids = df[\"sample_index\"].unique()\n",
    "    if len(sids) > sample_cap:\n",
    "        rng = np.random.default_rng(42)\n",
    "        sids = rng.choice(sids, size=sample_cap, replace=False)\n",
    "\n",
    "    acfs = []\n",
    "    for sid in sids:\n",
    "        # (T, J) matrix for this sequence\n",
    "        seq = (df.loc[df[\"sample_index\"] == sid]\n",
    "                 .sort_values(\"time\")[joint_cols].to_numpy(dtype=np.float32))\n",
    "        T, J = seq.shape\n",
    "        L = min(max_lag, T - 1)  # ACF defined up to T-1\n",
    "        # ACF for each joint, then average across joints â†’ one curve per sequence\n",
    "        per_joint = []\n",
    "        for j in range(J):\n",
    "            per_joint.append(_acf_1d(seq[:, j], L))  # shape (L+1,)\n",
    "        acfs.append(np.mean(np.stack(per_joint, axis=0), axis=0))  # (L+1,)\n",
    "\n",
    "    # Average across sequences â†’ single smooth ACF curve\n",
    "    mean_acf = np.mean(np.stack(acfs, axis=0), axis=0)  # (L+1,)\n",
    "    lags = np.arange(len(mean_acf))\n",
    "    return lags, mean_acf\n",
    "\n",
    "def suggest_window_from_acf(mean_acf: np.ndarray, min_window=12, cutoff=0.10):\n",
    "    \"\"\"\n",
    "    Heuristic to convert the mean ACF curve into a WINDOW_SIZE (W).\n",
    "\n",
    "    Intuition:\n",
    "      â€¢ If there's a visible \"cycle\", the ACF will have a local peak at its period.\n",
    "        â†’ pick the first local maximum after lag=1 (we ignore lag=0..1).\n",
    "      â€¢ If no clear peak, use the lag where correlation \"dies out\" (drops < cutoff).\n",
    "        â†’ pick first lag where ACF < cutoff (e.g., 0.10).\n",
    "      â€¢ Clamp to a minimum window (min_window) so we don't get too tiny a W.\n",
    "      â€¢ Snap to a multiple of 4 to make stride W//4 an integer (nice, common choice).\n",
    "\n",
    "    Args:\n",
    "      mean_acf (np.ndarray): curve from mean_acf_over_joints\n",
    "      min_window (int): lower bound to keep W usable for training (default 12)\n",
    "      cutoff (float): ACF threshold for \"memory fades\" (default 0.10)\n",
    "\n",
    "    Returns:\n",
    "      W (int): suggested window size\n",
    "    \"\"\"\n",
    "    # 1) Look for the first local MAX after lag=1 (i.e., k >= 2)\n",
    "    peak_lag = None\n",
    "    for k in range(2, len(mean_acf) - 1):\n",
    "        # local max if it is >= next and > previous\n",
    "        if mean_acf[k] > mean_acf[k - 1] and mean_acf[k] >= mean_acf[k + 1]:\n",
    "            peak_lag = k\n",
    "            break\n",
    "\n",
    "    # 2) First lag where ACF falls below cutoff (correlation has faded)\n",
    "    below = np.where(mean_acf < cutoff)[0]\n",
    "    drop_lag = int(below[0]) if len(below) else None\n",
    "\n",
    "    # Combine signals (prefer a peak if present, else use drop)\n",
    "    if peak_lag is not None and drop_lag is not None:\n",
    "        # keep it within [min_window, drop_lag]\n",
    "        W = min(max(peak_lag, min_window), drop_lag)\n",
    "    elif peak_lag is not None:\n",
    "        W = max(peak_lag, min_window)\n",
    "    elif drop_lag is not None:\n",
    "        W = max(drop_lag, min_window)\n",
    "    else:\n",
    "        # No clear info â†’ conservative fallback\n",
    "        W = max(24, min_window)\n",
    "\n",
    "    # Safety clamp within [min_window, 160] (your T=160)\n",
    "    W = int(np.clip(W, min_window, 160))\n",
    "\n",
    "    # Snap to multiple of 4 so stride = W//4 is an integer\n",
    "    if W % 4 != 0:\n",
    "        W += (4 - (W % 4))\n",
    "    return W\n",
    "\n",
    "def suggest_stride(window: int) -> int:\n",
    "    \"\"\"\n",
    "    Default stride choice: quarter window.\n",
    "    Why? Good balance between:\n",
    "      - enough overlap to preserve information\n",
    "      - not exploding the number of windows too much\n",
    "    \"\"\"\n",
    "    return max(1, window // 4)\n",
    "\n",
    "# ---- RUN IT ON YOUR TRAIN DF (after normalization/mapping) ----------\n",
    "# NOTE: Use df_train (TRAIN SPLIT ONLY) to avoid leaking validation info.\n",
    "lags, mean_acf = mean_acf_over_joints(df_train, max_lag=80, sample_cap=256)\n",
    "\n",
    "# Heuristic suggestions from ACF\n",
    "W_SUGG = suggest_window_from_acf(mean_acf, min_window=12, cutoff=0.10)\n",
    "S_SUGG = suggest_stride(W_SUGG)\n",
    "\n",
    "print(f\"[ACF] Suggested WINDOW_SIZE={W_SUGG}, STRIDE={S_SUGG}\")\n",
    "\n",
    "# Optional: coverage diagnostic for your fixed T=160\n",
    "T = 160\n",
    "n_windows = (T - W_SUGG) // S_SUGG + 1 if T >= W_SUGG else 0\n",
    "covered = n_windows * W_SUGG  # can exceed T because windows overlap\n",
    "print(f\"[ACF] With T={T}: n_windows={n_windows}, covered_steps={covered}/{T}\")\n",
    "# --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aebbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 528 sequences; each shape = (160, 37)\n"
     ]
    }
   ],
   "source": [
    "# y_train_df must contain sample_index + label columns\n",
    "y_train_df = pd.DataFrame({\n",
    "    \"sample_index\": X_train[\"sample_index\"].unique(),\n",
    "    \"label\": y_train\n",
    "})\n",
    "\n",
    "X_train_seq_complete_window, y_train_seq_complete_window = build_sequences(X_train, y_train_df, window=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6047ed31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 133 sequences; each shape = (160, 37)\n"
     ]
    }
   ],
   "source": [
    "y_val_df = pd.DataFrame({\n",
    "    \"sample_index\": X_val[\"sample_index\"].unique(),\n",
    "    \"label\": y_val\n",
    "})\n",
    "\n",
    "X_val_seq_complete_window, y_val_seq_complete_window = build_sequences(X_val, y_val_df, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0245dc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 1324 sequences; each shape = (160, 37)\n"
     ]
    }
   ],
   "source": [
    "X_test_seq_complete_window, _ = build_sequences(X_test, window=160)  # no labels â†’ returns (dataset, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b74f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 26400 sequences; each shape = (12, 37)\n",
      "Built 6650 sequences; each shape = (12, 37)\n",
      "Built 66200 sequences; each shape = (12, 37)\n"
     ]
    }
   ],
   "source": [
    "X_tr_win, y_tr_win = build_sequences(X_train, y_train, window=W_SUGG, stride=S_SUGG, pad=False)\n",
    "X_va_win, y_va_win = build_sequences(X_val,y_val, window=W_SUGG, stride=S_SUGG, pad=False)\n",
    "X_te_win, _        = build_sequences(X_test,None, window=W_SUGG, stride=S_SUGG, pad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6753d52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12, 37), 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X_tr_win.shape[1:] # extract the shape of a single sequence\n",
    "num_classes = len(np.unique(y_tr_win)) # how many unique pain level exists\n",
    "input_shape, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11d1772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch datasets (pairs features with labels)\n",
    "# each dataset now pairs each (T,F) TENSOR WITH ITS LABEL\n",
    "train_ds = TensorDataset(torch.from_numpy(X_tr_win), torch.from_numpy(y_tr_win))\n",
    "val_ds   = TensorDataset(torch.from_numpy(X_va_win), torch.from_numpy(y_va_win))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef48f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size, which is the number of samples in each batch\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3c461fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(ds, batch_size, shuffle, drop_last):\n",
    "    # Determine optimal number of worker processes for data loading\n",
    "    cpu_cores = os.cpu_count() or 2\n",
    "    num_workers = max(2, min(4, cpu_cores))\n",
    "\n",
    "    # Create DataLoader with performance optimizations\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,  # Faster GPU transfer\n",
    "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
    "        prefetch_factor=4,  # Load 4 batches aheads\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b8da5619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders with different settings for each phase\n",
    "train_loader = make_loader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader   = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "884fa47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features batch shape: torch.Size([64, 12, 37])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Get one batch from the training data loader\n",
    "for xb, yb in train_loader:\n",
    "    print(\"Features batch shape:\", xb.shape)\n",
    "    print(\"Labels batch shape:\", yb.shape)\n",
    "    break # Stop after getting one batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d16b2e",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ **Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d9527bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ClassAwareLabelSmoothing(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements BOTH professor's advice:\n",
    "    - Advice 08/11: Class weights (errors on rare classes weighted higher)\n",
    "    - Advice 09/11: Label smoothing (prevents overconfidence)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=3, smoothing_per_class=None, class_weights=None):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Label smoothing per class (Advice 09/11)\n",
    "        if smoothing_per_class is None:\n",
    "            # More smoothing for majority, less for minority\n",
    "            smoothing_per_class = [0.15, 0.05, 0.02]\n",
    "        self.smoothing = smoothing_per_class\n",
    "        \n",
    "        # Class weights (Advice 08/11) - NEW!\n",
    "        if class_weights is None:\n",
    "            # Calculate inverse frequency weights\n",
    "            # Your distribution: 408:75:45 = 77%:14%:9%\n",
    "            # Weights: [1.0, 408/75, 408/45] â‰ˆ [1.0, 5.4, 9.1]\n",
    "            class_weights = torch.tensor([1.0, 5.44, 9.07])\n",
    "        else:\n",
    "            class_weights = torch.tensor(class_weights)\n",
    "        \n",
    "        # Register as buffer (moves with model to GPU)\n",
    "        self.register_buffer('class_weights', class_weights)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pred: logits [batch_size, num_classes]\n",
    "            target: true labels [batch_size] (integers 0,1,2)\n",
    "        \"\"\"\n",
    "        log_probs = F.log_softmax(pred, dim=-1)\n",
    "        batch_size = target.size(0)\n",
    "        \n",
    "        # Create smooth targets per sample based on its true class\n",
    "        smooth_targets = torch.zeros_like(pred)\n",
    "        sample_weights = torch.zeros(batch_size, device=pred.device)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            true_class = target[i].item()\n",
    "            smoothing = self.smoothing[true_class]\n",
    "            confidence = 1.0 - smoothing\n",
    "            \n",
    "            # Distribute smoothing uniformly across other classes\n",
    "            smooth_targets[i].fill_(smoothing / (self.num_classes - 1))\n",
    "            smooth_targets[i, true_class] = confidence\n",
    "            \n",
    "            # Apply class weight (NEW! - Advice 08/11)\n",
    "            sample_weights[i] = self.class_weights[true_class]\n",
    "        \n",
    "        # Compute loss with class weights applied per sample\n",
    "        per_sample_loss = -(smooth_targets * log_probs).sum(dim=-1)\n",
    "        weighted_loss = (per_sample_loss * sample_weights).mean()\n",
    "        \n",
    "        return weighted_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3ab9e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurrent_summary(model, input_size):\n",
    "    \"\"\"\n",
    "    Custom summary function that emulates torchinfo's output while correctly\n",
    "    counting parameters for RNN/GRU/LSTM layers.\n",
    "\n",
    "    This function is designed for models whose direct children are\n",
    "    nn.Linear, nn.RNN, nn.GRU, or nn.LSTM layers.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to analyze.\n",
    "        input_size (tuple): Shape of the input tensor (e.g., (seq_len, features)).\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary to store output shapes captured by forward hooks\n",
    "    output_shapes = {}\n",
    "    # List to track hook handles for later removal\n",
    "    hooks = []\n",
    "\n",
    "    def get_hook(name):\n",
    "        \"\"\"Factory function to create a forward hook for a specific module.\"\"\"\n",
    "        def hook(module, input, output):\n",
    "            # Handle RNN layer outputs (returns a tuple)\n",
    "            if isinstance(output, tuple):\n",
    "                # output[0]: all hidden states with shape (batch, seq_len, hidden*directions)\n",
    "                shape1 = list(output[0].shape)\n",
    "                shape1[0] = -1  # Replace batch dimension with -1\n",
    "\n",
    "                # output[1]: final hidden state h_n (or tuple (h_n, c_n) for LSTM)\n",
    "                if isinstance(output[1], tuple):  # LSTM case: (h_n, c_n)\n",
    "                    shape2 = list(output[1][0].shape)  # Extract h_n only\n",
    "                else:  # RNN/GRU case: h_n only\n",
    "                    shape2 = list(output[1].shape)\n",
    "\n",
    "                # Replace batch dimension (middle position) with -1\n",
    "                shape2[1] = -1\n",
    "\n",
    "                output_shapes[name] = f\"[{shape1}, {shape2}]\"\n",
    "\n",
    "            # Handle standard layer outputs (e.g., Linear)\n",
    "            else:\n",
    "                shape = list(output.shape)\n",
    "                shape[0] = -1  # Replace batch dimension with -1\n",
    "                output_shapes[name] = f\"{shape}\"\n",
    "        return hook\n",
    "\n",
    "    # 1. Determine the device where model parameters reside\n",
    "    try:\n",
    "        device = next(model.parameters()).device\n",
    "    except StopIteration:\n",
    "        device = torch.device(\"cpu\")  # Fallback for models without parameters\n",
    "\n",
    "    # 2. Create a dummy input tensor with batch_size=1\n",
    "    dummy_input = torch.randn(1, *input_size).to(device)\n",
    "\n",
    "    # 3. Register forward hooks on target layers\n",
    "    # Iterate through direct children of the model (e.g., self.rnn, self.classifier)\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, (nn.Linear, nn.RNN, nn.GRU, nn.LSTM)):\n",
    "            # Register the hook and store its handle for cleanup\n",
    "            hook_handle = module.register_forward_hook(get_hook(name))\n",
    "            hooks.append(hook_handle)\n",
    "\n",
    "    # 4. Execute a dummy forward pass in evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            model(dummy_input)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during dummy forward pass: {e}\")\n",
    "            # Clean up hooks even if an error occurs\n",
    "            for h in hooks:\n",
    "                h.remove()\n",
    "            return\n",
    "\n",
    "    # 5. Remove all registered hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    # --- 6. Print the summary table ---\n",
    "\n",
    "    print(\"-\" * 79)\n",
    "    # Column headers\n",
    "    print(f\"{'Layer (type)':<25} {'Output Shape':<28} {'Param #':<18}\")\n",
    "    print(\"=\" * 79)\n",
    "\n",
    "    total_params = 0\n",
    "    total_trainable_params = 0\n",
    "\n",
    "    # Iterate through modules again to collect and display parameter information\n",
    "    for name, module in model.named_children():\n",
    "        if name in output_shapes:\n",
    "            # Count total and trainable parameters for this module\n",
    "            module_params = sum(p.numel() for p in module.parameters())\n",
    "            trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "\n",
    "            total_params += module_params\n",
    "            total_trainable_params += trainable_params\n",
    "\n",
    "            # Format strings for display\n",
    "            layer_name = f\"{name} ({type(module).__name__})\"\n",
    "            output_shape_str = str(output_shapes[name])\n",
    "            params_str = f\"{trainable_params:,}\"\n",
    "\n",
    "            print(f\"{layer_name:<25} {output_shape_str:<28} {params_str:<15}\")\n",
    "\n",
    "    print(\"=\" * 79)\n",
    "    print(f\"Total params: {total_params:,}\")\n",
    "    print(f\"Trainable params: {total_trainable_params:,}\")\n",
    "    print(f\"Non-trainable params: {total_params - total_trainable_params:,}\")\n",
    "    print(\"-\" * 79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dee00313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Generic RNN classifier (RNN, LSTM, GRU).\n",
    "    Uses the last hidden state for classification.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            num_classes,\n",
    "            rnn_type='GRU',        # 'RNN', 'LSTM', or 'GRU'\n",
    "            bidirectional=False,\n",
    "            dropout_rate=0.2\n",
    "            ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        # Map string name to PyTorch RNN class\n",
    "        rnn_map = {\n",
    "            'RNN': nn.RNN,\n",
    "            'LSTM': nn.LSTM,\n",
    "            'GRU': nn.GRU\n",
    "        }\n",
    "\n",
    "        if rnn_type not in rnn_map:\n",
    "            raise ValueError(\"rnn_type must be 'RNN', 'LSTM', or 'GRU'\")\n",
    "\n",
    "        rnn_module = rnn_map[rnn_type]\n",
    "\n",
    "        # Dropout is only applied between layers (if num_layers > 1)\n",
    "        dropout_val = dropout_rate if num_layers > 1 else 0\n",
    "\n",
    "        # Create the recurrent layer\n",
    "        self.rnn = rnn_module(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,       # Input shape: (batch, seq_len, features)\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout_val\n",
    "        )\n",
    "\n",
    "        # Calculate input size for the final classifier\n",
    "        if self.bidirectional:\n",
    "            classifier_input_size = hidden_size * 2 # Concat fwd + bwd\n",
    "        else:\n",
    "            classifier_input_size = hidden_size\n",
    "\n",
    "        # Final classification layer\n",
    "        self.classifier = nn.Linear(classifier_input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch_size, seq_length, input_size)\n",
    "        \"\"\"\n",
    "\n",
    "        # rnn_out shape: (batch_size, seq_len, hidden_size * num_directions)\n",
    "        rnn_out, hidden = self.rnn(x)\n",
    "\n",
    "        # LSTM returns (h_n, c_n), we only need h_n\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            hidden = hidden[0]\n",
    "\n",
    "        # hidden shape: (num_layers * num_directions, batch_size, hidden_size)\n",
    "\n",
    "        if self.bidirectional:\n",
    "            # Reshape to (num_layers, 2, batch_size, hidden_size)\n",
    "            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n",
    "\n",
    "            # Concat last fwd (hidden[-1, 0, ...]) and bwd (hidden[-1, 1, ...])\n",
    "            # Final shape: (batch_size, hidden_size * 2)\n",
    "            hidden_to_classify = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n",
    "        else:\n",
    "            # Take the last layer's hidden state\n",
    "            # Final shape: (batch_size, hidden_size)\n",
    "            hidden_to_classify = hidden[-1]\n",
    "\n",
    "        # Get logits\n",
    "        logits = self.classifier(hidden_to_classify)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409c7b2a",
   "metadata": {},
   "source": [
    "## ðŸ§  **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "28945707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize best model tracking variables\n",
    "best_model = None\n",
    "best_performance = float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d25240af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, \n",
    "                    device, l1_lambda=0, l2_lambda=0,max_grad_norm=1.0):\n",
    "    \"\"\"\n",
    "    Perform one complete training epoch through the entire training dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to train\n",
    "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
    "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
    "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
    "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "        l1_lambda (float): Lambda for L1 regularization\n",
    "        l2_lambda (float): Lambda for L2 regularization\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Iterate through training batches\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        # Move data to device (GPU/CPU)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Clear gradients from previous step\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Forward pass with mixed precision (if CUDA available)\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, targets)\n",
    "\n",
    "            # Add L1 and L2 regularization\n",
    "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n",
    "            loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n",
    "\n",
    "\n",
    "        # Backward pass with gradient scaling\n",
    "        if scaler is not None and device.type == 'cuda':\n",
    "            scaler.scale(loss).backward()            # grads are scaled\n",
    "            scaler.unscale_(optimizer)               # unscale to true grad values\n",
    "            torch.nn.utils.clip_grad_norm_(          # CLIP true gradients (magnitude cap)\n",
    "                model.parameters(), max_norm=max_grad_norm\n",
    "            )\n",
    "            scaler.step(optimizer)                   # safe optimizer.step() (skips on inf/NaN)\n",
    "            scaler.update()                          # update scaling factor\n",
    "        else:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        all_predictions.append(predictions.cpu().numpy())\n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_f1 = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='macro'\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6d2ff28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Perform one complete validation epoch through the entire validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n",
    "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
    "        criterion (nn.Module): Loss function used to calculate validation loss\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n",
    "\n",
    "    Note:\n",
    "        This function automatically sets the model to evaluation mode and disables\n",
    "        gradient computation for efficiency during validation.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Disable gradient computation for validation\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            # Move data to device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass with mixed precision (if CUDA available)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                logits = model(inputs)\n",
    "                loss = criterion(logits, targets)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    epoch_accuracy = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='macro'\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "01f1604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics_to_tensorboard(writer, epoch, train_loss, train_f1, val_loss, val_f1, model):\n",
    "    \"\"\"\n",
    "    Log training metrics and model parameters to TensorBoard for visualization.\n",
    "\n",
    "    Args:\n",
    "        writer (SummaryWriter): TensorBoard SummaryWriter object for logging\n",
    "        epoch (int): Current epoch number (used as x-axis in TensorBoard plots)\n",
    "        train_loss (float): Training loss for this epoch\n",
    "        train_f1 (float): Training f1 score for this epoch\n",
    "        val_loss (float): Validation loss for this epoch\n",
    "        val_f1 (float): Validation f1 score for this epoch\n",
    "        model (nn.Module): The neural network model (for logging weights/gradients)\n",
    "\n",
    "    Note:\n",
    "        This function logs scalar metrics (loss/f1 score) and histograms of model\n",
    "        parameters and gradients, which helps monitor training progress and detect\n",
    "        issues like vanishing/exploding gradients.\n",
    "    \"\"\"\n",
    "    # Log scalar metrics\n",
    "    writer.add_scalar('Loss/Training', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "    writer.add_scalar('F1/Training', train_f1, epoch)\n",
    "    writer.add_scalar('F1/Validation', val_f1, epoch)\n",
    "\n",
    "    # Log model parameters and gradients\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            # Check if the tensor is not empty before adding a histogram\n",
    "            if param.numel() > 0:\n",
    "                writer.add_histogram(f'{name}/weights', param.data, epoch)\n",
    "            if param.grad is not None:\n",
    "                # Check if the gradient tensor is not empty before adding a histogram\n",
    "                if param.grad.numel() > 0:\n",
    "                    if param.grad is not None and torch.isfinite(param.grad).all():\n",
    "                        writer.add_histogram(f'{name}/gradients', param.grad.data, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6a4550b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, val_loader, epochs, train_criterion, val_criterion, optimizer, scaler, device,\n",
    "        l1_lambda=0, l2_lambda=0, patience=0, scheduler=None, # Added scheduler parameter\n",
    "        evaluation_metric=\"val_f1\", mode='max', \n",
    "        restore_best_weights=True, writer=None, verbose=1, experiment_name=\"\"):\n",
    "    \"\"\"\n",
    "    Train the neural network model on the training data and validate on the validation data.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to train\n",
    "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
    "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
    "        epochs (int): Number of training epochs\n",
    "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
    "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
    "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "        l1_lambda (float): L1 regularization coefficient (default: 0)\n",
    "        l2_lambda (float): L2 regularization coefficient (default: 0)\n",
    "        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n",
    "        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n",
    "        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n",
    "        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n",
    "        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n",
    "        verbose (int, optional): Frequency of printing training progress (default: 10)\n",
    "        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n",
    "\n",
    "    Returns:\n",
    "        tuple: (model, training_history) - Trained model and metrics history\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize metrics tracking\n",
    "    training_history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_f1': [], 'val_f1': []\n",
    "    }\n",
    "\n",
    "    # Configure early stopping if patience is set\n",
    "    if patience > 0:\n",
    "        patience_counter = 0\n",
    "        best_metric = float('-inf') if mode == 'max' else float('inf')\n",
    "        best_epoch = 0\n",
    "\n",
    "    print(f\"Training {epochs} epochs...\")\n",
    "\n",
    "    # Main training loop: iterate through epochs\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        # Forward pass through training data, compute gradients, update weights\n",
    "        train_loss, train_f1 = train_one_epoch(\n",
    "            model, train_loader, train_criterion, optimizer, scaler, device\n",
    "        )\n",
    "\n",
    "        # Evaluate model on validation data without updating weights\n",
    "        if val_loader is not None:\n",
    "            val_loss, val_f1 = validate_one_epoch(model, val_loader, val_criterion, device)\n",
    "        else:\n",
    "            val_loss, val_f1 = None, None\n",
    "\n",
    "\n",
    "        # Step the scheduler if provided (typically after validation)\n",
    "        if scheduler is not None:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(val_f1)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "        # Store metrics for plotting and analysis\n",
    "        training_history['train_loss'].append(train_loss)\n",
    "        training_history['val_loss'].append(val_loss)\n",
    "        training_history['train_f1'].append(train_f1)\n",
    "        training_history['val_f1'].append(val_f1)\n",
    "\n",
    "        # Write metrics to TensorBoard for visualization\n",
    "        if writer is not None:\n",
    "            log_metrics_to_tensorboard(\n",
    "                writer, epoch, train_loss, train_f1, val_loss, val_f1, model\n",
    "            )\n",
    "\n",
    "        # Print progress every N epochs or on first epoch\n",
    "        if verbose > 0:\n",
    "            if epoch % verbose == 0 or epoch == 1:\n",
    "                if val_loss is not None:\n",
    "                    print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
    "                          f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n",
    "                          f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f}\")\n",
    "                else:\n",
    "                    print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
    "                          f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f}\")\n",
    "\n",
    "\n",
    "        # Early stopping logic: monitor metric and save best model\n",
    "        if patience > 0 and val_loader is not None:\n",
    "            current_metric = training_history[evaluation_metric][-1]\n",
    "            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n",
    "\n",
    "            if is_improvement:\n",
    "                best_metric = current_metric\n",
    "                best_epoch = epoch\n",
    "                torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping triggered after {epoch} epochs.\")\n",
    "                    break\n",
    "\n",
    "\n",
    "    # Restore best model weights if early stopping was used\n",
    "    if restore_best_weights and patience > 0:\n",
    "        model.load_state_dict(torch.load(\"models/\"+experiment_name+'_model.pt'))\n",
    "        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n",
    "\n",
    "    # Save final model if no early stopping\n",
    "    if patience == 0:\n",
    "        torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
    "\n",
    "    # Close TensorBoard writer\n",
    "    if writer is not None:\n",
    "        writer.close()\n",
    "\n",
    "    return model, training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fa8c0c",
   "metadata": {},
   "source": [
    "## ðŸ§® **Network and Training Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae2522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class distribution:\n",
      "  no_pain (0): 408 (77.3%)\n",
      "  low_pain (1): 75 (14.2%)\n",
      "  high_pain (2): 45 (8.5%)\n",
      "\n",
      "Class weights: [1.         5.44       9.06666667]\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 100\n",
    "PATIENCE = 20\n",
    "\n",
    "# Architecture\n",
    "HIDDEN_LAYERS = 2        # Hidden layers\n",
    "HIDDEN_SIZE = 128        # Neurons per layer\n",
    "\n",
    "# Regularisation\n",
    "DROPOUT_RATE = 0.4         # Dropout probability\n",
    "L1_LAMBDA = 0            # L1 penalty\n",
    "L2_LAMBDA = 3e-4            # L2 penalty\n",
    "\n",
    "# Set up loss function and optimizer\n",
    "\n",
    "y_train_np = np.array(y_train)  # (Replace with your actual array)\n",
    "\n",
    "num_classes = np.max(y_train_np) + 1  # For 0-indexed labels: [0, 1, 2] â†’ num_classes=3\n",
    "class_counts = np.bincount(y_train_np, minlength=num_classes)\n",
    "total = len(y_train_np)\n",
    "\n",
    "print(\"Training class distribution:\")\n",
    "for i, name in enumerate(['no_pain', 'low_pain', 'high_pain']):\n",
    "    print(f\"  {name} ({i}): {class_counts[i]} ({class_counts[i]/total*100:.1f}%)\")\n",
    "\n",
    "# Compute class weights using the 'maximum count' rule (makes the most common class weight=1.0)\n",
    "max_count = class_counts.max()\n",
    "class_weights = max_count / class_counts\n",
    "print(f\"\\nClass weights: {class_weights}\")\n",
    "# For use in PyTorch or your label smoothing class:\n",
    "class_weights = class_weights.tolist()\n",
    "\n",
    "train_criterion = ClassAwareLabelSmoothing(\n",
    "    num_classes=3,\n",
    "    smoothing_per_class=[0.15, 0.05, 0.02],  # Or tune as needed\n",
    "    class_weights=class_weights     # Use automatic weights\n",
    ")\n",
    "\n",
    "val_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# model\n",
    "MODEL='GRU'\n",
    "BIDIRECTIONAL=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1365430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and display architecture with parameter count\n",
    "rnn_model = RecurrentClassifier(\n",
    "    input_size=input_shape[-1], # Pass the number of features\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=HIDDEN_LAYERS,\n",
    "    num_classes=num_classes,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    bidirectional=BIDIRECTIONAL,\n",
    "    rnn_type=MODEL\n",
    "    ).to(device)\n",
    "recurrent_summary(rnn_model, input_size=input_shape)\n",
    "\n",
    "# Set up TensorBoard logging and save model architecture\n",
    "prefix = \"bi_\" if BIDIRECTIONAL else \"\"\n",
    "experiment_name = prefix + MODEL.lower()\n",
    "writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n",
    "x = torch.randn(1, input_shape[0], input_shape[1]).to(device)\n",
    "writer.add_graph(rnn_model, x)\n",
    "\n",
    "# Define optimizer with L2 regularization\n",
    "optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n",
    "\n",
    "# Enable mixed precision training for GPU acceleration\n",
    "scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94204b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model and track training history\n",
    "rnn_model, training_history = fit(\n",
    "    model=rnn_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCHS,\n",
    "    train_criterion=train_criterion,\n",
    "    val_criterion=val_criterion,\n",
    "    optimizer=optimizer,\n",
    "    scaler=scaler,\n",
    "    device=device,\n",
    "    writer=writer,\n",
    "    verbose=1,\n",
    "    experiment_name=MODEL.lower(),\n",
    "    patience=PATIENCE\n",
    "    )\n",
    "\n",
    "# Update best model if current performance is superior\n",
    "if training_history['val_f1'][-1] > best_performance:\n",
    "    best_model = rnn_model\n",
    "    best_performance = training_history['val_f1'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f583a3",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ea34aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Plot Hitory\n",
    "# Create a figure with two side-by-side subplots (two columns)\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n",
    "\n",
    "# Plot of training and validation loss on the first axis\n",
    "ax1.plot(training_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
    "ax1.plot(training_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Plot of training and validation accuracy on the second axis\n",
    "ax2.plot(training_history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
    "ax2.plot(training_history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n",
    "ax2.set_title('F1 Score')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# Adjust the layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fdf134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Plot Confusion Matrix\n",
    "# Collect predictions and ground truth labels\n",
    "val_preds, val_targets = [], []\n",
    "window_to_sample = []  # Track which windows belong to which sample\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for xb, yb in val_loader:\n",
    "        xb = xb.to(device)\n",
    "        \n",
    "        # Forward pass: get model predictions\n",
    "        logits = rnn_model(xb)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "        \n",
    "        # Store batch results (these are still per-window)\n",
    "        val_preds.append(preds)\n",
    "        val_targets.append(yb.numpy())\n",
    "\n",
    "# Combine all batches into single arrays (still per-window)\n",
    "val_preds_windows = np.concatenate(val_preds)\n",
    "val_targets_windows = np.concatenate(val_targets)\n",
    "\n",
    "# ============= AGGREGATE WINDOWS TO SEQUENCES =============\n",
    "# Reconstruct mapping: each sequence produces (160 - W) // S + 1 windows\n",
    "n_windows_per_seq = (160 - W_SUGG) // S_SUGG + 1\n",
    "\n",
    "# Map window predictions back to sample_index\n",
    "unique_samples = X_val[\"sample_index\"].unique()\n",
    "sequence_preds = {}\n",
    "sequence_targets = {}\n",
    "\n",
    "for idx, sid in enumerate(unique_samples):\n",
    "    # Extract windows for this sequence\n",
    "    start_idx = idx * n_windows_per_seq\n",
    "    end_idx = start_idx + n_windows_per_seq\n",
    "    \n",
    "    window_preds = val_preds_windows[start_idx:end_idx]\n",
    "    window_targets = val_targets_windows[start_idx:end_idx]\n",
    "    \n",
    "    # Aggregate strategy: MAJORITY VOTE\n",
    "    from collections import Counter\n",
    "    vote_counts = Counter(window_preds)\n",
    "    final_pred = vote_counts.most_common(1)[0][0]\n",
    "    \n",
    "    # Target should be same across all windows (sanity check)\n",
    "    assert len(np.unique(window_targets)) == 1, f\"Sample {sid} has inconsistent labels!\"\n",
    "    final_target = window_targets[0]\n",
    "    \n",
    "    sequence_preds[sid] = final_pred\n",
    "    sequence_targets[sid] = final_target\n",
    "\n",
    "# Convert to arrays for metrics\n",
    "val_preds = np.array([sequence_preds[sid] for sid in unique_samples])\n",
    "val_targets = np.array([sequence_targets[sid] for sid in unique_samples])\n",
    "# ============= END AGGREGATION =============\n",
    "\n",
    "# Calculate overall validation metrics (now sequence-level)\n",
    "val_acc = accuracy_score(val_targets, val_preds)\n",
    "val_prec = precision_score(val_targets, val_preds, average='macro')\n",
    "val_rec = recall_score(val_targets, val_preds, average='macro')\n",
    "val_f1 = f1_score(val_targets, val_preds, average='macro')\n",
    "print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n",
    "print(f\"Precision over the validation set: {val_prec:.4f}\")\n",
    "print(f\"Recall over the validation set: {val_rec:.4f}\")\n",
    "print(f\"F1 score over the validation set: {val_f1:.4f}\")\n",
    "\n",
    "# Generate confusion matrix for detailed error analysis\n",
    "cm = confusion_matrix(val_targets, val_preds)\n",
    "\n",
    "# Create numeric labels for heatmap annotation\n",
    "labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
    "\n",
    "# Visualise confusion matrix\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.heatmap(cm, annot=labels, fmt='',\n",
    "            cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix â€” Validation Set (Sequence-Level)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4cddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose output directory manually\n",
    "\n",
    "# --- Kaggle ---\n",
    "# OUT_DIR = \"/kaggle/working\"\n",
    "\n",
    "# --- Cluster (Westworld / Elysium) ---\n",
    "# OUT_DIR = \"/home/cristiano.battistini/storage/an2dl_outputs\"\n",
    "\n",
    "# --- Docker / local environment ---\n",
    "OUT_DIR = os.path.join(os.getcwd(), \"outputs\")\n",
    "\n",
    "# --- Create directory if it doesn't exist ---\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb83ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment_output(\n",
    "    model_name: str,\n",
    "    hyperparams: dict,\n",
    "    X_test_seq: np.ndarray,\n",
    "    label_mapping: dict,\n",
    "    sample_indices: list,\n",
    "    output_dir: str,\n",
    "    model=None,\n",
    "    batch_size: int = 256,\n",
    "    window_size: int = None,\n",
    "    stride: int = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Run inference on the test set, save predictions and hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the experiment (e.g. 'lstm', 'bilstm', 'ffn').\n",
    "        hyperparams (dict): Dict containing all hyperparameters and training config.\n",
    "        X_test_seq (np.ndarray): Test sequences of shape (N_windows, W, F) â€” windowed data.\n",
    "        label_mapping (dict): Mapping from label string to class index.\n",
    "        sample_indices (list): List of sample_index identifiers (as strings).\n",
    "        output_dir (str): Folder where submission and metadata are saved.\n",
    "        model (torch.nn.Module): Trained model for inference.\n",
    "        batch_size (int): Inference batch size.\n",
    "        window_size (int): Window size used to create X_test_seq.\n",
    "        stride (int): Stride used to create X_test_seq.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Reverse mapping\n",
    "    idx2label = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "    # --- Inference on windows ---\n",
    "    model.eval().to(device)\n",
    "    with torch.inference_mode():\n",
    "        logits = []\n",
    "        for i in range(0, len(X_test_seq), batch_size):\n",
    "            xb = torch.from_numpy(X_test_seq[i:i+batch_size]).to(device)\n",
    "            logits.append(model(xb).cpu().numpy())\n",
    "        logits = np.concatenate(logits, axis=0)  # (N_windows, num_classes)\n",
    "\n",
    "    # Get per-window predictions\n",
    "    pred_idx_windows = logits.argmax(axis=1)  # (N_windows,)\n",
    "\n",
    "    # --- Aggregate windows to sequences ---\n",
    "    # Calculate how many windows per sequence (assuming T=160)\n",
    "    if window_size is None or stride is None:\n",
    "        # Try to infer from hyperparams if not provided\n",
    "        window_size = hyperparams.get('window', 12)\n",
    "        stride = hyperparams.get('stride', 3)\n",
    "    \n",
    "    n_windows_per_seq = (160 - window_size) // stride + 1\n",
    "\n",
    "    # ============= FIX: SORT SAMPLE INDICES =============\n",
    "    # CRITICAL: X_test_seq windows are created in the order that sample_indices\n",
    "    # appear in X_test. We must match this order for aggregation.\n",
    "    # If build_sequences processes sample_indices in sorted order, sort here too.\n",
    "    sample_indices = sorted(sample_indices)  # Ensure alignment\n",
    "    # ============= END FIX =============\n",
    "    \n",
    "    # Group predictions by sample_index using majority vote\n",
    "    from collections import Counter\n",
    "    sequence_predictions = []\n",
    "    \n",
    "    for idx in range(len(sample_indices)):\n",
    "        # Extract windows for this sequence\n",
    "        start_idx = idx * n_windows_per_seq\n",
    "        end_idx = start_idx + n_windows_per_seq\n",
    "        \n",
    "        window_preds = pred_idx_windows[start_idx:end_idx]\n",
    "        \n",
    "        # Majority vote across windows\n",
    "        vote_counts = Counter(window_preds)\n",
    "        final_pred_idx = vote_counts.most_common(1)[0][0]\n",
    "        \n",
    "        sequence_predictions.append(final_pred_idx)\n",
    "    \n",
    "    # Convert indices to labels\n",
    "    pred_labels = [idx2label[int(i)] for i in sequence_predictions]\n",
    "\n",
    "    # --- Build submission DataFrame ---\n",
    "    submission = pd.DataFrame({\n",
    "        \"sample_index\": [str(sid).zfill(3) for sid in sample_indices],\n",
    "        \"label\": pred_labels\n",
    "    })\n",
    "\n",
    "    # --- Build file names ---\n",
    "    run_name = f\"{model_name}_exp\"\n",
    "    csv_path = os.path.join(output_dir, f\"{run_name}_submission.csv\")\n",
    "    json_path = os.path.join(output_dir, f\"{run_name}_config.json\")\n",
    "\n",
    "    # --- Save submission ---\n",
    "    submission.to_csv(csv_path, index=False)\n",
    "\n",
    "    # --- Save hyperparameters as JSON ---\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(hyperparams, f, indent=4)\n",
    "\n",
    "    print(f\"Saved submission at: {csv_path}\")\n",
    "    print(f\"Saved hyperparameters at: {json_path}\")\n",
    "    return submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your hyperparameters as a dict\n",
    "hyperparams = {\n",
    "    \"m\": MODEL,\n",
    "    \"lr\": LEARNING_RATE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"pat\": PATIENCE,\n",
    "    \"hl\": HIDDEN_LAYERS,\n",
    "    \"hs\": HIDDEN_SIZE,\n",
    "    \"dr\": DROPOUT_RATE,\n",
    "    \"l1\": L1_LAMBDA,\n",
    "    \"l2\": L2_LAMBDA,\n",
    "}\n",
    "\n",
    "model = best_model if \"best_model\" in globals() else rnn_model\n",
    "\n",
    "# Run and save output\n",
    "submission = save_experiment_output(\n",
    "    model_name=MODEL.lower(),\n",
    "    hyperparams=hyperparams,\n",
    "    X_test_seq=X_te_win,\n",
    "    label_mapping={'no_pain': 0, 'low_pain': 1, 'high_pain': 2},\n",
    "    sample_indices=X_test[\"sample_index\"].unique(),\n",
    "    output_dir=OUT_DIR,\n",
    "    model=model,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017e3820",
   "metadata": {},
   "source": [
    "## **K-Shuffle-Split Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF, _ = preprocess_joints(X_TRAIN.copy())\n",
    "X_train  = dataset_conversion_type_embed_ready(DF)\n",
    "y = Y_TRAIN.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_shuffle_split_cross_validation_round_rnn(df, y, epochs, criterion, device, k, batch_size, window, stride,\n",
    "                                               hidden_layers, hidden_size, learning_rate, dropout_rate, rnn_type, bidirectional,\n",
    "                            l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
    "                            restore_best_weights=True, writer=None, verbose=10, seed=SEED, experiment_name=\"\"):\n",
    "    \"\"\"\n",
    "    Perform K-fold shuffle split cross-validation with user-based splitting for time series data.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with columns ['user_id', 'activity', 'x_axis', 'y_axis', 'z_axis', 'id']\n",
    "        epochs: Number of training epochs\n",
    "        criterion: Loss function (train_criterion with label smoothing)\n",
    "        device: torch.device for computation\n",
    "        k: Number of cross-validation splits\n",
    "        n_val_idxs: Number of indexes for validation set\n",
    "        batch_size: Batch size for training\n",
    "        hidden_layers: Number of recurrent layers\n",
    "        hidden_size: Hidden state dimensionality\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        dropout_rate: Dropout rate\n",
    "        rnn_type: Type of RNN ('RNN', 'LSTM', 'GRU')\n",
    "        bidirectional: Whether to use bidirectional RNN\n",
    "        l1_lambda: L1 regularization coefficient (if used)\n",
    "        l2_lambda: L2 regularization coefficient (weight_decay)\n",
    "        patience: Early stopping patience\n",
    "        evaluation_metric: Metric to monitor for early stopping\n",
    "        mode: 'max' or 'min' for evaluation metric\n",
    "        restore_best_weights: Whether to restore best weights after training\n",
    "        writer: TensorBoard writer\n",
    "        verbose: Verbosity level\n",
    "        seed: Random seed\n",
    "        experiment_name: Name for experiment logging\n",
    "\n",
    "    Returns:\n",
    "        fold_losses: Dict with validation losses for each split\n",
    "        fold_metrics: Dict with validation F1 scores for each split\n",
    "        best_scores: Dict with best F1 score for each split plus mean and std\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialise containers for results across all splits\n",
    "    fold_losses = {}\n",
    "    fold_metrics = {}\n",
    "    best_scores = {}\n",
    "    best_epochs_per_fold = {}\n",
    "\n",
    "    # Step 1. temporary merge X_train + y_train to create splits ---\n",
    "    train_merged = df.merge(y, on=\"sample_index\")\n",
    "\n",
    "    # Step 2. Retrieve unique indexes ---\n",
    "    unique_samples = train_merged['sample_index'].unique()\n",
    "\n",
    "    num_classes = len(train_merged['label'].unique())\n",
    "\n",
    "    # Prepare stratified K-fold based on label per sample_index\n",
    "    # ---------------------------------------------------------------\n",
    "    # Extract one label per sample_index\n",
    "    label_per_sample = train_merged.groupby(\"sample_index\")[\"label\"].first().map({\n",
    "        \"no_pain\": 0, \"low_pain\": 1, \"high_pain\": 2\n",
    "    }).values\n",
    "\n",
    "    # Create stratified splitter\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "    all_splits = list(skf.split(unique_samples, label_per_sample))\n",
    "    # ---------------------------------------------------------------\n",
    "\n",
    "    # Store initial weights to reset model for each split\n",
    "    initial_state = None\n",
    "\n",
    "    # Iterate through K random splits\n",
    "    for split_idx, (train_idx, val_idx) in enumerate(all_splits):\n",
    "\n",
    "        if verbose > 0:\n",
    "            print(f\"Split {split_idx+1}/{k}\")\n",
    "\n",
    "        # stratified split indices\n",
    "        train_idxs = unique_samples[train_idx]\n",
    "        val_idxs   = unique_samples[val_idx]\n",
    "\n",
    "        # Split the dataset into training, validation, and test sets based on user IDs\n",
    "        df_train = train_merged[train_merged['sample_index'].isin(train_idxs)].copy()\n",
    "        df_val = train_merged[train_merged['sample_index'].isin(val_idxs)].copy()\n",
    "\n",
    "        # X: only features\n",
    "        X_train = df_train.drop(columns=['label'])\n",
    "        X_val   = df_val.drop(columns=['label'])\n",
    "\n",
    "        # y: un'etichetta per ogni sequenza\n",
    "        y_train = df_train.groupby(\"sample_index\")[\"label\"].first().values\n",
    "        y_val   = df_val.groupby(\"sample_index\")[\"label\"].first().values\n",
    "\n",
    "        # Define mapping once\n",
    "        label_mapping = {'no_pain': 0, 'low_pain': 1, 'high_pain': 2}\n",
    "        inv_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "        # Convert y_train/y_val from string â†’ int\n",
    "        y_train = np.array([label_mapping[l] for l in y_train])\n",
    "        y_val   = np.array([label_mapping[l] for l in y_val])\n",
    "\n",
    "        # ============= COMPUTE CLASS WEIGHTS FROM TRAINING FOLD =============\n",
    "        # Calculate class distribution for this fold's training set\n",
    "        num_classes_fold = np.max(y_train) + 1\n",
    "        class_counts_fold = np.bincount(y_train, minlength=num_classes_fold)\n",
    "        \n",
    "        if verbose > 0:\n",
    "            total_train = len(y_train)\n",
    "            print(f\"  Training fold class distribution:\")\n",
    "            for i, name in enumerate(['no_pain', 'low_pain', 'high_pain']):\n",
    "                print(f\"    {name} ({i}): {class_counts_fold[i]} ({class_counts_fold[i]/total_train*100:.1f}%)\")\n",
    "        \n",
    "        # Compute class weights using the 'maximum count' rule\n",
    "        max_count_fold = class_counts_fold.max()\n",
    "        class_weights_fold = max_count_fold / class_counts_fold\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print(f\"  Class weights for this fold: {class_weights_fold}\")\n",
    "        \n",
    "        # Define training criterion with class-aware label smoothing for this fold\n",
    "        train_criterion = ClassAwareLabelSmoothing(\n",
    "            num_classes=num_classes_fold,\n",
    "            smoothing_per_class=[0.15, 0.05, 0.02],\n",
    "            class_weights=class_weights_fold.tolist()\n",
    "        )\n",
    "        # ============= END CLASS WEIGHTS COMPUTATION =============\n",
    "\n",
    "        # Normalise features using training set statistics\n",
    "        scale_columns = [col for col in X_train.columns if col.startswith(\"joint_\")]\n",
    "\n",
    "        train_max = X_train[scale_columns].max()\n",
    "        train_min = X_train[scale_columns].min()\n",
    "\n",
    "        X_train[scale_columns] = (X_train[scale_columns] - train_min) / (train_max - train_min + 1e-8)\n",
    "        X_val[scale_columns] = (X_val[scale_columns] - train_min) / (train_max - train_min + 1e-8)\n",
    "\n",
    "        if verbose > 0:\n",
    "            print(f\"  Training set shape: {X_train.shape}\")\n",
    "            print(f\"  Validation set shape: {X_val.shape}\")\n",
    "\n",
    "        y_train_df = pd.DataFrame({\n",
    "            \"sample_index\": X_train[\"sample_index\"].unique(),\n",
    "            \"label\": y_train\n",
    "        })\n",
    "\n",
    "        X_train_seq, y_train_seq = build_sequences(X_train, y_train_df, window, stride)\n",
    "\n",
    "        y_val_df = pd.DataFrame({\n",
    "            \"sample_index\": X_val[\"sample_index\"].unique(),\n",
    "            \"label\": y_val\n",
    "        })\n",
    "\n",
    "        X_val_seq, y_val_seq = build_sequences(X_val, y_val_df, window, stride)\n",
    "\n",
    "        if verbose > 0:\n",
    "            print(f\"  Training sequences shape: {X_train_seq.shape}\")\n",
    "            print(f\"  Validation sequences shape: {X_val_seq.shape}\")\n",
    "\n",
    "        input_shape = X_train_seq.shape[1:] # extract the shape of a single sequence\n",
    "        num_classes = len(np.unique(y_train)) # how many unique pain level exists\n",
    "\n",
    "        if verbose > 0:\n",
    "            print(f\"  Input shape: {input_shape}\")\n",
    "            print(f\"  Num classes: {num_classes}\")\n",
    "\n",
    "        # Create PyTorch datasets\n",
    "        train_ds = TensorDataset(torch.from_numpy(X_train_seq), torch.from_numpy(y_train_seq))\n",
    "        val_ds   = TensorDataset(torch.from_numpy(X_val_seq), torch.from_numpy(y_val_seq))\n",
    "\n",
    "        # Create data loaders\n",
    "        train_loader = make_loader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "        val_loader   = make_loader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "        # Initialise model architecture\n",
    "        model = RecurrentClassifier(\n",
    "            input_size=input_shape[-1],\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=hidden_layers,\n",
    "            num_classes=num_classes,\n",
    "            dropout_rate=dropout_rate,\n",
    "            bidirectional=bidirectional,\n",
    "            rnn_type=rnn_type\n",
    "        ).to(device)\n",
    "\n",
    "        # 3. save initial state at 1st split, reset in the following splits\n",
    "        if initial_state is None:\n",
    "            # the first split (split_idx == 0)\n",
    "            # save initial random weights\n",
    "            initial_state = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            # Questo Ã¨ uno split successivo (1, 2, ...)\n",
    "            # Resetta il modello ai pesi iniziali salvati\n",
    "            model.load_state_dict(initial_state)\n",
    "        \n",
    "        # Define optimizer with L2 regularization\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=l2_lambda)\n",
    "\n",
    "        # Enable mixed precision training for GPU acceleration\n",
    "        split_scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "\n",
    "        # Create directory for model checkpoints\n",
    "        os.makedirs(f\"models/{experiment_name}\", exist_ok=True)\n",
    "\n",
    "        # Validation criterion (standard CrossEntropy without smoothing)\n",
    "        val_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Train model on current split\n",
    "        model, training_history = fit(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            epochs=epochs,\n",
    "            train_criterion=train_criterion,  # Use fold-specific class-aware smoothing\n",
    "            val_criterion=val_criterion,\n",
    "            optimizer=optimizer,\n",
    "            scaler=split_scaler,\n",
    "            device=device,\n",
    "            writer=writer,\n",
    "            patience=patience,\n",
    "            verbose=verbose,\n",
    "            evaluation_metric=evaluation_metric,\n",
    "            mode=mode,\n",
    "            restore_best_weights=restore_best_weights,\n",
    "            experiment_name=experiment_name+\"/split_\"+str(split_idx)\n",
    "        )\n",
    "\n",
    "        # Store results for this split\n",
    "        fold_losses[f\"split_{split_idx}\"] = training_history['val_loss']\n",
    "        fold_metrics[f\"split_{split_idx}\"] = training_history['val_f1']\n",
    "        best_scores[f\"split_{split_idx}\"] = max(training_history['val_f1'])\n",
    "\n",
    "        best_epoch_idx = training_history['val_f1'].index(max(training_history['val_f1']))\n",
    "        best_epochs_per_fold[f\"split_{split_idx}\"] = best_epoch_idx\n",
    "\n",
    "\n",
    "    # Compute mean and standard deviation of best scores across splits\n",
    "    best_scores[\"mean\"] = np.mean([best_scores[k] for k in best_scores.keys() if k.startswith(\"split_\")])\n",
    "    best_scores[\"std\"] = np.std([best_scores[k] for k in best_scores.keys() if k.startswith(\"split_\")])\n",
    "    best_scores[\"mean_best_epoch\"] = np.mean([\n",
    "        best_epochs_per_fold[k] for k in best_epochs_per_fold.keys() if k.startswith(\"split_\")\n",
    "    ])\n",
    "\n",
    "    if verbose > 0:\n",
    "        print(f\"Best score: {best_scores['mean']:.4f}Â±{best_scores['std']:.4f}\")\n",
    "\n",
    "    return fold_losses, fold_metrics, best_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff903bd4",
   "metadata": {},
   "source": [
    "## **Hyperparameters Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c88b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def grid_search_cv_rnn(df, y, param_grid, fixed_params, cv_params, verbose=True, n_iter=60, \n",
    "                       checkpoint_every=10, early_prune_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Execute grid search with K-shuffle-split cross-validation for RNN models on time series data.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with columns \n",
    "        param_grid: Dict of parameters to test, e.g. {'batch_size': [16, 32], 'rnn_type': ['LSTM', 'GRU']}\n",
    "        fixed_params: Dict of fixed hyperparameters (hidden_size, learning_rate, window_size, stride, etc.)\n",
    "        cv_params: Dict of CV settings (epochs, k, patience, criterion, scaler, device, etc.)\n",
    "        verbose: Print progress for each configuration\n",
    "        checkpoint_every: Save results every N iterations (default 10)\n",
    "        early_prune_threshold: Stop config if score < best_score * threshold after 2 folds (default 0.7)\n",
    "\n",
    "    Returns:\n",
    "        results: Dict with scores for each configuration\n",
    "        best_config: Dict with best hyperparameter combination\n",
    "        best_score: Best mean F1 score achieved\n",
    "        best_config_epochs: Mean best epoch from best configuration\n",
    "    \"\"\"\n",
    "    # Generate all parameter combinations\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_values = list(param_grid.values())\n",
    "    all_combinations = list(product(*param_values))\n",
    "\n",
    "    total_possible = len(all_combinations)\n",
    "\n",
    "    \n",
    "    results = {}\n",
    "    best_score = -np.inf\n",
    "    best_config = None\n",
    "    best_config_epochs = None\n",
    "\n",
    "    # Se n_iter Ã¨ minore del totale, scegli N combinazioni a caso\n",
    "    if n_iter < total_possible:\n",
    "        print(f\"--- Eseguendo RANDOM SEARCH ---\")\n",
    "        print(f\"Selezionate {n_iter} combinazioni casuali su {total_possible} possibili.\")\n",
    "        # Use seed for reproducibility\n",
    "        random.seed(cv_params.get('seed', 42))\n",
    "        combinations = random.sample(all_combinations, n_iter)\n",
    "    else:\n",
    "        print(f\"--- Eseguendo GRID SEARCH ---\")\n",
    "        print(f\"Testando tutte le {total_possible} combinazioni.\")\n",
    "        combinations = all_combinations\n",
    "\n",
    "    for idx, combo in enumerate(combinations, 1):\n",
    "        # Create current configuration dict\n",
    "        current_config = dict(zip(param_names, combo))\n",
    "        config_str = \"_\".join([f\"{k}_{v}\" for k, v in current_config.items()])\n",
    "\n",
    "        if verbose:\n",
    "            if n_iter < total_possible:\n",
    "                print(f\"\\nConfiguration {idx}/{n_iter}:\")\n",
    "            else:\n",
    "                 print(f\"\\nConfiguration {idx}/{total_possible}:\")\n",
    "            for param, value in current_config.items():\n",
    "                print(f\"  {param}: {value}\")\n",
    "\n",
    "        # Merge current config with fixed parameters\n",
    "        run_params = {**fixed_params, **current_config}\n",
    "\n",
    "        # Execute cross-validation \n",
    "        _, _, fold_scores = k_shuffle_split_cross_validation_round_rnn(\n",
    "            df=df,\n",
    "            y=y,\n",
    "            experiment_name=config_str,\n",
    "            **run_params,\n",
    "            **cv_params\n",
    "        )\n",
    "\n",
    "        # Early pruning: skip config if performance is too poor after initial folds\n",
    "        if best_score > -np.inf:  # Only prune after we have a baseline\n",
    "            partial_scores = fold_scores.get('scores', [])\n",
    "            if len(partial_scores) >= 2:\n",
    "                partial_mean = np.mean(partial_scores[:2])\n",
    "                if partial_mean < best_score * early_prune_threshold:\n",
    "                    if verbose:\n",
    "                        print(f\"  [PRUNED] Score {partial_mean:.4f} < {best_score * early_prune_threshold:.4f} (threshold), skipping.\")\n",
    "                    results[config_str] = fold_scores  # Still save for analysis\n",
    "                    continue\n",
    "\n",
    "        # Store results\n",
    "        results[config_str] = fold_scores\n",
    "\n",
    "        # Track best configuration\n",
    "        if fold_scores[\"mean\"] > best_score:\n",
    "            best_score = fold_scores[\"mean\"]\n",
    "            best_config = current_config.copy()\n",
    "            best_config_epochs = fold_scores[\"mean_best_epoch\"]\n",
    "            if verbose:\n",
    "                print(\"  NEW BEST SCORE!\")\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"  F1 Score: {fold_scores['mean']:.4f}Â±{fold_scores['std']:.4f}\")\n",
    "\n",
    "        # Save checkpoint periodically\n",
    "        if idx % checkpoint_every == 0:\n",
    "            checkpoint_path = f'grid_search_checkpoint_{idx}.pkl'\n",
    "            with open(checkpoint_path, 'wb') as f:\n",
    "                pickle.dump({\n",
    "                    'results': results,\n",
    "                    'best_config': best_config,\n",
    "                    'best_score': best_score,\n",
    "                    'best_config_epochs': best_config_epochs,\n",
    "                    'completed_idx': idx,\n",
    "                    'total': n_iter if n_iter < total_possible else total_possible\n",
    "                }, f)\n",
    "            if verbose:\n",
    "                print(f\"  [CHECKPOINT] Salvato in {checkpoint_path}\")\n",
    "\n",
    "    # Final save\n",
    "    final_path = os.path.join(OUTPUT_DIR, 'grid_search_final.pkl')
\n",
    "    with open(final_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'results': results,\n",
    "            'best_config': best_config,\n",
    "            'best_score': best_score,\n",
    "            'best_config_epochs': best_config_epochs\n",
    "        }, f)\n",
    "    print(f\"\\n[COMPLETATO] Risultati salvati in {final_path}\")\n",
    "\n",
    "    return results, best_config, best_score, best_config_epochs\n",
    "\n",
    "\n",
    "def plot_top_configurations_rnn(results, k_splits, top_n=5, figsize=(14, 7)):\n",
    "    \"\"\"\n",
    "    Visualise top N RNN configurations with boxplots of F1 scores across CV splits.\n",
    "\n",
    "    Args:\n",
    "        results: Dict of results from grid_search_cv_rnn\n",
    "        k_splits: Number of CV splits used\n",
    "        top_n: Number of top configurations to display\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    # Sort by mean score\n",
    "    config_scores = {name: data['mean'] for name, data in results.items()}\n",
    "    sorted_configs = sorted(config_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Select top N\n",
    "    top_configs = sorted_configs[:min(top_n, len(sorted_configs))]\n",
    "\n",
    "    # Prepare boxplot data\n",
    "    boxplot_data = []\n",
    "    labels = []\n",
    "\n",
    "    # Define a dictionary for replacements, ordered to handle prefixes correctly\n",
    "    replacements = {\n",
    "        'window_':'W=',\n",
    "        'stride_':'S=',\n",
    "        'batch_size_': 'BS=',\n",
    "        'learning_rate_': '\\nLR=',\n",
    "        'hidden_layers_': '\\nHL=',\n",
    "        'hidden_size_': '\\nHS=',\n",
    "        'dropout_rate_': '\\nDR=',\n",
    "        'rnn_type_': '\\nRNN=',\n",
    "        'bidirectional_': '\\nBIDIR=',\n",
    "        'l1_lambda_': '\\nL1=',\n",
    "        'l2_lambda_': '\\nL2='\n",
    "    }\n",
    "\n",
    "    # Replacements for separators\n",
    "    separator_replacements = {\n",
    "        '_window_':'\\nW=',\n",
    "        '_stride_':'\\nS=',\n",
    "        '_learning_rate_': '\\nLR=',\n",
    "        '_hidden_layers_': '\\nHL=',\n",
    "        '_hidden_size_': '\\nHS=',\n",
    "        '_dropout_rate_': '\\nDR=',\n",
    "        '_rnn_type_': '\\nRNN=',\n",
    "        '_bidirectional_': '\\nBIDIR=',\n",
    "        '_l1_lambda_': '\\nL1=',\n",
    "        '_l2_lambda_': '\\nL2=',\n",
    "        '_': ''\n",
    "    }\n",
    "\n",
    "    for config_name, mean_score in top_configs:\n",
    "        # Extract best score from each split (auto-detect number of splits)\n",
    "        split_scores = []\n",
    "        for i in range(k_splits):\n",
    "            if f'split_{i}' in results[config_name]:\n",
    "                split_scores.append(results[config_name][f'split_{i}'])\n",
    "        boxplot_data.append(split_scores)\n",
    "\n",
    "        # Verify we have the expected number of splits\n",
    "        if len(split_scores) != k_splits:\n",
    "            print(f\"Warning: Config {config_name} has {len(split_scores)} splits, expected {k_splits}\")\n",
    "\n",
    "        # Create readable label using the replacements dictionary\n",
    "        readable_label = config_name\n",
    "        for old, new in replacements.items():\n",
    "            readable_label = readable_label.replace(old, new)\n",
    "\n",
    "        # Apply separator replacements\n",
    "        for old, new in separator_replacements.items():\n",
    "             readable_label = readable_label.replace(old, new)\n",
    "\n",
    "        labels.append(f\"{readable_label}\\n(Î¼={mean_score:.3f})\")\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    bp = ax.boxplot(boxplot_data, labels=labels, patch_artist=True,\n",
    "                    showmeans=True, meanline=True)\n",
    "\n",
    "    # Styling\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor('lightblue')\n",
    "        patch.set_alpha(0.7)\n",
    "\n",
    "    # Highlight best configuration\n",
    "    ax.get_xticklabels()[0].set_fontweight('bold')\n",
    "\n",
    "    ax.set_ylabel('F1 Score')\n",
    "    ax.set_xlabel('Configuration')\n",
    "    ax.set_title(f'Top {len(top_configs)} RNN Configurations - F1 Score Distribution Across {k_splits} Splits')\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "    plt.xticks(rotation=0, ha='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=5\n",
    "VAL_FRAC = 0.20 #20% sequences for validation in each split\n",
    "N = X_train['sample_index'].nunique()\n",
    "N_VAL_IDXS = max(1, int(round(N * VAL_FRAC)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e71877",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF, _ = preprocess_joints(X_TRAIN.copy())\n",
    "X_train = dataset_conversion_type_embed_ready(DF)\n",
    "y = Y_TRAIN.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b2aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define parameters to search\n",
    "param_grid = {\n",
    "    # Batch size â€” gradient noise vs stability\n",
    "    'batch_size': [64, 128, 256],\n",
    "\n",
    "    # Model capacity â€” too small underfits, too large overfits quickly\n",
    "    'hidden_size': [64, 128, 192],\n",
    "    'hidden_layers': [1, 2, 3],\n",
    "\n",
    "    # Regularization â€” dropout reduces overfitting; 0.3â€“0.5 typical for RNNs\n",
    "    'dropout_rate': [0.2, 0.4, 0.5],\n",
    "\n",
    "    # Learning rate â€” main driver of convergence\n",
    "    'learning_rate': [1e-3, 5e-4, 3e-4],\n",
    "\n",
    "    # Weight decay (L2) â€” mild values prevent overfitting\n",
    "    'l2_lambda': [0, 1e-4, 3e-4, 1e-3],\n",
    "\n",
    "    # Architecture type and direction\n",
    "    'rnn_type': ['GRU', 'LSTM'],\n",
    "    'bidirectional': [False, True],\n",
    "\n",
    "    # Training dynamics\n",
    "    'epochs': [100],      # Reduced from 300\n",
    "    'patience': [20],     # Reduced from 50\n",
    "\n",
    "    'window': [12, 16, 20, 24],  # From ACF analysis\n",
    "    'stride': [3, 4, 5, 6],   # From ACF analysis\n",
    "}\n",
    "\n",
    "# Fixed hyperparameters (not being tuned)\n",
    "fixed_params = {\n",
    "    'l1_lambda': L1_LAMBDA,\n",
    "}\n",
    "\n",
    "# Cross-validation settings\n",
    "cv_params = {\n",
    "    'criterion': criterion,\n",
    "    'device': device,\n",
    "    'k': K,\n",
    "    'verbose': 0,\n",
    "    'seed': SEED\n",
    "}\n",
    "\n",
    "# Run aggressive random search\n",
    "# Total possible: 3Ã—3Ã—3Ã—3Ã—3Ã—4Ã—2Ã—2 = 3,888 combinations\n",
    "# Testing: 60 random samples (~1.5% of total)\n",
    "results, best_config, best_score, best_epochs = grid_search_cv_rnn(\n",
    "    df=df_train,\n",
    "    y=y_train,\n",
    "    param_grid=param_grid,\n",
    "    fixed_params=fixed_params,\n",
    "    cv_params=cv_params,\n",
    "    verbose=True,\n",
    "    n_iter=60,  # Sample 60 random configurations\n",
    "    checkpoint_every=10,  # Save every 10 iterations\n",
    "    early_prune_threshold=0.70  # Skip if score < 70% of best\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"BEST CONFIGURATION:\")\n",
    "for k, v in best_config.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"Best F1 Score: {best_score:.4f}\")\n",
    "print(f\"Best Epochs: {best_epochs:.1f}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b198321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "plot_top_configurations_rnn(results, k_splits=K, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1bbd06eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preprocess_joints] start=31 | kept=30 | dropped=1\n",
      "  â€¢ dropped: ['joint_30']\n",
      "\n",
      "Training class distribution:\n",
      "  no_pain (0): 511 (77.3%)\n",
      "  low_pain (1): 94 (14.2%)\n",
      "  high_pain (2): 56 (8.5%)\n",
      "Class weights: [1.         5.43617021 9.125     ]\n"
     ]
    }
   ],
   "source": [
    "DF, _ = preprocess_joints(X_TRAIN.copy())\n",
    "X_train_full = dataset_conversion_type_embed_ready(DF)\n",
    "y_full = Y_TRAIN.copy()\n",
    "\n",
    "\n",
    "labels_full = y_full[\"label\"].map(label_mapping)\n",
    "y_full_np = labels_full.to_numpy()\n",
    "\n",
    "num_classes = np.max(y_full_np) + 1  # For 0-indexed labels: [0, 1, 2] â†’ num_classes=3\n",
    "class_counts = np.bincount(y_full_np, minlength=num_classes)\n",
    "total = len(y_full_np)\n",
    "\n",
    "print(\"\\nTraining class distribution:\")\n",
    "for i, name in enumerate(['no_pain', 'low_pain', 'high_pain']):\n",
    "    print(f\"  {name} ({i}): {class_counts[i]} ({class_counts[i]/total*100:.1f}%)\")\n",
    "\n",
    "# Compute class weights using the 'maximum count' rule (makes the most common class weight=1.0)\n",
    "max_count = class_counts.max()\n",
    "class_weights = max_count / class_counts\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# For use in PyTorch or your label smoothing class:\n",
    "class_weights = class_weights.tolist()\n",
    "\n",
    "# Define training criterion with class-aware label smoothing\n",
    "train_criterion = ClassAwareLabelSmoothing(\n",
    "    num_classes=3,\n",
    "    smoothing_per_class=[0.15, 0.05, 0.02],  # Or tune as needed\n",
    "    class_weights=class_weights              # Use automatic weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b9e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FINAL TRAINING ON THE FULL DATASET + SUBMISSION GENERATION\n",
    "# ============================================================\n",
    "\n",
    "# 1. Preprocess full training data\n",
    "DF, _ = preprocess_joints(X_TRAIN.copy())\n",
    "X_train_full = dataset_conversion_type_embed_ready(DF)\n",
    "y_full = Y_TRAIN.copy()\n",
    "\n",
    "\n",
    "labels_full = y_full[\"label\"].map(label_mapping)\n",
    "y_full_np = labels_full.to_numpy()\n",
    "\n",
    "num_classes = np.max(y_full_np) + 1  # For 0-indexed labels: [0, 1, 2] â†’ num_classes=3\n",
    "class_counts = np.bincount(y_full_np, minlength=num_classes)\n",
    "total = len(y_full_np)\n",
    "\n",
    "print(\"\\nTraining class distribution:\")\n",
    "for i, name in enumerate(['no_pain', 'low_pain', 'high_pain']):\n",
    "    print(f\"  {name} ({i}): {class_counts[i]} ({class_counts[i]/total*100:.1f}%)\")\n",
    "\n",
    "# Compute class weights using the 'maximum count' rule (makes the most common class weight=1.0)\n",
    "max_count = class_counts.max()\n",
    "class_weights = max_count / class_counts\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# For use in PyTorch or your label smoothing class:\n",
    "class_weights = class_weights.tolist()\n",
    "\n",
    "# Define training criterion with class-aware label smoothing\n",
    "train_criterion = ClassAwareLabelSmoothing(\n",
    "    num_classes=3,\n",
    "    smoothing_per_class=[0.15, 0.05, 0.02],  # Or tune as needed\n",
    "    class_weights=class_weights              # Use automatic weights\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Combine the best hyperparameters (found in grid search)\n",
    "final_best_params = {**fixed_params, **best_config}\n",
    "\n",
    "# Use mean best epoch from CV + 20% buffer (more data â†’ slightly more epochs)\n",
    "final_epochs = int(best_epochs * 1.2)\n",
    "print(f\"\\nðŸ“Š CV found best performance at epoch {best_epochs:.1f} (average)\")\n",
    "print(f\"   Final training will use {final_epochs} epochs (20% buffer for full dataset)\")\n",
    "\n",
    "final_best_params['epochs'] = final_epochs\n",
    "\n",
    "\n",
    "print(\"Training final model with best configuration:\")\n",
    "for k, v in final_best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# 3. Merge features and labels\n",
    "train_merged = X_train_full.merge(y_full, on=\"sample_index\")\n",
    "\n",
    "# 4. Encode labels numerically BEFORE building sequences\n",
    "label_mapping = {\"no_pain\": 0, \"low_pain\": 1, \"high_pain\": 2}\n",
    "train_merged[\"label\"] = train_merged[\"label\"].map(label_mapping)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Normalise feature values\n",
    "\n",
    "scale_columns = [col for col in train_merged.columns if col.startswith(\"joint_\")]\n",
    "# calculate the minimum and maximum values from the training data only\n",
    "mins = X_train[scale_columns].min()\n",
    "maxs = X_train[scale_columns].max()\n",
    "\n",
    "# apply normalisation to the specified columns in all datasets (training and validation)\n",
    "for column in scale_columns:\n",
    "\n",
    "    # normalise the training set\n",
    "    train_merged[column] = (train_merged[column] - mins[column]) / (maxs[column] - mins[column])\n",
    "\n",
    "# 6. Build full sequences\n",
    "X_train_seq, y_train_seq = build_sequences(train_merged, train_merged[[\"sample_index\", \"label\"]], window=final_best_params[\"window\"], stride=final_best_params[\"stride\"])\n",
    "\n",
    "\n",
    "# 7. DataLoader\n",
    "train_ds = TensorDataset(torch.from_numpy(X_train_seq), torch.from_numpy(y_train_seq))\n",
    "train_loader = make_loader(train_ds, batch_size=final_best_params[\"batch_size\"], shuffle=True, drop_last=False)\n",
    "\n",
    "# 8. Initialize model with tuned hyperparameters\n",
    "model = RecurrentClassifier(\n",
    "    input_size=X_train_seq.shape[2],\n",
    "    hidden_size=final_best_params[\"hidden_size\"],\n",
    "    num_layers=final_best_params[\"hidden_layers\"],\n",
    "    num_classes=len(label_mapping),\n",
    "    dropout_rate=final_best_params[\"dropout_rate\"],\n",
    "    bidirectional=final_best_params[\"bidirectional\"],\n",
    "    rnn_type=final_best_params[\"rnn_type\"]\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=final_best_params[\"learning_rate\"])\n",
    "scaler = torch.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "# 9. Train model on the entire dataset\n",
    "model, history = fit(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=None,\n",
    "    epochs=final_epochs,\n",
    "    train_criterion=train_criterion,\n",
    "    val_criterion=None,\n",
    "    optimizer=optimizer,\n",
    "    scaler=scaler,\n",
    "    device=device,\n",
    "    patience=final_best_params[\"patience\"],\n",
    "    verbose=True,\n",
    "    evaluation_metric=\"val_f1\",  # ignored since no validation\n",
    "    mode=\"max\",\n",
    "    restore_best_weights=False,\n",
    "    experiment_name=\"final_full_train\"\n",
    ")\n",
    "\n",
    "# 10. Prepare test set for inference\n",
    "X_test = pd.read_csv(DATASET_ROOT / \"pirate_pain_test.csv\")\n",
    "DF_test, _ = preprocess_joints(X_test.copy())\n",
    "X_test = dataset_conversion_type_embed_ready(DF_test)\n",
    "\n",
    "for column in scale_columns:\n",
    "    # normalise the test set\n",
    "    X_test[column] = (X_test[column] - mins[column]) / (maxs[column] - mins[column])\n",
    "\n",
    "# Build windowed sequences (this creates N_windows, not N_sequences)\n",
    "X_test_seq, _ = build_sequences(X_test, None, window=final_best_params[\"window\"], stride=final_best_params[\"stride\"])\n",
    "\n",
    "# 11. Save predictions and configuration\n",
    "OUT_DIR = \"results_best_model\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "hyperparams = final_best_params.copy()\n",
    "hyperparams.update({\n",
    "    \"best_cv_f1\": best_score\n",
    "})\n",
    "\n",
    "# MODIFIED: Pass window_size and stride for aggregation\n",
    "submission = save_experiment_output(\n",
    "    model_name=final_best_params[\"rnn_type\"].lower(),\n",
    "    hyperparams=hyperparams,\n",
    "    X_test_seq=X_test_seq,  # Windowed data (N_windows, W, F)\n",
    "    label_mapping=label_mapping,\n",
    "    output_dir=OUT_DIR,\n",
    "    sample_indices=X_test[\"sample_index\"].unique(),\n",
    "    model=model,\n",
    "    window_size=final_best_params[\"window\"],  # NEW: pass for aggregation\n",
    "    stride=final_best_params[\"stride\"]  # NEW: pass for aggregation\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Final model trained and submission saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "an2dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
